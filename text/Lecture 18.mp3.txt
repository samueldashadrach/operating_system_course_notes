{"text":"So, welcome to Operating Systems lecture 18. So, so far we were discussing how processes are implemented and how they work, how they work in action. So, let us say there are two processes P1 and P2. P1 has a, each process has a user space and a kernel space. The user space is private. So, this is P1 space, this is P2 space and the kernel space is shared, so this is, so the kernel space is common. So, P1 and P2 both share the same kernel space. The only thing that distinguishes two processes are the k-stacks. So, P1's k-stack is different from P2's k-stack, okay, all right. And, and we said that the state of a process within the kernel is encapsulated in its k-stack, right. So, the state of a process within the user space is encapsulated by whatever the contents of the address space are, but the state of the process inside the kernel, for example, what are the processes that are called, where was it when it was context switched out, all this information is basically stored in the kernel stack. In general, I mean, recall that we had made a statement that every user process is also a kernel thread, right. So, a user process, the state of a process also involves the contents of its address space, because each process has a different address space and different contents. The state of a thread typically is just represented by a stack, right, or can be encapsulated by pretty much its stack, right. So, a thread basically shares the address space, or threads, multiple threads usually share the address space, and each thread is really, you know, so what is, how do you distinguish one thread from another, or what is the context of a thread? The context of a thread is really encapsulated in its stack, right. So, any scheduling algorithm among these threads is going to take one thread, if it switches out, it's going to just save all its information in the stack, right, and when it gets switched in, then it's going to retrieve all that information from the stack. And we saw last time what kind of information is saved and retrieved, the registers, the current values of the registers, including the EIP, the program counter, to which it should return immediately, as soon as it gets context within. Also, in the case of KStack, it also saves the information of the trap, right, so at the time that the trap occurred, what are the values of the user registers and all that, right. So, KStack contains not just the information of what was happening in the kernel, but also what happened to the, what was happening in the user at the time when the process entered the kernel, right. So, it contains all this information. So, when you switch to a new process, you can, you know, resume execution from where it was in the kernel space, and the stack also has enough information so that if you want to return to the user space, you will resume at exactly the same point from where you entered from user space to kernel space, all right. So, if we look at the KStack in a little more detail, which we did last time, the KStack basically has, you know, let's say this is the top of the KStack, which means that's where you start from, and on every trap, and the trap could be a system call, a trap could be an external interrupt, a trap could be an exception, like divide by zero or page fault, right, you try to access a segmentation fault, you try to access an address that you are not supposed to access. In either case, a trap frame gets pushed, which contains all the user's values, so these are, you know, user values. So, if you want to return from here, you're just going to pop these values, and you're going to call irate, which is going to pop the last five values, and you want to resume back in your user mode, and we've seen this before. So, this pointer to this structure can also be called P1's trap frame, right, so this entire structure, which contains the entire information about the user execution when it was interrupted, or when it was, you know, when it entered the kernel, when it was trapped in the trap frame, and you can, you know, use this information to, for example, pass arguments from user to kernel, we saw that, and these registers can also be pointers, so you can actually even dereference these values, because you are executing the same address space, right, and you can also use this to pass, to return return values, so you can change these values, and you can say that, okay, you know, I want to change EAX, so you change EAX in the trap frame, and it's going to return, the user is going to see a new EAX, and that, it's assumed it's the return value of the system call, for example, right, and the other thing that happens is, immediately after this, you know, this is a return address, so the stack is treated just like a normal function stack from then on, so you just, let's say, make a call to another function, but in doing so, you should ensure that the address, the return address is pushed on the stack, is that it's address of this function called trap rate, right, and trap rate is going to execute these instructions, which will, you know, pop all these registers and call IRate, right, so just to make sure that, you know, the, so from now on, the stack will behave just like it is expected to behave in case of function calls, right, so you make a function call, and, but before you do that, make sure that the return address is trap rate, now those functions are going to get executed, there could be a deep chain of function calls, you know, one after another, in which case, multiple return addresses will get pushed, and when they return, return addresses will be popped, and eventually, when you reach here, then trap rate is going to get popped, and then it's going to pop off all these registers, and then it's going to call IRate, and you're going to get back to, you know, right, all right, we also discussed that it's possible, so firstly, the stack of a thread, or the stack of a, the case stack of a process is finite, right, question is, how big should it be, right, clearly it cannot be infinite, right, so how does the programmer decide how, if you were a kernel programmer, how will you decide how big a case stack should be, well, firstly, it should be at least as big as the trap frame, okay, then it should, you know, whatever function it's going to call, what is the deepest function call that it can have, so if you, if you, if you can analyze your code and say, you know, this is the maximum call chain, or call depth that you can have, that will give you some indication of what the maximum size of the case stack should be, moreover, a function should not have very large local variables, so if you're allocating local variables on stack, you know, you shouldn't be allocating like large arrays on the case stack, so all these things, the kernel needs to be, the developer needs to be careful about, right, so few sums of rules, number one, you shouldn't have a very deep call stack, you should design your code such that the call stack can never become so deep, right, easy to do, you basically ensure that, you know, the function call chain can never go beyond a certain depth, secondly, you never allocate large variables, you never declare large variables as local variables, right, if you want large variables, what should you do? Allocate out of the heap, right, just malloc, just k-alloc, and allocate a page size value, and that's it, right, so don't allocate large variables on the stack, okay, and that should pretty much satisfy what I said, except there's one issue, right, I said that a kernel, while a thread was executing in the kernel mode, an interrupt could come, right, so if I, if the thread was executing in the kernel mode, and let's say the stack pointer is somewhere here, and another interrupt comes, a timer interrupt comes, or, you know, a disk interrupt comes, or a network card interrupt comes, another trap frame gets pushed, and while I'm executing that handler, another interrupt comes, and another trap frame gets pushed, and theoretically, I could very soon overflow my stack frame, right, that's possible, so what can be done to prevent this problem? Okay, there's an answer that after three nested frames, call a triple fault and fault, I mean, is that a valid solution? I mean, it's possible that some external device is making lots of interrupts, do you really want to shut your system because some device is misbehaving? Well, the answer is very simple, you basically ensure that some of your handlers are run with interrupts disabled, right, so for example, any interrupt handler which handles an external interrupt, for example, an external device interrupt, like a timer, or a disk, or a network, these handlers will never run with interrupts enabled, they will always run with interrupts disabled, right, so notice that this kind of a situation where, you know, multiple trap frames are getting pushed on the stack can only happen if an external device is misbehaving, right, that's giving me a lot of traps, so if I ensure that any handler of an external device always runs with interrupts disabled, while that handler is executing, I'll not receive any interrupts, right, the other thing I ensure is that my code is such that I will never, you know, I'll never have more than, let's say, n number of trap frames on the stack, right, for x86, let's say, the maximum number of the n is 2, right, so one trap frame is the first trap, the first trap could have occurred either due to an external interrupt, in which case there cannot be any other trap frame, because the entire external interrupt handler will run with interrupts disabled, or it can happen due to a system call, in which case I don't need to really disable interrupts, right, I want that my system call should be interruptible, and in which case, so now I want to make sure that my system call handler should never cause a trap itself, for example, a system call handler should never cause a page fault, or a segmentation fault, or my system call handler should never do a divide by zero, right, that's easy to ensure, as a developer I can make sure, the thing that's not in my control is somebody from outside triggering an interrupt, so because of that, I can have another trap frame, so I can have at most two trap frames, because the external device handler will run with interrupts disabled, I'll not have more than two, right, so that way you can limit the maximum number of trap frames you can have on the stack, you have also limited the maximum call chain, and from that you can estimate what's the maximum size of stack that you need, as on xv6 you just allocate one page for the case stack, 4kb, all right, there's a question, right, so can you support more than one external device in this setting, well, yes, you can, I mean, so what happens if the interrupts are disabled, while the interrupts are disabled, if another interrupt comes, that interrupt gets ignored, right, we have discussed this before, so that interrupt just simply gets ignored, what will happen if the interrupt gets ignored, does the device get confused, because he's thinking he has given the interrupt, and the CPU has actually not received the interrupt, well, one thing, you know, usually the setup is such that an interrupt needs to be acknowledged by the CPU, that I've received your interrupt, right, so the hardware is, you know, is typically programmed in a way that if you have not received an acknowledgement, then you'll retry the interrupt, let's say, okay, the other thing is to avoid too many retries, the CPU itself has a buffer of, you know, one or two interrupts, so if you got an interrupt while the CPU was, had disabled the interrupt, you just buffer the interrupt, and as soon as the interrupt flag gets enabled, you just push it to the CPU, right, so that's just an optimization, right, so let's say, you know, you can buffer up to two interrupts, just so that the interrupts don't get lost, okay, another interesting piece, another interesting thing, how does the computer keep time, how does it know how much time it has passed, how does it keep track of, you know, how does it implement your clock, it just counts the number of time interrupts, it has configured the time interrupt hardware to say, give me an interrupt every 10 milliseconds, 10 milliseconds, and just keeps counting the number of time interrupts that I've received, and that basically tells him the time, that's the only way it can, so far we have seen, that's the only way for a CPU to keep track of the time, right, okay, fine, that's fine, okay, so with that, we know that the case stack is a finite sized structure, and and when a process traps, either due to a system call or a time interrupt handler, or anything else, like an exception, it just creates a stack, has a function chain, and let's say, at some point, you want to switch it out, in which case, you're going to save the registers, and in this case, you're going to save the kernel registers value, okay, and you're going to put this stack in memory, you're going to put these values in memory, you're going to leave it as it is, and you're going to switch to a new stack, okay, and that stack is now, and you're going to unwind that stack, just as you wound it, and you're going to, and that basically implements your context switch, okay, right, so let's talk about how, let's say, fork is implemented, so recall what is fork, fork basically creates a new process, which is a replica of the parent process, so it creates a child process, which is a replica of the parent process, everything about it is identical in the user space, except that the return value is different, right, so what does, what will it do, what do you think, let's say a parent process called fork, fork will be treated just like any other system call, so this trap frame is going to get pushed, some functions are going to get called, and in those functions, what it's going to do, is it's going to create another stack, child K stack, where is it going to allocate the space to create the child K stack, from the kernel Z, K alloc, right, so it calls K alloc to create a child K stack, and it initializes the child K stack, such that it has either identical trap frame, right, so the trap frame is identical, the contents of these two are identical, the ID of this, let's say, except that the EX value is different, right, so that's how the child will have a different return value, and I will have a different return value, that's all, okay, the other thing I do is, you know, I also push trap rate here, so that, you know, when it gets scheduled, it knows that it needs to pop up these values, and then return to user mode, so I'll push trap rate here, and then I'll push some initialization function, let's say, you know, some other return address, on xv6, this is fork rate, but let's just say, you know, some functions, and then I'm going to save, I don't need to save the entire call chain from the parent, I just save, I just initialize it with the parent trap frame, the address of the function trap rate, and the registers, which can be, let's say, zero initialized or something, right, you don't care, all you care is that you're going to return from here, you're going to return from the trap, and you're going to start executing in user mode, as a fresh process, also you're obviously going to allocate a new page there, and copy the contents of the kernels of the parent's page there into the child's page there, that's the implementation of fork, did I need to copy the entire call chain from the parent to the child, no, that would have been wrong, right, because the parent is executing a system called fork, the child is not executing the system called fork, the child just wants to return to the user mode, it's exactly the same point, that's all, it's not calling the system called fork, so I only need to copy this area, not anything below it, and I need to initialize something so that, you know, it starts from where it wants to start, so that's fork, as I said, you know, all processes, once a process has been created, in future, all new processes are created using fork, except the first process, right, so the first process is special, and that's something that's created by the kernel, right, so the first process will be created by the kernel, and what the first process is going to do is, it's going to exec, let's say, some command, which is going to, and so you're going to see a shell on the console, and you can now type command and execute more forks and more execs, right, that's how it typically works, there's one init process in the kernel, be it x86 or any mainstream kernel, and that just reads some files, and based on the file, they just fork some processes in the beginning, right, but the first process is created by the kernel, that's all, so how is the first process created, very simple, in the fork, we just copied the stack from the parent to the child, if I want to create the first process, I just initialize the case stack, right, and initialize the fresh page there, except that it's a special case stack, special page there, yes, no, the child and the parent don't share the page table, the page table gets copied, no, the page, by page there, I'm copying the page there, I mean, the entire two level page table gets copied, are the values of pte underscore p set to zero, no, I mean, so basically you just, so you copy the entire page table, and you also, in fact, copy the physical pages, right, so whatever is the size of the parent process, you don't just copy the page table, you also copy the physical pages, right, so you allocate new set of pages, you copy the pages from the parent, the contents of the pages from the parent to the child, you create a new page table to point to this new set of pages, and that's it, right, so this is basically the nice way of doing things, which is you copy the entire set of pages from the parent to the child, and then you initialize the page directory of the child, but we said that, look, this is expensive, often not needed, because the first thing a fork process may want to do is exit, in which case you wasted all this work, in which case you can do demand paging, right, so, you know, how will demand paging work? Well, I just, you know, I have the parent's page directory and the page table, the two level page table, I copy the page table from the parent to the child, I mark all the pages in the parent's page table as read only, I mark all the pages in the child's page table as read only, and I started running, right, as and when the process is going to access a page that, with right intentions, then you're going to get a page fault, the page fault can either occur in the parent or it can occur in the child, at the time of a page fault, you are going to look at which address it is that page fault is, and you're going to copy that particular page and make two copies of it, one for the child and one for the parent, and you're going to remove the read only mapping and make it read write, so that's an optimization, that's a copy on write optimization, and, but let's keep things simple, x86 does not implement that, so let's just understand first how things work at the basic level and then we can definitely talk about optimization from there on, okay? All right. Okay, so in both these cases, what I've done is I've initialized the kstack, and I haven't done anything, I've just added it to my list of PCBs, right, so initialize, a creation of a process basically means initialize kstack and page div, and let's say put these in a structure called PCB, right, and put it to the list of PCBs, add it to the list of PCBs, and make it schedulable, right, and then just call the scheduler, and the scheduler is going to pick one of the PCBs and just switch to it, because I've initialized the kstack in such a way that when you switch to it, you're going to start running exactly as you wanted it to run, that's fine, right? Okay, so let's talk about creation of the first process. So after boot up, the kernel has initialized itself to be running off a kstack, but this kstack is different from the kstack of the first process, so let's call it a scheduler's kstack. So the kernel, when it initialized itself, it just initialized its kstack and it, once again, the kstack was allocated off the heap, and that particular kstack does not belong to any process, and let's just call it the scheduler's kstack, right? Now it's going to initialize, you know, p0's, let's say, the init process of p0, so it's going to initialize p0's kstack, and it's going to switch p0, right, p0's kstack, and it's going to switch from the scheduler's kstack to the p0's kstack. The p0 will now get to run, and p0 may now, let's say, fork new processes, so a new p1 gets created, and so a new p1's kstack gets created, right? And at some point, p0 is going to yield, either voluntarily, by calling the yields call, or involuntarily, because of a timer interrupt. In either case, p0's kstack is going to switch back to the scheduler's kstack. Scheduler's going to run, right? The scheduler's kstack is the kstack that was running right in the beginning, right? Scheduler's going to run on its own kstack, and it's going to pick up one process to run, and now it's going to switch to, let's say, p1's kstack, and this process just continues forever, right? So there's a scheduler's kstack for a CPU, which is the first kstack that it started with. It picks a process. The logic of picking up a process executes on this kstack, when you pick up a process, you switch to that kstack, that process gets to run, then that process yields, you switch back to scheduler kstack, the scheduler picks another process to run, and so on, right? So there's a scheduler's kstack, so a process switches to scheduler, then scheduler switches to yet another process, and so this seesaw keeps happening, right? Okay, so let's look at how this switch actually works. This is the first process that we are creating. Yes. Is the scheduler implemented by hardware? No, scheduler is completely software, an operating system code. The scheduler is not really a process, right, because it doesn't have a user space associated to it. A scheduler can be thought of as a kernel thread. So every CPU just has this one special kstack, that's all. And notice that in general, there's a one-to-one correspondence between a thread and a stack, right? So because I'm saying a scheduler has its own stack, you can think of a scheduler as a thread. A scheduler doesn't have a page there, so scheduler is not a process. Okay, all right. So here's the function which switches, right? So we said that the scheduler is going to switch to the new process. What does it mean to switch to the new process? It just calls this function called switch, right? And let's understand this function before we go forward. So this is a function called switch without an I in this case. It's an assembly function. It takes two arguments. There's a structure called context, which basically holds the saved register values of the kernel, right? Recall that we said that there's some values that the kernel has that needs to be saved. So it takes a pointer to the context, so there's a structure called context. This is the old context, and this is the new context. And what this switch function is going to do is switch from the current context to the new context and save the values of the current context into old, right? So the semantics here, save current into old, right? And load from new. That's what this function is going to do. It's going to save the current context, which is the values of the current registers, into old, and load the values of registers from the new context. And then it's done, basically. So where is this context going to get stored? So what is this context? If I look at this figure here in this kstack, right? If this is my kstack, then the context will be this pointer here. So it's going to save values at the bottom of the stack. That's where the old context is. So if you're switching from here to here, then this will be the old context, and you're going to save the current values here, and you're going to load the new context from here. So that's what this is going to do. It's going to save the current context into the old context, and the old context will live on the kstack of the old process, or old thread. And similarly, you're going to load values from the new context. So what does it do? It basically just takes its first argument. The first argument is at offset 4 from the current ESP. It's a function. So you're basically using the function calling conventions, GCC calling conventions, which are the first argument is at offset 4 from ESP, put into EAX. That's your old pointer. This is, take the second argument, 8 offset, put it into EDX. That's a new pointer. You push values on the current stack, whatever the values of the registers are on the current stack, whatever the current values are on the stack, and you move the stack into the old context. Recall that EAX was the old context. So you move values into, so basically what's happening is there's a pointer called old context, and there is, let's say, old kstack. So currently ESP will be pointing in the old kstack somewhere. You push some values, you push the values of the current registers, let's say EBP, EBX, ESI, ESI, EDI. ESP now starts pointing here. And you basically save the value of the ESP in old context. You say old context is equal to ESP. Star old context is equal to ESP. So you save the value of the current ESP into old context. And then you say ESP is equal to new context. So that's switching taking place. You save the current value of ESP into a pointer called old context, and you loaded ESP from the new context. And then whatever you did here, you do the opposite of here, which is pop all the registers. So because the old context, the new context is assumed to be in the same structure as your current old, so assuming that that process was also switched out in the same way, which means it must have pushed all these registers. So the moment I switch to the new context, I can now start popping those registers, and I can call the return instruction, which is going to go to the caller of switch and continue like that. So that's where you switch the stack. And basically all stacks, so all saved stacks in the kernel will always be in the state where the last four values in the stack will be these saved values, EBP, EBX, ESI, and EDI, always. And so whenever you switch to a stack, then the first thing you will do is pop off all these values, and the fifth value will be the return address. So return will return to that address. Right? So basically, when I was talking about switching case stacks, let's say this is my case stack, I now have a new invariant that context will be pointing to a location in my case stack, such that the first four values will be these registers, and the fifth value will be a return address. And so whenever I switch to it, I'll always switch to it in the switch function. And what I'm going to do is I'm going to pop off these values and then call return, and I'm back in business. I'm back in action, just like I left. Irrespective of where I am, I call switch, I get switched out. At some later point, I get switched in, and I start execution, resuming from exactly where I left. Right? So whoever called switch is going to now start executing from the next instruction after calling switch. Right? Just like before. So that's a context switch. Just with the stack. So one thread enters the switch, and another thread leaves the switch. Right? So it's a special function in that sense. Typically, you enter, you know, you enter, let's say foo calls switch. Let's say, let's say this is foo, and it calls switch. And let's say there was another function, so it's probably never going to return here. Right? It's going to return in some other, it's going to start executing some other thread. And then that thread is going to call switch at some later time. And at that time, I'm going to start, resume execution from here. Right? So I don't immediately return from switch. I return from switch much later on another context switch. Right? That's the difference, basically. All right. Okay, good. Yes? So the switch function hasn't changed the EIP value. How is the EIP value getting changed? By the return instruction. Right? So the return instruction is the one that changes the EIP value. So the moment you switch the stack, you also change the return address. Right? So that's the trick going on here. You didn't change the pointer, you didn't change EIP explicitly. You just changed the stack, and the return address got changed. So this is very interesting, you know, this is the heart of an operating system, which is the context switching code, and quite tricky in that sense. All right. Okay. So what does this tell us? It tells us that if I want to create the first process, I should initialize the kstack such that it has the trap frame, let's call it 3f, at the top, it has trap red here, and at the bottom, it has the context. That's what I'm going to do. I'm going to initialize a kstack, which looks just like this, and just add it to the list of PCBs and call the scheduler. And the scheduler is going to call switch, and because the kstack is well-formed, it's just going to start returning from here and start executing the first process. The invariant I'm maintaining is that all the kstacks that are saved, that are not currently running, are always in this sort of format where the last few bytes, the context is pointing to a location, which is basically pointing to the size of the current stack, and the first few bytes after context are basically the saved registers and the return address. Okay, question. Why am I only saving these four registers? Why not eax, ebx? What happened to those registers? There's an answer that they were saved in the trap frame. Is that right? No, I mean, trap frame saved the user's eax, ebx. Now I'm executing the kernel, so kernel has some eax, ebx also, so they may have changed. So why am I not saving eax, ebx? Yeah, it's a caller-saved register, right? I'm assuming that switch is a function call, and I'm assuming that the function calling conventions are being weighed, so all those registers must have been saved by the caller. So I only need to save the callee-saved registers, okay? I mean, I could have saved all registers, that would have been just extra work unnecessarily, right? The caller must have saved them for me anyway, so I just need to save the callee-saved registers. Okay, very good. Okay, so yes. Callee is switch. Callee is the switch function. Yes. Okay, so the question is, who is the callee and who is the caller? Well, whoever called the switch function, he's the caller, and because he's following the calling conventions, he must have saved the caller-saved register, right? And he must have ensured that, you know, when he comes back from the switch function, he'll reload the caller-saved registers back. So as a function, I only need to worry about the callee-saved registers, because I'm a function, right? And I'm assuming that the function calling conventions are being obeyed. All right. Okay, so then let's look at sheet 20, and let's look at the structure of a PCB on x86, right? So when talking about PCB, let's understand what it looks like, right? So this struct block basically is the structure of a PCB, process control block, inside x86, and here are all the fields of the process control block. So let me bring your attention to some of the fields that you already understand. So here is a pointer to the page directory, right? This pointer value will always be a low address or a high address? I mean, will it be an address above current base? It'll always be a high address, right? It'll always be a current base and above address, because it's something that you've allocated, and now you're going to load the value of this pointer after converting it to its physical address by subtracting current base and load into CR3, whenever you want to context switch to it, right? So that's what page there does. And pages for the page there and all the second level page tables are allocated off the kernel heap, right? Kstack, we understand this. Once again, allocated off the kernel heap, and the maximum size of a Kstack in x86 is one page. So we understand this also. Then there's this integer called PID, which basically says what the process ID. So every process should also have an ID, right? And there's a system called getPID, which allows the process to know its current process ID. So you need to store that. Okay. Then you see that there is this pointer called struct trap frame star tf. What is it? It's a pointer into the Kstack at the location where the trap frame is stored. Why do you need it? If any of the downstream functions want to access the values of user registers, you can just do tf.pointer.value. So it's very nice, easy to do that. Then there is a pointer to the context. Yes. Okay. So the question is, tf stores a valid value only if we were executing in the kernel space right now. Okay. What does it mean? So does tf always store a valid value? Well, if the process is not currently running, then the tf must hold a valid value, right? Because if the process is not currently running, it must have switched out in the kernel space, right? If the process is currently running, then yes, tf is not valid. It's not valid if the process is currently running in the user space, then tf is not valid. If the process is currently running in the kernel space, then tf is still valid, right? But for any process that's not running, so any saved process or any suspended process, tf will always be valid, right? Because the suspended process, in fact, both tf and context will be valid, right? Because as we said, any suspended process, processor's case stack should look exactly like what we drew earlier. And so it should have a context pointer and it should have a tf.trapframe pointer. And so when you want to switch to that suspended process, you're just going to load the stack from that process's context. So you're going to look at that process's context and whatever the value pointer is there, you're going to load it into ESP. So that's what context is storing. You switch to this context, okay? So this is also very important. The context field is important because when you context switch, you switch to this context, which means you load the ESP with this value. So the scheduler has figured out that this is the process I want to run next. It just looks at the context field and calls switch with this as a second argument. And the switch loads that value into ESP. Good. All right. So those are the relevant fields so far, but let's just look at the other fields. Let's say state. So a process also has a state. It basically says whether it's used or unused. So this is just to say that a process, whether it exists or not, right? So if you're not implementing a process, the list of PCBs as a list, but you are implementing it as an array, then you can just have this bit saying this PCB is not used, which means it's not even allocated. Embryo, okay? What embryo means, we're going to discuss later, but it basically means the process hasn't even born yet, right? So it's actually just called fork recently, and the process is just sort of getting initialized. And so only when I'm going to add it to the PCB list, am I going to change its name from embryo to runnable, right? So runnable says here's a process that can be done, right? So any runnable process must have its case tag initialized exactly as the way we discussed. So that's the invariant. Any runnable process, any process whose state is runnable, its case tag should have been initialized exactly as we discussed, basically. A process could be running. It's currently running, right? So, you know, these pointers may not make any sense. If it's running in the user mode, then case tag is not useful, right? Case tag just points to the bottom of the tag, actually. But let's say, you know, the TF and the context fields are not useful. And then there are other fields like sleeping and zombie, which we understand, but let's ignore them for now because we are discussing other things, right? Okay, so let's also look at what happens on a trap, T30. So on a trap, the IDT points to a handler, right? And we said the first thing the handler does is save all the registers, right? So the way xv6 has organized it is that it has pointed all the IDT handlers. You know, it has some initialized code for every handler, but eventually they all jump to this code pointer called traps. So just call jump here, not call, but jump, all right? So they just jump here, and here you see all the code for saving all the registers. So you save all the segment registers, and this instruction pushal basically saves all the general-purpose registers like execx, so all the eight registers that we've discussed. So that's pushall. That's what pusha means. And then it loads the segment registers with the kernel segment, right? Because the difference between segkdata and segudata is only that different privileges. That's all, right? Base and offset are identical. Base and limit are identical. So it just loads it with the kernel segment. You save the user segment. You load the new kernel segment. You do it for all the segment registers. What segkcpu is, let's ignore it for a moment. Let's just say that, you know, there's something that the kernel is doing for kdata and kcpu. It pushes the current esp also. So pusha doesn't push the right esp, so you also push the esp. So one register is not correctly pushed by pushall, which is the esp register itself, because you can imagine esp is changing as you're pushing stuff. So you have to separately use an instruction for pushesp. And then you call a function in C. It's called trap, right? Trap will basically figure out why I trapped and all that. For example, it'll look at the trap frame to figure out why I trapped. So what has happened is this function has initialized the trap frame, right? And then it has called trap. Trap will return at some point, and you're going to get back to trapret. So in this case, the code has been nicely organized such that you call a function, and when it returns, it actually returns back to trapret. And trapret is just going to pop all these registers and call iret. Yes, it will return to line 3023, and 3023 is just ignoring the esp value, that's all. And then it calls trapret. Right? So yes, I mean, trap will return to line 3023. 3023 is not doing much. It's just ignoring one value on the stack. It's just popping off one value on the stack. And then it calls popal and all the other things. Aren't traps no-return functions? Well, I mean, this trap function is not a no-return function. It returns. Right, right. So that's what's happening. So in this case, in this special case, or in this general case, I should say, whenever a trap happens through the regular way, then trapret automatically gets pushed as a return address. Or you know, trapret minus whatever, 3023 gets pushed as a return address. And so everything works normally. But then I'm going to create a new process. What I'm going to do, the new process never called a trap, right? So I'm going to simulate as though that, so I'm going to push trapret manually in that. In general, the trapret gets automatically pushed because you did a call, and you made a call. So the next instruction address gets pushed on the stack. But when I'm going to create the first process, or when I create a fourth process, a child process, in all these cases, the child process didn't make a trap, right? So I need to initialize it with trapret. So either way, there should be a trapret on the stack frame, just below the trap frame, right? So the stack is basically the trap frame and trapret. In case of a normal trap, it automatically happens by the call instruction. In case of the first process, add a fourth process, we need to do it manually. That's all. Yeah, I mean, when you do a fourth process or a new process, then we don't push ESP at the end, so we don't need the statement. Okay, great question. So why are we not saving, why are we saving all the registers? Could I have used the caller callee conventions in this case, just like switch? The switch was a function. This is a trap. A trap follows no convention, right? I need to save all the user registers. A user didn't, a user, there's no, we never studied, we never discussed any convention that before making a system call, the user will save some registers. If there was such a convention, then yes, I would have saved those registers. But even then, you would have had to have a different handler for the system call, and what happens if there was an external interrupt? You know, if there was an external interrupt, the user was completely not expecting an external interrupt, so he may have all the registers valid, and so I need to save all the registers. So firstly, there's no convention on syscalls, and then we need to worry about exceptions and interrupts, so we need to save all the registers. Okay, all right, so let's stop here, and we're going to discuss this more next time."}
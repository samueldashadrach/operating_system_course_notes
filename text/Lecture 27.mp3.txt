{"text":"All right, so welcome to Operating Systems Lecture 27. So far we have looked at locks, condition variables, semaphores, we also looked at lock-free methods like transactions, and one manifestation of that called compare-and-swap, right? So these compare-and-swap instructions are also what are called lock-free methods of dealing with synchronization, and there are advantages of doing lock-free synchronization as we are going to discuss later in this course, right? So today I am going to discuss these in the context of XV6, and let us look at how an operating system like XV6 is using synchronization under it, within itself. And so XV6 uses locks, XV6 uses condition variables but, you know, in a different form. So instead of calling them condition variables, we call them sleep, wake-up, all right? So the semantics are similar, sleep is conditional wait, and wake-up is notify. So instead of calling them condition variables and wait and notify, we call them sleep and wake-up, and we are going to see what are the subtle differences between sleep and wake-up and wait and notify, and does not use semaphores, so that is fine. Semaphores are anyway higher level, you can always simulate anything that you need with semaphores using locks and wake-up. So let us look at how the acquire function is implemented in, so let us look at XV6 locks. Let us look at how XV6 is implementing locks. So this is sheet 14 on your listing, that is the lock function, that is the acquire function basically. Let us see what the lock structure is before that. So lock structure, you know, if you want to initialize a lock, you basically have three fields in the lock. One is the name. Name is just for debugging purposes, if you want to know what lock it is, so it is just for debugging purposes. You do not really need it, but they are using it for debugging. Then there is this lock variable that we know about, that is the state of the lock, and then also which CPU is holding it, that is also again only for debugging. You do not really need it strictly, but that is, you know, it helps in understanding what is going on. All right. So this is the acquire function. It, you know, it disables interrupts. So push CLI is going to disable the interrupts on the current processor. So notice that the acquire function disables interrupts, uses this loop to atomically set the lock variable to 1, sets the CPU to the current CPU value, and this is some debugging function which allows you to log exactly who called this lock, and that is it. So what does it mean? When you get out of acquire, the interrupts are still disabled, right, because you called push CLI and you never called pop, right, you never re-enabled interrupts. So for the entire critical section in this spin lock, the interrupts are disabled. So why does xv6 need to disable interrupts in the entire critical section? So one answer is that if there is a timer interrupt within the critical section, then, you know, it can get swapped out and somebody else can get to run, and atomicity can get violated. Is that right? No, because, you know, the other thread should also be taking the lock, and it will not get the lock because it has already called the exchange instruction here, right? So it has set the lock variable to 0, to 1, so any other thread will not be able to set, you know, be able to acquire the lock. So what if the interrupt handler also tries to access your data, right? So we are within the kernel, and it's possible that whatever data you're accessing, the interrupt handler also tries to access the same data. It's not about multiple threads. Recall that we have been talking about mutual exclusion across threads. Mutual exclusion across threads is easily handled by this atomic exchange instruction, right, on multiple CPUs. But what about mutual exclusion between a thread and the interrupt handler, right? If an interrupt gets to run in the middle of a critical section, and the interrupt handler could touch the data that you have in the middle of a critical section, then we need a way to protect it, right? So what are some ways to protect it? You could say, oh, won't the interrupt handler also try to acquire the lock? But if the interrupt handler tries to acquire the lock, then you have a deadlock right there, right? So you got an interrupt, the interrupt handler gets to run, and the interrupt handler tries to acquire the lock that's already held, right? So that's not a good thing. An interrupt handler will likely run with interrupts disabled, so that's not a good thing. You have a deadlock. So basically to protect a thread from the interrupt handler, from concurrent accesses by the interrupt handler, you disable the interrupts for the entire critical section. The reason this is acceptable in xv6 is because you will expect that the critical sections are small, and critical sections that are protected using the spin lock are small, and those critical sections indeed need to be protected against accesses from interrupts, and we're going to see some examples. In general, when you write your programs, you won't worry about, so let's say you have your own program, or you write your own kernel thread, and that thread has nothing to do with an interrupt handler. Then you won't use xv6's spin lock. You would probably want to use your own spin lock that doesn't disable interrupts, because you don't care about atomicity with respect to the interrupt handler. So the interrupts are disabled for the entire length of the critical section. Acquire leaves the interrupts disabled. Why do I need push fly? Why can't I just use fly? Just to ensure that if there are nested calls to acquire, if they're nested locks, so you acquired lock one, and then you acquired lock two, then you have a count of how many times fly was called. And so that many times you have to call fly before you actually re-enable the interrupts. So if you have nested locks, then that's why you push fly is nothing but it just increments the counter. It's the first CPU counter that it increments, basically saying how many times fly has been called. All right, so that's acquire. And let's look at the other things. So notice that this holding function, what is it doing? It's just checking that whether I'm holding the lock already, whether this CPU is holding the lock already. So this is just a debugging thing, really. And the reason you can check this is because you also have a field called CPU. So holding is just going to check that if the same CPU tried to acquire the same lock twice, that's a bug. And you want to just tell the programmer right away that there's a bug in your program, rather than him have to find it in a roundabout way. So this is just a debugging aid. In general, if you didn't have the CPU field, you won't have been able to make this check. And if you have written your code correctly, that's still correct, but it's a debugging aid for you. Sir? OK, yes. So I mean, the other semantics in this sort of, I mean, the slightly subtle semantics are that a lock is actually held by a CPU, right? So I mean, that falls out from the fact that you disable interrupts. So a thread and a CPU basically mean the same thing, because if you disable the interrupt, the thread is now stuck to that CPU, right? It cannot now move anywhere. So now the lock is not really, you can say that the lock is actually for the CPU and not for the thread. On the other hand, if you didn't disable interrupts, the lock should have been per thread. Because if the thread gets switched out and goes to another CPU, then that thread is holding the lock, not the CPU that's holding the lock, right? But because you have disabled interrupts, now the thread is stuck to that CPU. So you can call it a per-CPU lock instead of calling it a per-thread lock, right? But yeah, so both of these are sort of interrelated. But I guess the point is that if you didn't care about atomicity with respect to the interrupt handler, you didn't have to do push-fly, right? Okay. So that's a quire. So let's look at the other things. So of course, you know, this loop we are very much familiar with, just, you know, trying to atomically set it to 1. And if it's not, if it's not, if it doesn't find it to be 0, it just keeps spinning, right? That's a spin loop. We know this. And then it just says, you know, just sets the CPU variable to that I'm holding this lock, basically. Is it okay to put LK.CPU above while loop? Firstly, until and unless you have acquired it, you should not. Secondly, you know, there can be racing accesses to CPU, right? Because this while loop is protecting, so you can be sure that only one thread or one CPU is within this region. But if you put this above it, then, you know, there's a race condition on the CPU field of the lock. Right? So because you put it after while, you can be sure that there's no race here. Okay? And then let's look at release, the release function. And once again, there's this debugging aid, which says if not holding lock, then, you know, in panic that you're trying to release a lock that you're not holding, that's fine. And you set CPU to 0. And then you exchange lock with 0. So once again, why do I need an exchange? So I could have just said lock.lock, LK.lock is equal to 0. But instead, the programmer chooses to use the exchange instruction to do this, right? Because, because, so yeah, so that there's a fence, there's a barrier between, you know, so that this neither the hardware nor the compiler is able to reorder these instructions in any way. Right? Because these instructions are serialized with respect to each other. In other words, in other words, exchange instruction acts as an implicit fence or barrier. Right? So the exchange instruction acts as a barrier. So these instructions cannot get reordered with other instructions because of the exchange instruction. If you had just written LK.lock is equal to 0, the hardware was free at runtime to just reorder these instructions. Right? As we have discussed before. All right. Now is it okay to put LK.cpu after exchange LK.lock? I mean, is it all possible? Is it okay to swap these two instructions, these two statements, 1508 and 1519? No, because? Because there will be race conditions on this statement, right? As soon as you release the lock, other people can now, well, other people can now access the CPU variable. Because another thread could have taken the lock and now it can, it may be trying to write to the lock. And here you are trying to write to the lock. So there are two concurrent accesses to the CPU variable. And so now there are two concurrent accesses to the CPU variable. So you know, quite obviously and smartly, I'm just, the programmer is just using the same lock field to also protect the internal structures of the lock, internal fields of the lock variable itself. Apart from the critical section, the fields itself are being protected by this lock field. All right. Okay. Now let's look at, now let's look at sleep and wake up, all right, xv6, sleep and wake up. This is just, you know, you can call it, you can call it wait and notify. These are just, this is just an incarnation of a condition variable and let's see how they are used. So sleep, the implementations are on sheet 25 of sleep and wake up, sheet 25 and 26. And let's see what, what's the idea behind sleep and wake up. So you have a function called sleep. Let's look at the signatures of the functions. So there's a function called sleep that takes an argument void star channel, let's discuss what the channel is, and struct lock star mutix. And then there's wake up. Wake up just says void star channel. This is very similar to, you know, wait, except that instead of a condition variable, I'm using this pointer called void star channel, right? Instead of saying struct cv star cv, I'm saying void star channel. And similarly here, I'm saying void star channel, right? Apart from it, the semantics are exactly identical. Sleep is going to start waiting on the channel and release the lock, release the mutix atomically. And wake up is going to wake up all the threads that are waiting on the channel, right? Identical semantics. Now question is, how can I just say void star channel? Why don't I need a struct cv here? Recall that unlike locks and semaphores, the condition variables are a stateless abstraction. You don't need any state inside the condition variable. You don't have any field called locked or anything of that sort or a counter or anything. So it's a completely stateless abstraction. So you don't even actually need to have a variable specifically. All you need to say is that there is some number that I'm going to sleep on, right? That number in our condition variable example was the address of that condition variable. Instead of actually wasting memory or using memory to declare that condition variable, you can just say I'm going to sleep on some channel, some number. That number may be tied to the logic of your program. You don't need to... So earlier I was declaring a condition variable for the logic. For example, I had not full and not empty. I'm saying I don't need to declare these variables because these variables don't have any state anyway. So why am I wasting some memory maybe? Instead of doing that, let's just use some channel, which is just a number, right? So condition variable was also just being used as a number, as an address. So why don't we just use it as an address? Okay. So let's see. I mean, at a high level, what does sleep do? Sleep is going to... It takes two arguments. I'm just going to say... Let's say whoever... Whichever process calls sleep, it's going to say kerprock.channel is equal to channel and kerprock.state is going to do sleeping, freeze the lock, and then it will call the scheduler so that somebody else can get to run now. So it's made its own state as sleeping, and now when it runs the scheduler, the scheduler is not going to schedule this process because this process's state has become sleeping. So I'm just trying to develop the implementation of sleep, how it would be implemented under the covers. We have discussed the semantics of condition variables already. All right. Now let's look at wakeup. And this whole process has to be atomic, right? What does atomic mean? Well, no other process should be able to inspect kerprock while I'm doing all this, right? For example, if somebody calls wakeup, then he shouldn't be able to inspect kerprock while I was sort of in the middle of doing sleep, right? So how I'm going to make it atomic, let's defer the discussion, but let's just say this is atomic. And then let's see how wakeup is implemented. Wakeup is just this. It'll just, for each talk, for each P in the proc table, I have a global list of all the PCBs or processes. If P.channel is equal to channel and P.state equal to sleeping, then do what? P.state is equal to runnable, right? That's my implementation of wakeup. Okay. So don't we change P arrow channel? It doesn't matter. I mean, channel is only valid if the state was sleeping. If the state is runnable, then there's no, I mean, channel is meaningless. Do I set all the processes to be runnable or only one? All, right? That's the semantics of wakeup or notify that all the processes are going to wake up. That's the semantics that we have discussed. There are different semantics in literature, but you know, the semantics that we are working with are that wakeup is going to wake up all the cells. Okay. Once again, this whole thing needs to be atomic. What does it mean for this whole thing to need to be atomic? While I am doing this check, no other process should be able to read or write the struct proc structure, right? This proc table should be sort of exclusive to me, right? Or for example, this one is also touching, Kerr proc is also part of the proc table, right? Kerr proc is just a pointer inside your proc table. So even this should be atomic with respect to that, right? So in other words, you know, it shouldn't happen that in the middle of, while I'm in the middle of this, this code gets to run, right? So sleep and wakeup need to be atomic with respect to each other. How do you ensure atomicity? By lock, right? So what do you think is the easiest option here? Just have a lock for the entire P table, right? Good enough. So just have a lock for the entire P table, have acquired P table here and release P table somewhere here. Acquire P table, release P table, acquire P table, when I say acquire P table, I'm really saying acquire P table dot lock, right? And then release P table. Is this correct? Is there a problem of deadlocks? And there will be a problem of deadlocks. Firstly, if the lock that we are trying to acquire is a P table lock, then you know, the same thread, so if this argument is also equal to P table lock, then there is a problem. So firstly, I need to handle this special case, because I'm inside the kernel, it's possible that somebody wants to sleep and the mutex that's protecting that critical section is actually the P table lock itself. So I could just say, if lock is not equal to P table lock, then acquire P table lock, right? Let me write it clearly. If lock is not equal to P table dot lock, acquire table dot lock. Similarly, when I release the lock here, I don't need to do two releases, I just need to do one release if lock was equal to P table dot lock. Is this okay? Am I safe now? Interrupt handlers also acquire P table lock. Is that a problem? No, because we know the acquire function will disable interrupt completely. So if I'm within this region, I can be sure that interrupts are disabled. So no interrupt handler will get to run. So that's the whole idea why we add push fly inside acquire, right? Don't we need to worry about one more thing to ensure that there are no deadlocks? Yes? Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Wake up,어 wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Wake up Erfolg! Sleep is going to acquire ptable.lock. So now you have two locks. And whenever you hold, there's any point you can hold two locks, you have to worry about the order. Otherwise, there can be a deadlock. Right? So this is, this is a, this is a real example of, you know, why locking kills modularity. You have to worry about these things. Okay? So, so, so, so the, the convention in the, in the operating system is that ptable.lock will always be the lowest lock. That will never be taken. So the ptable has the least priority. In some sense, right? So it will always be the last lock that's ever taken. So if you make that assumption, then this code is correct. Right? But that assumption has to be obeyed by all other parts of the code. That you will never acquire another lock after you hold the ptable.lock. So ptable.lock will always be the innermost lock, in other words. Right? You have to have this global invariant across your code, basically. Okay? Let's look at, so this is, you know, I've sketched the implementation, but let's look at the real implementation on sheet 25. So this is sleep on channel and spin lock lock, right? And once again, there are, there are these debugging aids that the current process should have, should not be zero. Proc is a global variable, which is indicating what the current process that's running on the CPU, it's a per CPU variable. If LK is equal to zero, the lock shouldn't be equal to null. I shouldn't be sleeping without a lock. So lock shouldn't be equal to null. These are just debugging aids. You can ignore it. Here is a check. If lock is not equal to ptable.lock, acquire ptable.lock and release the real lock. Lock that was used to call it. It's happening. So what did I have? I had something different. I said if lock, I said if lock is not equal to ptable.lock, acquire ptable.lock. Else, don't acquire ptable.lock. You know, you already have ptable. Here, he's saying if lock is not equal to ptable.lock, acquire ptable.lock. That's the same, but he's also releasing the lock here. In my code, I said, you know, I was releasing the lock here. Does it matter if I release the lock here as opposed to releasing the lock here? So I, I was releasing the lock here. He's releasing the lock here. Doesn't matter. Doesn't matter because, you know, you already held ptable.lock. So now you have created mutual exclusion between, you know, between the data. So the data that you're going to access is mutually exclusive because, so, so this area is mutually exclusive because of ptable.lock. Because all you're doing is accessing the proc structure and assuming that you hold invariant, that whenever you touch the proc structure, you hold the ptable.lock. This area is anyways, this area is anyways protected from race condition. So you don't really need to hold the lock for all that long. You could have held it, but you know, it's better. It's also okay to just release it. Apriori. So let's say I have released the lock here and I'm somewhere here. Let's say another thread calls wakeup at this point. What will happen? Another thread calls wakeup. So wakeup will try to acquire the ptable.lock and will not get it, right? It will wait for this whole thing to complete. The scheduler to get called. The scheduler recall is going to cause the ptable.lock to get released. Whoever gets to run next is going to release the ptable.lock. Recall that the scheduler's invariant was that whoever calls the scheduler should have held the ptable.lock and then called the scheduler and the scheduler is going to schedule somebody and that somebody is going to release the lock for you. So this was sort of a very, very different kind of a structure where one thread acquires the lock and another thread releases the lock. Right? So this was a different pattern and so that's fine. The ptable.lock will be released at this point. And but you know, you have ensured mutual exclusion with respect to the wakeup function. Yes, question. If we were after Okay. Yes. So if we had another acquisition of a lock here, then it would be much more prudent to release the lock as soon as possible so that you don't have more ordering dependencies. Right? Because if you have another acquire here, then you know, you would have had to add have an ordering dependency between the LK that you have as an argument and this particular lock also, but you know, yeah, but you don't have any acquisition. That's true. Okay, and let's look at the wakeup function. Here's the wakeup function. The first thing it does is acquire ptable.lock calls this helper function called wakeup1 and releases the ptable.lock. Right? And what is wakeup1 doing? Let's see. Wakeup1 is just above it. Wakeup1 is just iterating over the ptable and checking if state is equal to sleeping and channel is equal to chan, then state is equal to running. So this whole logic is being called with ptable.lock held. Okay. So we understand how how sleep and wakeup can be implemented under the covers and recall that, you know, in doing this, we have made sure that the sleep is not just going to sleep, putting the process to sleep in sleeping state, but also releasing the lock and it's doing it in an atomic fashion in the sense that no other process can see the state of a process within this whole thing. And the the construct that's providing you this atomicity is what? Ptable.lock. Right? So ptable.lock is ensuring that there's atomicity in going to sleep and releasing the lock. All right. All right. So let's look at how sleep and wakeup are used inside the xv6 kernel. All right. So we have seen before we have seen before this the system calls called exit and wait. Right? A discussion on Unix system calls and also in your in your lab. You may have come across exit and wait. What are the semantics of exit and wait? Let's just revise that. So let's say this is a process that calls exit and here's a parent process. So parent child. So if a parent calls wait then the wait will never return till one of its children exits. Right? So the semantics of wait is that it's going to wait till one of the children have exited. So the dependency is that you know, you will come out of it only after this has called exit. So how does how will an OS implement let's say something of this sort. So what are the semantics that I have to put myself to sleeping state till some of one of my children exits and so he will put me in the runnable state. Right? One way to do this is using condition variables or using sleep wake up. The idea is wait internally will call sleep. It will check a condition. The condition is has a you know, do I have any children and if so are they running and if so I'll start sleeping on some some channel and then exit should call wake up on that particular channel. So that if there was a parent sleeping on that channel, then he will wake up and then he can he can actually come out of the wait. No, so the signals is just an abstraction at the process level. Right? In either case you this is I'm talking about inside the kernel. I'm not talking about at the user level. So inside the kernel, you know, let's say one process has called wait. It's a big exit weight is completely independent of the six child. Six child was there. If the parent hasn't called wait and yet you want to basically inform the parent that I have, you know, my child has your child has basically exited. So, I mean you Unix has both exit rate and six I know signal mechanism. So I'm right now talking about exit rate, right? So how is exit rate implemented even signal signals will require some kind of synchronization. It may not require sleep and wake up necessarily, but it requires some kind of synchronization which will be very similar. Basically, but let's I mean, this is a simpler thing to worry about signals is more complicated to implement. Right? And actually actually it doesn't support signals at all. In any case, I mean even Unix or Linux or whatever will have exit rate without any six child or anything, right? So if a parent is waiting then and a process exists, then it's going to wake up the parent so that it comes out of it. Okay, so and and I'm saying that you know, the waiting can be implemented using sleep. And and telling the parent that I have exited can be implemented using wake up. I can use what's the lock? What's the mutex I should use here? Inside my sleep and wake up if I want to do it. One good mutex to use is p table dot lock, right? After all, I'm putting myself to sleep which basically you know, I could I could potentially use p table dot lock and so let's say, you know, that's easy. I can use p table dot log. I need any mutex that's going to ensure that you know anything that's going to it's going to give me mutual exclusion with respect to accesses to my proc structure. So one log that gives you mutual exclusion with respect to accesses to your proc structure is basically p table dot log. So that's easy. No, that's just the mutex that is for the mutex right? Now the question is what's the channel? What's the channel I should use? Process ID of parent. Great. I can say, you know, I can say parents process ID. Let's say does that make sense? Why does this channel make sense? Let's say I have 10 children. All of them are going to call wake up on one process ID of parent, right? So that's the page that the channel that I'm sleeping on right? And and so I actually make sense because PID of parent is basically right, you know, so assuming that your convention is that you're going to use PID of parent only for this exit weight business. Then, you know, another person's child cannot wake you right? So one a process cannot be vacant by another processes child. You will only be woke up woken up by your own children. Right? If you use this convention, what if you used some, you know, instead of using PID of parent, let's say I just used one constant number one. So I'm always going to sleep on identifier on this constant called one. Any process that exit is going to call wake up on all the processes that are waiting is is that a correctness problem? That may not be a correctness problem because you recall that usually you would you know, when you come out of sleep, you check the condition again. And so what will happen is if you are sleeping on some global channel, that's shared across all the processes. Then, you know, you will wake up all these other processes, but all these processes, if you have written your code correctly again, going to check the condition and everybody except your own parent is going to find the condition to be false. And so all of them are going to go back to sleep. Your parent is going to come out. It's wasteful. It's not it's not incorrect. Right? So choosing the channel identifier is just a matter of you know, figuring out what are you know, what are my what are my communication patterns? And then figuring out the channels, the the identifier that's common to these two to the pattern. So in this case, it's a parent ID. But if you use something which was more coarse-grained, right? Like I took the exam, extreme example of a global identifier called one. Assuming you have your enclosed your sleep loop with a while condition and a check, that's still correct. But it's wasteful. Okay. All right, good. So let's look at the exit and wait implementations. The real ones on sheet 23 and 24. That's your exit function. This function will be called. If you if a process makes the exit system call and well, it just says, you know, here's some debugging aid. The first process the init proc should not get ever exit. So that's just a debugging it. Close all the open files. Right? We have seen this every process has a file every table file table and xv6 also implements these unique semantics. And so if a process is exiting just close all the files. So we are that's fine. That's easy. Also, you know, this is some so the process that was open that that was currently running its current working directory that CWD is also sort of in the file system know that this process is accessing this particular directory. So that files is so nobody can actually delete that directory from under its feet. So for that reason, you know, there is there's a way to lock that directory and we're going to discuss this when we discuss by system. So it's basically unlocking that directly saying that I'm going to exit so I can unlock that directory. If some other process wants to delete that directory is free to do that. Okay. I set my CWD to 0 current working directory. And now is my logic to do implement exit to do exit weight synchronization. So I do acquire p table or lock and I wake up on proc dot parent. So instead of the PID of the parent, I'm using the pointer of the PC. Yeah. So here I'm actually using the PID says the product parent actually the PID of actually the pointer to the proc structure of the parent, right? So instead of using the PID just use the pointer in the proc structure. That's equally good, right? There's a one-to-one corresponding PID and the proc structure the product parent. You just wake it up. Notice that I'm not calling wake up. I'm calling wake up one because I already have the p table lock. Here's another example by lock skill modularity. I do worry about which function will acquire the lock and which will not acquire the log and what locks I already have. So it's so I'll just wake up the proc dot parent and just fall through and if I have any children, then so what then I just iterate over the proc table. Notice that I have the p table lock. So I can safely assume that these accesses are atomic. So p table dot proc do p. So look at all the processes. If I am the parent of that process, right? Which means that this process is my child then then do what? I'm going to you know, I'm going to exit. So basically he's going to know the orphaned process has to be connected to the init process recall that this is something this sort of semantics that we discussed that if the parent exits then all its children are connected to the init proc and init proc is going to call wait so that there are no zombies remaining and if p dot state is equal to zombie then wake up init proc. What's happening here? Right? So init proc is probably already called is already in the wait loop, right? So init proc is just constantly calling wait just to collect all these sort of zombie processes and now here was so now I was a process and I had a child process. I forgot to call wait on the child process. So that child process is just languishing as a zombie there right now. I'm going to I'm exiting. So what I can do is all my zombie processes. If I see any zombie process, I can tell the init proc to wake up because I have attached a zombie process to him. So now his wake, you know, wait is going to return. So that's what I'm doing. So I'm breaking up the init proc so that his weight returns if he is inside the wait. This is to wait to ensure that your parent returns so a process that exiting you're making sure that your parent in return from a weight. This is to make sure that init proc returns from the wait if any if it is inside wait because it's just attached a zombie process to the init proc and then you make your state as zombie right notice that I have not cleaned up my virtual memory. I have not cleaned up my case stack. I not be allocated my virtual memory. My page table still remains all the data that I have. I have not freed it. Right? I have just marked my state as zombie and call the scheduler. What's going to happen? Is that the my parent process when going to run is going to call wait and that's going to a deallocate my page table and my case stack. Why can't I just deallocate my page table here? Because I'm standing on that page table, right? That's the page table that currently loaded loaded. This exit function is being called in the context of the process that's currently running. And so I can't just deallocate the page table because that page table is actually the one that's loaded into the hardware right now. Now you you only change your state to zombie and now when the other process gets loaded now that you know now you are off the CPU and now you can be deallocated similarly case stack cannot be deallocated because this entire function is executing off that case stack. You can't just deallocate the case stack. It's a parent who will deallocate this case stack. You can deallocate the user side of the page table. That's an optimization and you know, a real operating system will perhaps do that. But you know, actually they just make it simpler and say the parent will deallocate everything. Okay. Right. So so the question is instead of waiting for the parent to deallocate the stack. Is it possible to just you know on every context which check if my previous process has become zombie and if you know on the context switch as soon as you context switch if you have figured out that the previous process that just got context which doubt has become zombie then you can just deallocate its structure, but you know some only some of its structure you still have to maintain its cross structure because the parent may call wait you have to for example store the exit status return value exit code. Right? So those are all possibilities, but you know that there's a trade-off in doing that on every context which you're going to check whether the previous process context which process has become zombie or not that that itself has a cost some cost to it, you know whether it's a it's a worthwhile thing to do or not is a it's something that has that's basically a design decision. Okay, let's look at wait. So here's wait. I just go through my so firstly I acquired a p-table lock once again what wait going to do it's going to go through the entire p-table and will check if I am the parent of this particular process and if it is zombie then I can just return I called wait on something that has already exited so I can just return right because it is already zombie so I can just return from there. So I just sort of go through the p-table if if I am not the parent of that proc of that p then continue otherwise I am the parent I just check if it is if it is a zombie I found a zombie my way doesn't need to sleep my way it can just return so I found one I can just free all its things so I can free its case back I can free its page directory I can set its state to unused right and I am doing this under the protection of p-table lock recall and I just release the p-table lock and I return the process ID of the process that I just released right that's the one that was zombie so return the PID I mean you do you need to set it to 0 because you have set it to unused I mean those small things can be can be done I am not sure you know what other parts of the code are relying on you know how what invariants they maintain but you could do that all right now if I don't have kids right which means I don't have any children and I called wait I don't need to wait for anything right because I don't have any children so and I am calling wait so I just return with a minus one status that's all right and then there is this field called proc.kill I am going to discuss this next time let's wait on that but at this point I know that I have some children this process has some children and none of I have some children that are not yet zombie so what do I have to do I have to wait for them to become zombie so I just sleep on proc and this is the ptable.log that's protecting that that's basically exit wait so now this process has become will go into a sleeping state as soon as somebody exits he is going to call wake up and the channel is going to be his parent I slept on my own ID right he is going to wake up on his parent's ID so that's how the synchronization happens okay all right let's stop here and I am going to discuss the kill system call and how the killing system call is implemented using using these mechanisms and how the IDE device how a disk device driver uses synchronization and how a device driver works internally to do this thing and also we are going to discuss virtual memory and we are going to start the topic of virtual memory and paging in the next lecture"}
{"text":"Okay, all right. So, welcome to operating systems lecture 22. All right. So, last time we were discussing locks. And just to revise, locks is an abstraction. The abstraction has a type called strut lock. So, you can declare any variable of this type, strut lock. And this type has two functions, acquire and release, right. And the semantics of acquire and release are that the lock can only be acquired once at any time. If two calls to the acquire function are made before any release, then if two simultaneous calls to acquire are made or two calls are made without a release, then one of them will not be able to acquire and only the other one will be. So, if two threads try to acquire the same lock, one thread will be able to acquire it and the other will have to wait. And the other will have to wait till the first thread calls release, right. So, that's the semantics of a lock. And we also saw last time how a lock can potentially be implemented. Basically, we use some sort of hardware support for an atomic instruction. In the case of x86, we are using the exchange instruction to implement the lock, right. We also saw there were two ways to implement the lock. You could either spin wait or you could either block, right. Spinning is useful if you have a multiprocessor and you know your critical sections are small. So, you know, spinning may be the better option to do. But if you are on a uniprocessor or if your critical sections are large, then blocking may be a more efficient thing to do, right. Because after all, blocking is not free. Blocking involves executing many instructions also. And if spinning is going to finish very soon, then maybe spinning is better, right. And then we were looking at this example of a list. And we said, look, let's say there's a list, there's a shared list L. And there's a function called insert that's going to insert this data element into this L. And here's this code which is just going to, you know, allocate a new list element and initialize its data and its next pointer and update the list, right. And if multiple sets are doing this simultaneously, there's a problem. Because this area, this is statement A and this is statement B. These are, these need to be atomic, executed atomically, right. So, if two threads are executing these and the, and the execution interleave on these two instructions, then very bad things can happen. And we saw some bad things that can happen. And so, of course, locks are meant to solve these kind of problems. And what you're going to do is you're going to put an acquire call here and a release call here, right. And because a lock cannot be acquired twice simultaneously, only one thread can be active in this particular region, right. So, this region is also called a critical section. And the lock, and this act of actually using locks to ensure that the thread, only one thread is active in the critical section is also called mutual exclusion. So, locks are a way to ensure mutual exclusion. And in fact, the locks themselves, another name for a lock, because of this word, is basically mutex. So, a lock is also called a mutex in many, in many scenarios. The other thing is, you know, you can actually, because, you know, you can actually choose your lock variables. So, firstly, if you want to have mutual exclusion between multiple threads, does the lock need to be visible to both the threads? Yes, right. So, can the lock be a local variable here? Of course not, right, because local variable is only thread private. So, it has to be a global variable, clearly. But even if it's a global variable, you know, you have a choice. You can either have a single, you know, you can have a global lock, let's say struct lock, glock, global lock, and you can use acquire glock and release glock. So, you can do that. This is perfectly correct code, except that, you know, you're using one lock for all these insert operations. So, if there are multiple lists and you're doing, multiple threads are doing inserts on different lists simultaneously, they will become, these operations will become mutually exclusive. So, even though there are multiple lists, they didn't need to be mutually exclusive. Because you're using a global lock, you have made them mutually exclusive. And so, this is called coarse-grained locking. So, you're taking locks at a very coarse granularity. You're basically saying, oh, these are all the lists and I have one lock for all the lists, right? So, irrespective of which list I am on, you're going to take the same lock and you're serializing accesses to all the lists, which is an over, you know, overkill. You don't really need all that. So, what's a better option? Have a lock per list, right? So, we discussed this last time. So, we can have a lock per list instead of a glock. Let's say I have a, I have a lock variable inside the structure itself and I can just basically take that. And this is finer-grained locking. In general, coarse-grained locking is easier to get correct, but it's less performant. Finer-grained locking is a little harder to reason about, but it has potentially more performance, more confidence. So, let's take some more examples to understand this tradeoff between coarse-grained locking and finer-grained locking, all right? So, let's take this code and let's say, you know, let's say I am a bank and I'm holding these accounts. So, you know, let's say I define this type called struct account and let's say each account has an account ID or account number and it, how much money there is in the account, right? And let's say, you know, I define some number, let's say it's 100 and I have these accounts and let's say this account is also, so accounts are declared as this global array. So, these are accounts that I'm holding and each account is having some money and I'm a bank and I want to provide this service to my customers called transfer, right? So, I should be able to avoid transfer, account A to account B. I'm omitting some syntax here and let's say what it's going to do is if A dot money greater than 0, then A dot money minus minus B dot money plus plus and that's it. So, and let's say, let me just write this in a different slide. So, you know, let's say I want to provide this transfer functionality that's going to money from one account to another, okay? Let's, let me rewrite this on a new slide, a new slide because it's a little, I'm running out of space here and let's also say that this transfer can either succeed or fail. So, let's say this is a bold transfer. Source to destination, let me also rename the variable so that it's clearer and say if source dot money is greater than 0, nation dot money. Let's say I return true. So, the intent of the transfer function is to transfer let's say one unit of money from the source account to the destination account and it can only transfer if the money was actually non-negative, right? Or actually positive and otherwise it just returns false. Let's say this is my transfer function. Now, clearly, I mean, so assume that this function is correct if you're running it in a single thread, but if multiple threads are running this code, then bad things can happen. What are some bad things that can happen? Okay. So, one bad thing that can happen is let's say initially an account, the source account had one rupee or one unit of money in it. So, two threads come in. They both check that the money is greater than 0 because it's 1 and they both try to decrement it and at the end of the day what you'll have is that one account, the account will have actually money equal to minus 1, right? And the two people would have been paid and it doesn't make sense because money shouldn't be less than 0, right? So, you're dealing with a non-negative number here. So, there's a race condition here. So, what's happening is between the check and the update, there's a race condition, right? What you would have wanted is that the check and the update are atomic, which means you would want to use some kind of a lock here, right? The other thing that can, of course, happen is these statements themselves are not atomic, right? So, minus, minus and plus, plus involves at least two or three instructions because they're going to read it into a register, two or three operations, read it into a register, increment it and then write it. And we have seen this before that if these instructions that interleave bad things can happen. Recall the hits variable in the web server that we discussed before, right? So, you know, there are these problems with this, okay? So, what will you do? You'll use a lock, of course. And let's say one way to use a lock is I define lock, struct lock, G lock. Once again, it's a global lock. And I just say acquire lock and release G lock, right? Do I need, is this, is this okay or do I need to do something else? One more, yeah. So, I need to put a release G lock here. I need to make sure that along all the parts of my program, the lock is actually released before I exit the function, right? Of course. All right. So, this is fine. This code is correct, okay? But is this the best way to do things? Well, no, because let's say, you know, I have a hundred accounts. I want to transfer money to you and, you know, another person wants to transfer money to somebody else. You know, both of us will get serialized. So, only one transfer instance can work at any time. It's not a very scalable solution. If you are a bank who is, you know, if this function is running inside a server which is, you know, connected to a hundred ATMs, it's not a very scalable solution. So, what will you do? All right. So, you'll, okay. So, I got two answers. One is put a lock at the source and the destination separately. And the other is put a lock per account, okay? Let's try the first one, first, right? So, clearly, we need to use final gain locks. One lock is not good enough. We want to use more locks so that there's more concurrency, right? So, let's say the first thing I'm going to try to do is I'm going to say lock the source separately, lock the destination separately, right? So, let's say bool transfer. So, let's say I rewrite this code and let's say I have two locks now, right? So, I have struct lock, source lock, and destination lock. Let's say I try to do this, okay? And let's say I say acquire source lock. So, I'm going to say, oh, okay, here I'm accessing the source. So, I'm going to use a different lock to protect all operations on source and I'm going to use a different lock to protect operations on destination. What I'm going to do is I'm going to say acquire source lock and I'm going to say release source lock and let's say acquire, yeah, give me a minute, mission lock, let's say release destination lock, right? And what do I need to do here? Release source lock, right? Okay. So, let's say I do this. So, what have I done? I made sure that all operations which are of this nature, which is between source and source itself, you are making them atomic and these operations are atomic, all right? Okay. So, what are some things that cannot happen? It's not possible that there's a condition within the statement. It's also not possible that you check and, you know, so these two statements cannot be concurrent with these two statements themselves. But is this correct? No, why? Okay. So, here's one answer. He's saying that, look, you know, it's possible at this point, there's no lock held, right? So, what can happen is at this point, you have released the source lock. So, you know, let's say I'm transferring money to you. My lock has been released. I'm about to take your lock. But let's say there's another thread which is just checking the total amount of money in the bank. At this point, you will see, you know, the bank has one unit of money less, right? That's not a, and that may violate some invariance, okay? So, yeah, that's a valid point, you know, because if there's a thread which is checking how much total money there is, you know, this transfer operation is not atomic anymore. The whole transfer operation is not atomic anymore because, you know, there's a point where somebody can observe the state of the bank and you'll see an inconsistent state, right? Okay, so, agreed, transfer is not atomic. Is there anything else that's wrong with this? So, let's just talk about it. Let's just say there's a transfer in the system. So, what if, you know, I want, you know, there's a thread. So, I want to, one thread is trying to transfer money from me to you, and there's another thread that's trying to transfer money from you to your friend, right? So, one thread has me as a source, and another thread has, and you as a destination, and another thread has you as the source, right? So, one thread has you as the destination, and another thread has you as a source. So, what can happen? One of the threads could be operating on your account at this point, and another thread could be operating on your account at this point. This is a greater, is this a, I mean, do you see a correctness problem? Yes, because there's a race condition between one thread here, and another thread here, and the race condition exists because you're using different locks, right? So, both threads are holding some lock, but they're not holding the same lock, and so they can concurrently be accessing different, you know, concurrently accessing the same data, however, right? So, the problem is, if one thread says transfer A to B, and another thread says transfer B to C, here B is the destination, and here B is the source, right? And this code does not ensure mutual exclusion between this code and this code, right? And so, there's a problem. You wanted to also ensure mutual exclusion between this code and this code, right? If it is possible for these accounts to be the same, right? So, the problem really occurred because I was trying to have a lock per argument, and the arguments could alias, right? So, it's possible that one person's argument is another, one person's source argument is another person's destination argument. So, the better thing is probably to have a lock per account, right? Okay. So, let's see. Let's rewrite this. So, let me just rewrite this, okay? And now, okay. So, now, what I'm going to do here is I'm going to say acquire source dot lock. So, I now have an account, a lock per account, right? So, the other thing I have done here is in the structure account, I have another field called struct lock. And so, I'm going to say acquire source dot lock. Where do I release it? So, clearly, you know, I could, all right. So, I could release it here. I couldn't release it here. I could release it here, or I could release it here. I need to acquire another lock, right? I need to acquire the destination lock. Where should I acquire it? Okay. So, one answer is acquire both of them here, and release both of them here, and release both of them here, right? So, acquire everything in the beginning, and release everything at the end just before exiting. And so, now, somebody says, oh, that's a bad thing, because, you know, it seems it may be correct, but it's not the best that you can do, right? Okay. All right. So, there are many options. I mean, the small code, you can see there are, you know, many different sort of options, and it's a little confusing. But one thing you can do is you can acquire the source lock here. You can release the source lock. Then you can acquire the destination lock. Then release the destination lock. And then release the source lock here, right? So, acquire, release, acquire, release. This has a problem that the transfer is no longer atomic, right? Because you have released the source lock. Then you acquire the destination lock. In the middle, if somebody observes the state, he will see an inconsistent overall state. You know, you may or may not care about atomicity of the whole transfer function, right? Sometimes you care about the atomicity of the whole operation. Sometimes you don't care about the atomicity of the transfer function. If the only service that the bank is providing is transfer, perhaps you don't care about the atomicity, right? How does it matter if for some time, somebody sees one rupee less in the account, right? At the end of the day, probably I'm going to see everything correct, right? But of course, you know, typically you won't want something like transfer to be atomic because, you know, there will be some, let's say, you know, some thread, which is, let's say, the sum thread, which will just sum all the accounts. And that may be running in parallel. And so you may care about the atomicity. So the second option is that you, let's say you care about the atomicity of transfer. So the second option was suggested was that you acquire source lock. But then before you release the source lock, you acquire the destination lock. Then you acquire the source lock. Then you release the source lock. And then you release the destination lock. So so here's the here's the suggestion. You leave. Sorry, you acquire. Let me just shortcut it, shorthand it. So you acquire destination. You release source and then you release destination. What do you do here? Release, right? Notice that our code has become slightly, slightly tricky because at this point, I have acquired one lock and I'm trying to acquire another lock, right? And I have to do that because this operation, which involves accessing multiple sort of accounts, needs to have both for atomicity. I need to hold at least hold on to at least one lock. I cannot just leave both locks. All right. OK. All right. So. So let's see what can happen. Yeah. OK, so. So if the source and destination are same, then you can see a problem. You know, you acquire the same lock and you try to acquire the same lock. And what happens? The thread deadlocks. It will never be able to acquire the same lock twice. That's the structure of the lock. The same thread falls acquired twice. It just deadlocks. It will never be able to proceed. OK, so that's you know, you may say, oh, that's you know, that that you can check. You can just say if source is not equal to this, then do this. Otherwise, you don't do anything. Right. So that's a very interesting observation. But let's just take this observation a little further. Let's say one thread is transferring account from me to you and another thread is transferring account from you to me. Right. So what will happen? The first. So let me just write it before I discuss. Let's say this is doing transfer A to B and this is going transfer B to A. Right. What will happen? The first thread will acquire A's lock and it will try and it may be somewhere here. And it's possible that the second thread runs simultaneously and it acquires B's lock. Right. Now the first thread will try to acquire B's lock and it will wait for the second thread to release B's lock. And the second thread will try to acquire A's lock and it will wait for the first thread to release A's lock. What do you have? Deadlock. Because the first thread has acquired A's lock and is waiting for B's lock to get free. The second thread has acquired B's lock and is waiting for A's lock to get free. Both the threads are waiting for the other thread to release the lock. But they will never be able to, none of the threads will be able to release any lock because they are both stuck at an acquire. Right. And so you have a deadlock. So this is a big problem with fine-grained locking. You have, you know, recall that coarse-grained locking had no such problem. You just had one big lock. You know, but now because you, now you, what you did was you somehow said, okay, you know, maybe per-account locks are better. So you had per-account locks. Then you had some operations which involved multiple accounts. So when you have multiple accounts, you need to take multiple locks at the same time. When you have to take multiple locks at the same time, then you have these problems of cyclic dependency. Right. There's a cyclic dependency because there's a cycle because I'm holding one lock and I'm trying to, waiting for another lock. And that guy's holding the lock that I'm waiting for. And he's waiting for my, the lock I'm holding. So there's a cyclic dependency in the, in the lock acquisition order. All right. Okay. So how do you solve something like this? So clearly this code is not correct. It is, it is okay from a data race freedom standpoint. So there are no races in this code. Transfer function appears atomic, but it has a problem that the function can actually deadlock. The system can actually deadlock. So what's the solution? The solution that's typically taken in an operating system. And so these, the deadlock is a very common problem seen in many different kinds of scenarios. But in an operating system, the typical solution to this kind of a problem is to have an order on the acquisition of locks. So you always say that if you ever have to do an operation which involves multiple entities, and which involves taking multiple locks, then you will take those locks in a certain order. Right? So one option is that you say that I'm going to take, so you, and that order can be completely, you know, arbitrary. You can decide whatever order you want. But assuming that all, if you're, if you're taking multiple locks and you're taking them in a certain order, then there'll never be a cyclic dependency. Right? So let's say one thread is transferring money from you to, me to you, and another thread is transferring money from you to me. Then in both threads, there will be an order. Right? Depending on what the order is, either my lock will be taken before you, or your lock will be taken before me. But it will never happen that one thread is taking my lock before you, and another thread is taking your lock before me. Right? So let's say I order it on account ID. Right? So if I order it on account ID, the correct version of the code may look like something like this. Void transfer source and destination. Let's say, you know, and let's say this is my, this is all my code, which has all returned, you know, somewhere it has a return. So at the end of it, it has a return. Right? So I'm not going to write the whole code, but let's just look at the, look at the locking behavior. So I may want to do something like this. If source.accountID is less than dest.accountID, then fire source.lock, fire destination.lock. Else, what? Acquire destination.lock, and then acquire source.lock. And then, you know, after you have all these locks, you can do whatever you like here. As I, you know, these operations will be atomic with respect to each other. And then at the end of the day, you can say, release. So the release need to have an order? No. Release doesn't need to have an order. Release is just a non-blocking operation. You just say, you know, any order is fine. And then you return. Whatever value you want to return. So this code is correct. It's fine-grained. Each lock, each account has one lock. And so, and you have made sure that any operation that involves multiple accounts and needs to be atomic takes all the locks, all the corresponding locks. And you have made sure that those locks are in a certain global order. Right? So the order needs to be a global order. And all threads respect that global order. Right? So let's say, let's say, let's consider the same situation. Let's say I wanted to transfer money to you. And, you know, in one thread, and then there's another thread that wants to transfer money from you to me. Then in both cases, let's say, you know, my account ID was smaller than yours. Then in both cases, my lock will be taken before yours. So let's say the first thread takes my lock. And then he's about, the second thread will also try to take my lock first. And so it will block right there. Right? So the second lock will not be taken. I mean, so, so there will not be a cyclic dependency. In other words, you know, basically, a deadlock occurred. So let's say each of these, let's say if I were to draw a graph, and each thread, and each node in this graph is equal to a thread. And let's say, let me draw edges in this graph. If I hold, I need a resource, if I can potentially request for a resource that is held by the other thread. Right? So I draw an edge between two nodes, if I can request for a resource that is held by the destination node. So the source thread can request for a resource that is held by the destination thread, I draw an edge. And the deadlock could only occur if let's say, so let's say this could request for this, and let's say this could request for this. The deadlock can only occur if there is a cycle in this graph. What I have made sure is that these edges can only be forward edges, because I have imposed a total order on the resources. So I can never be holding a resource. So let's say these nodes are now resources, right? So the other way to look at it is a node is a resource. And resources, you know, I'm using the word resource for a lock in this case. So I draw an edge from one resource to another resource, if it is possible for me to hold a resource, and then request for the other resource. If it's possible for one thread to hold one resource and request for another resource as an edge, the directed edge from that. So, and a deadlock can occur if there's a cycle in this graph. So in this, in the example in our accounts, a deadlock would occur because it's possible that one thread is holding account x and requesting for account y, and another thread is holding account y and requesting for account x. But if I put a total order on these resources, on these locks, and I say that it's never and I make sure that such backward edges never exist, right? So if I disallow backward edges, it's basically saying then there can never be a cycle. So that's basically why there can never be a deadlock if you completely order all these resources. So make sure that your resources are acquired in a certain global order. You will never have a backward edge in your resource, resource acquisition graph, right? So there'll never be a deadlock. So you can, you know, you can extend this example to three threads, you know, one saying transfer A, B, transfer E, and this one saying transfer A, right? So once again, you know, if you don't have a total order in your locks by account ID, then a deadlock can occur, right? Same thing. I hold account A, wait for account B. The other one holds account B, waits for account C, and the third thread completes the cycle. You hold account C, waits for account A, and all three threads now deadlock, right? But if you have a total order, then there'll be no edge from C to A. There'll only be edges from A to C, right? So if I were to draw the resource acquisition, let's say these are the locks, and this is A's lock, this is B's lock, and this is C's lock. This is possible, and let's say A is less than B is less than C. This is possible, this is possible, but this is not possible. Instead, I made sure I've written my code such that only this is possible. Because I've ordered my locks, I can only have forward edges in my resource, so there can be no deadlocks. Okay. All right. So let's see. So notice that the code that we had come up with was that we'll acquire source lock, then very carefully we will acquire release source lock after we will acquire destination lock, and we'll try to acquire the destination lock as late as possible and all that thing, right? But it looks very nice. It would be nice if we could do this because as you probably thought that it's going to increase concurrency, but in practice it's not possible because you also need to order these locks in a certain way. So basically we came back to the same solution that acquire both the locks in the beginning, right, because you also needed to check the order and then acquire the locks in that way, right? So even though the most concurrent way to do things would have been acquire locks as you need them, but because you had to have a total order on the locks, you couldn't do that. You just had to take all the locks in the beginning, and in fact you had to take those locks in a certain order, right? So let's take another example. Let's say in the same system there's another thread running that's called sum, and let's say this, right, so let's say the sum returns an integer, and it just, what it does is it just goes over all the counts. So for i is equal to zero, i is less than n, i plus plus, sum is equal to sum plus accounts i dot money. Let's say this is my code, and of course this function is also being done by a thread. Concurrently with other threads that may be running the same function sum or that may be running the transfer function, all right, and let's say, you know, I want to make sure that, you know, I want to make sure that the sum stays constant, so the total money in my account and my bank should remain constant. It's just transferring money across each other, and so to make, so clearly if you want that to be true, then the transfer function should have been atomic, and we have made that atomic itself, but can I just write the sum function like this? Would that be okay? No, why? What can happen? The sum function could run concurrently with the transfer thread, and the transfer thread could have decremented some money from some account and may not have incremented the money in some account, and so the sum may be incorrect, right. So what do you need to do? You want to make the sum operation mutually exclusive with the transfer operation, and but, so in a coarse-grained world it would have been very easy. You would have had just one lock, and both the transfer function and the sum function would have taken that lock, and that would have made everything completely mutually exclusive. Now in the fine-grained world, which lock should you take and when? Okay, so one answer is let's take locks for all accounts. Everybody agrees? Okay, so yes, I think we need to take locks of all accounts, because if we miss even one account, then you know our total sum will be wrong. Now where should I take these locks? Should I take the lock on demand around this? If you take the lock around this, then you know you are violating the order. So here's an operation that just is not operating on two accounts, it's operating on n accounts, right, and this operation also needs to be atomic with respect to other threads. So what are you going to do? You're going to take all the locks a priori. Then you're going to do the function, and then you're going to release all the locks after that. You can't take the locks on demand, because you need a certain order on the global order on the locks, right. So what you, so let's talk about, yeah, so let's first look at what we can do. So let's say, so the right thing to do would be for i is equal to zero, i is less than n, i plus plus, acquire accounts i dot lock. This is not correct either, right, because I'm not obeying any order on the lock. I should have really ordered it by, so you know what you'll need to do is let's say you have another array which just sorts the accounts by ID, and so, and that sorted order is what you use here. So you just take the locks in a certain sorted order, and the sorted order is, let's say, in the order of the account ID, ordered by the account ID, and similarly you want to just release it here. Here you don't care about the order, right, and return some. All right, so notice that the array itself is not necessarily sorted by the account ID, right. You just generate a permutation which is the sorted permutation, S, which is, you know, which sorts the accounts by this account ID, and then you basically do that, right, and so you need to take them a priority. Of course, now you may say, oh, but, you know, what, perhaps the better thing would have been that, you know, just arrange your accounts in a certain order, a priori, in the order of the account ID, or allocate the accounts in the order of the account ID, and so that way, you know, you don't need to do this sort operation, and you can probably even take the accounts in, in, on demand, in that case. Yeah, sure. You haven't sorted the accounts. You just, you just got a permutation. So notice that I'm just saying account SI. So S is a permutation, which is a sorted permutation, you know, which, which basically says, what will be the sorted order of these accounts? Okay, yeah, so what you could do is, you could say, you know, account SI here, and so then you can take the, take the, right, you just have to make sure that you always hold on to at least one lock, right? So, okay. Okay, so the question is, can't we just say acquire account I, and release account I right here? Okay, so I see some heads saying no, so why? So basically, you know, let's say there's a transfer going on from account A to account B, and now sum takes a lock on account A, and you know, let's say before the transfer started, and it got the lock, and it will, you know, read some value, then transfer happens, then it tries to get a lock on account B, and then, you know, it gets it, and so it will get a wrong sum. It will probably get, it can even get, you know, something which is bigger than, than your actual amount, right? Okay, so in general, figuring out where to put the loss, how to put the loss, whether to put the loss or not, is, you know, hard. In fact, loss is just one way of ensuring correctness, right? Notice that loss are just, basically what we did, we said, okay, oh, this code is not correct if executed concurrently. Let's make this code mutually exclusive. One way to make things mutually exclusive is locks, and then let's use locks. And then we said, okay, where to put the loss, that itself seems to be a hard problem. In fact, if there are other ways to make sure that the code is correct, which does not involve taking locks, where you can just structure your code in a very nice, very careful way, such that without taking locks, you can actually make sure that code is correct, right? And we're going to discuss some as we go along the course. So in general, ensuring correctness and concurrency is hard. But, and, you know, you would typically want to avoid things that are hard to understand, because they are, you know, not just it's hard to code, but it's hard to maintain over time. Typically, programmers follow a discipline, and that's the locking discipline. And the locking discipline basically says that, firstly, you should think about your system as a whole, and figure out where you want to put the locks, or how do you want to associate the locks? Do you want to associate a lock per account? Do you want to associate a lock per pair of accounts? Do you want to associate a global lock with the whole array of accounts? These are all possibilities, and you can choose one or another. Once you have done that, once you have decided that, then you ensure that for all shared regions, for all regions which can access this shared data, or access the region that is protected by that lock, that lock is always held before executing that region. So if there's any code that can access a shared region, then the lock corresponding to that shared region should be held by that lock. And if there's an operation that needs to touch multiple shared regions, and it needs to be atomic, then locks of all these accounts should be acquired a priori. All these shared regions should be acquired a priori and released after that, and they should be acquired in a certain global order. So this is basically the discipline that if you follow, you will get correctness. It may not be the best way to get correctness, but it's a reasonably good way of getting correctness. So in the example that we saw, there was transfer and there was sum. In transfer also, we did the same thing. We said, oh, we are going to operate on two accounts, so let's take the accounts, let's take the locks for both the accounts a priori, then do the operation, and then release both the locks. Similarly, in the sum operation, we said we have to touch all these shared objects, so let's take locks for all these shared objects a priori, touch all these shared objects, and then release all these shared objects after that. So in both cases, you are just using the locking discipline. Yes. Okay, is eventual consistency tolerable in OS? So what is eventual consistency? So in general, eventual consistency has been something that distributed systems people talk about, where you say that, let's say there are two people who are accessing the same thing. Eventually, it will get consistent, but sometimes you may see inconsistent values, right? So when you're designing a system, you have to worry about what does consistency mean, and what kind of consistency guarantees you need to provide to the user of your system, right? Let's just talk in concrete terms, so those become much more high-level discussions. Let's just talk in concrete terms, and let's look at these examples and see, you know, what we need. So in this case, you know, this is the consistency level you need, and this is how you're going to use it, okay? So since we are talking about a bank, you know, if this sum thread is going to run, the sum thread is going to have to take all the locks, and basically that means that all the transfer threads basically get stopped for that amount of time, right, till the sum gets computed, or in fact, till the other locks get taken. Are there better ways to do that? Yes, there are better ways to do that. In fact, banks are not, bank accounts are not implemented in memory. I'm just using a toy example, right? You would typically implement bank accounts in a database, and database has other ways to do concurrency control, right, because, so let's understand, I'll just give you a brief understanding of why databases, the way the database does the concurrency control is different from how an operating system needs to do concurrency control. A database needs to act, you know, operates on disk blocks, because it also cares about persistence. You know, data should remain across reboots. Disk accesses are much, much slower than memory accesses, right, and so the overhead to do concurrency control is much smaller in a database, and so you can do more fancier things to do concurrency control in database, and typical way of doing concurrency control in database are what's called transactions, right? So we're going to discuss some of this later. So databases do transaction concurrency control in a different way. An operating system cannot do transactions, because, you know, it's too costly to do transactions for memory accesses, right, and in fact, you know, more recently, there are, you know, modern hardware is coming up with what's called transactional memory that allows you to do some of this, and you know, these are all advanced topics that we may have time to cover later. But by and large, today, locks is the way to do concurrency control, and you're right, I mean, if there's something like this, then the sum thread is actually, you know, basically bringing everything else to a halt for that amount of time, but that's basically what the price you'll have to pay anyway. Okay, good, patience, all right, okay, let's stop and continue this discussion next time."}
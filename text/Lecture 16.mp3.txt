{"text":"So, welcome to Operating Systems Lecture 16. So, so far we have been looking at the virtual address space using paging, right? And we saw that when the operating system boots up, it boots up in the physical address space, then it enables segmentation, then it enables the 32-bit mode without paging, in which case still it has the physical address space, it can access the physical address space. And at some point, it enables paging, right? And the first page, when it enables paging for the first time, it enables it using this page directory called entry page there, right? And at the entry page there, you have an address space which looks something like this. From 0 to 4 MB, you are mapped to physical address 0 to 4 MB. And from kern base to kern base plus 4 MB, which, you know, which is starting at the, which is where the kernel is mapped, let's call them these, call these addresses the high addresses. So, at the high addresses, starting at the high, first high address to the 4 MB at high address, they are again mapped to the same. So, the, both these regions are aliased to the same physical memory area, right, in the entry page directory. And we saw that this is a nice way of doing things because this allows you a very smooth transition from a flat, from an address space which only had this much, right? And then, so, the initialization code still runs in this space, assuming that the kernel itself fits within 4 MB. And then at some point, the kernel moves its stack and itself, the instruction pointer, in this space, right? And from then on, it will want to always execute in the high addresses, leaving the low addresses available for the user process, right? So, eventually, you will want to move from the entry page directory, which was just a temporary, temporary thing, to something like this where you have mapped the physical memory in the kernel address space. So, starting from current base to, let's say, the maximum physical address that the kernel supports is fizztop. So, you will map current base to current base plus fizztop here, mapped to the physical address, and the lower addresses will be available for user process, right? So, the user can map its code here, map its data here, and so on. Yes, question? What happens to the entry page directory? Okay. When the kernel page directory is created, what happens to the entry page directory? Somebody wants to answer? Okay. One answer is that only in the entry page that this remains and, you know, the question is does the entry page get deallocated, right, or does it keep consuming the space that it was consuming earlier? Right? After all, entry page is living in physical memory. It is consuming some space, right? Initially I had some use for it, so I moved to entry page there, and I used it for something, and then I have moved to k-page there, and so what happens to the entry page there? Do I deallocate that space and reuse that for something else? Okay. Here's a suggestion. Here's a suggestion. How about just overwriting entry page directory with the contents of kernel page directory, and that would have saved some space, okay, all right? So, based on the codes we have seen so far for xe6, what do you think? How was entry page directory declared? It was a global variable, right? It was a global variable, which means it is taking some static space, and it can never be deallocated, right? Also, it has a fixed size, and its contents are sort of also, you know, initialized in some way. You can overwrite them, and one way to overwrite them could have been that you just overwrite them with pointers, right? On the other hand, k-page page directory was not a global variable. In fact, it was allocated from the kernel's heap. In fact, it was allocated from this region, from kern-base to kern-base plus 4mb, so anything that you allocate from heap, the nice thing is you can deallocate it, and you can start using it for something else. In the code that we have seen for xe6, entry page there was not allocated off the heap, right? Because by the time the entry page there was needed, the heap wasn't even initialized. So you use the entry page there as some static array, global array. So that much space is actually going to get wasted after entry page there is not used, right, in case of xe6 at least, right? You may, if you really care about this amount of space, which is, you know, 4kb, then you would maybe want to, you know, allocate entry page there also off the heap, and then deallocate it so you can use it for anything else you like later on. Or you could reuse it for k-page there. All these are options. You know, one has to, at some point, make a tradeoff between coding simplicity and efficiency. And so it's okay to just say that, you know, let's basically allocate this as a global variable. Later I'm not going to use it, but it doesn't matter. Okay? All right. Okay. So this is the k-page there. And yes, there's another question. Okay, the question is, couldn't I have just changed the pte underscore p flag to zero, and that would have deallocated it automatically? Well, I think there's some confusion between mapping and allocation, right? So mapping basically means that I have mapped, you know, I have created a mapping between a virtual address and a physical address. That's what mapping means. Allocation means I have some bookkeeping to do. So I have said that this amount of space is being used already, and this amount of space is not being used. So that's just bookkeeping, right? So mapping and allocation are two different things. So when I say I want to free a memory area, I'm basically saying I want to deallocate it. Deallocating it is not going to deallocate it, right? When I want to deallocate it, it basically means that if I want to allocate something else, I can reuse the space. That's what deallocation means. So that space should be reusable. That's what allocation deallocation means, right? Mapping and mapping is something different. Okay. All right. So this is k-page there, right? Now I'll point out one interesting thing here. Recall that most of our programs assume that the null address or zero address is an invalid address, right? If you ever dereference a null address, that basically means it's an error, right? That's a convention, right? So you cannot dereference the zero address. Another convention is when you say malloc, and if it returns zero, it basically means that the allocation failed. It basically means that the address zero should really be invalid. If address zero was valid, then, you know, this kind of a mechanism will not work. So typically the convention is, you know, initially at this point, notice that zero is a valid address, actually. So at this point, if malloc, you know, if this area was part of the heap and malloc returns zero, it may actually not be an error. It may actually be giving you an address which is zero, right? But at this point, zero is not mapped. So at this point, you know, so as a convention, typically operating systems do not map the zero space, just as a convention, right? That makes your coding interface simpler because you're just saying that one particular address called zero is not going to be a valid address. That's a convention that's being used across the software stack, right? If the operating system ever violates that convention, then, you know, a malloc could actually return a zero as a valid page, and that would violate my conventions, right? So as a convention, you basically say that at zero, I'm not going to map anything. So even when the operating system is going to map the user pages, one simple convention that it follows is it's not going to map the zero space. Okay? All right. Okay? Okay. All right. So and we were looking at x86, and we said, let's look at the code which basically does all this, right? So let's look at, let's look at the code which transitions from entry page there to k page there. And we said that this function called kv, so firstly, this function called kinit1 initializes the physical page allocator, right? So what does it do? It basically says that, let's say, you know, at this point, I'm executing an entry page there. And what I'm going to do is I'm going to initialize, and let's say some area of this 4mb is used for, this is, let's say, used for the kernel code plus data, k code plus k data, right? So all this area above it is going to be used as kernel's heap, let's call it k heap, right? And this is where you're going to allocate, you're going to create, you're going to use this space to allocate space for k page there, for example, right? So this is the area from where you're going to allocate pages for k page there. So before you can do that, you need to initialize this space in some way. And so you're going to initialize some data structure, which is going to be, which is, it's going to be called the free list, and you're going to add all these pages in this area to the free list, okay? And so once you do that, you can use these functions called, you know, k alloc, so once again, this is just bookkeeping. So you have, you have an internal data structure called free list, and k alloc is going to take a page from that free list and return it to you, and k free is going to push it back to the free list, all right, okay? So this statement here, the function called k init one is just initializing the heap starting at the kernel's end. So end is basically wherever the, you know, it's initialized, the symbol end itself is initialized by the linker that, you know, in the, in your compilation state. So the end was a symbol that was given to you by the linker. It basically marks the end of the code and data of the kernel. So that's the, that's where the heap starts, where the code and data ends, and till 4mb, right? T2V of 4mb, so current base plus 4mb, that's what this means. So end to 4mb is where you're going to initialize the kernel's heap. And so what you're going to do is k init one is going to push all this to some free list, and now you, whenever you say k alloc, it's going to allocate a page from that area, and when you say k free, it's going to push back a page into that area available for you, right? So kv malloc is going to initialize k page there, and inside kv malloc, it's going to call k alloc to basically allocate these pages for the page table, right? Okay. All right. So now let's look at kv malloc. That's sheet 16. We were looking at it last time, but let's look at it again. Sheet 17. Okay. So kv malloc does nothing. It allocates a page table in the virtual address space and assigns the pointer of it, of the page directory to k page there, and then it calls switch kvm, which switch kvm does nothing but loads the physical address corresponding to the k page there, which is just whatever k page there is minus current base, and puts it into crc, right? That's what kv malloc is going to do. It's going to allocate a page directory and the switch to it. Let's look at what happens when you allocate a page directory. So let's look at setup kvm. So this is the code for setup kvm. It basically allocates a page off the heap, right? Recall that k alloc is going to give me a page from between end and 4mb, right? End and v2p, 4mb. It's going to give me a page from there. The address of the page will be a virtual address. I'm only dealing in virtual addresses at this point. If for some reason the k alloc failed, you just say, you know, there's a failure. I'm running out of space, and this can happen if your kernel's code plus data was actually very large. It was close to 4mb, let's say. Then you memset page there to zero, which means you say that none of the entries in the kernel page directory is present. And then you say, you know, you do some sanity check, that fizztop should be greater than dev space. Let's ignore this. Then it iterates over this array called kmap, which contains information about the regions of kernels that need to be mapped, and then calls map pages on those regions, right? Last time we looked at the different regions that were mapped, we said, you know, kern base. So the first field of this is the virtual address at which you need to map. The second field is the physical address. So the virtual to physical address mapping is kern base gets mapped to zero. Extmem is a size. So extmem is basically representing zero to 1mb space, which has all the devices in it and all that. So that is mapped with permissions writable. Then kernlink is mapped to v2p kernlink. So this is kernel's text and read-only data, which is mapped with read-only privileges. Then from data to v2p data, data to fizztop, you map it as writable privileges. So all the writable data and the kernel's heap is in this segment, from data to fizztop. Right? Data to fizztop. Data to data plus fizztop, basically. Or data to p2v fizztop. Fizztop is expressed as a physical thing, it's a size, so you basically add it up, right? And finally, there's this extra thing for devspace, which is basically to keep the upper map memory map devices for that. So we can safely ignore this. And so what this loop is going to do is it's going to look at each of these entries, so it's going to iterate over the entries of kmap. And for each entry, it's going to create mappings in the page table. So map pages is going to create a mapping in page directory, starting in virtual address word, of size fizzend minus fizztop. Fizzend was the third field and fizztop was the second field. So we're starting at physical address fizztop, with permissions firm. That's what map pages is going to do. And we already know what map pages is going to do, it's going to fill in, so we have initialized a zero, a completely zeroed out page there, I'm going to fill in these entries. Some of these entries are going to be non-zero from now on. Also, I'm going to use only small pages to do this, so here's map pages. So I'm going to use only small pages to map this address space. And so not only do I have to fill up the page directory, I also have to allocate the second level page tables, right? And point the page directory to the second level page tables, and fill those page tables appropriately also. That's what I'm going to do. So this is simple, map pages takes a page directory, a virtual address, size, physical address, and permissions, and it creates these mappings. Basically it calls a function, so it basically says, where do I have to start? I start at, you know, whatever the virtual address is, you round it down to the nearest page boundary, and that's where you start. And this is where you end, you say VA plus size minus one, and you round it down to its page boundary, and that's where you end. And these are the pages that you need to map, starting from A to last, right? And then you basically say, let's walk the page directory with this address A, which means you look at A, you look at the top 10 bits of A, index using that value into the page directory, and so on. The next 10 bits into the page table, and so on, right? And based on that, you get a page table entry, right? And then you basically set up the page table entry to point to the physical address that you want to say, with the right permissions, and the present flag on, okay? And then you keep doing this, right? So basically, if I were to draw this, what's happening is, I started with a page directory, which was completely zero, right? All, everything is zeroed out. And then I said, let's say map pages, page this, let's say I wanted to map 0x802, right? To physical address, and size, let's say, it's the size of hexadecimal 4000, and starting at physical address, and let's say permissions are citable, right? If I want to do this, what I'm going to do is, I'm going to say, okay, 802000, this is the virtual address. Let's look at the top 10 bits of this address. So the top 10 bits are going to be, you know, the first two hexadecimal characters make up eight bits, and the two bits of the third one make it, you know, the top 10 bits. And so that basically comes up to the 512th entry, let's say, right? It has 1024 entries in all. And this particular address is basically saying that the 512th entry needs to be mapped. At this entry, I'm going to see it's a zero, right? So nothing has been mapped here. So what I'm going to do is, I'm going to say kalloc, and I'm going to create a new page, I'm going to allocate a new page, right, from the heap that we have seen before, same heap, we're going to use kalloc, and I'm going to point the top 20 bits to the physical address of this page, right? And I'm going to set the permissions here to present and writable, right? So I allocated a page, I point, I converted it into its physical address, put it in its 20 bits, and also zeroed it out, so it's also initially zero completely, right? Then I'm going to look at the next 20 bits of this address, and so the next 20 bits are going to be, let's say, next 10 bits, sorry, I look at the next 10 bits, which are, what, okay, one, zero, zero, so one, zero in binary, and let's say zero, zero in hexadecimal, which is, right, so that will probably be it. And so that's, into four, let's say this is 64th entry, okay, maybe I'm wrong, but let's just assume that it's the 64th entry here. So everything else is going to be zero, but the 64th entry, the pointer to the 64th entry will be called the page table entry pointer, and I'm going to set that to point to what? The top 20 bits are going to point to this address, right, zero, x, two, and five zeros, and the flags are going to say p, t, e, w, and p, t, e, p, right, and that's it, so you created a mapping as desired from 80200, but you also have to do it for all these pages, so how many pages these are, these are, these are four pages, right, so you have to do it for entry number 64, 65, 66, and 67, so you have to create four entries in the p, t, e, w, right, so you allocated one page table page, and you created four entries in the page table page to create this mapping, yeah, so in this case, the entry is 64, 65, 66, and 67 are going to be created, I'm assuming the 64 is the correct number, I haven't done the calculation, but wherever it starts, okay, somebody says 512, okay, good, so if it's 512, then it's going to be 512 to 515, that will get created in this, okay, so that's what map pages is going to do for you, and we can now look at the code and convince ourselves that it's doing exactly what we wanted, so walk page day returns a pointer to the page table entry, okay, that needs to be filled out, and you just fill up the page table entry with the physical address, so in other words, walk page day is going to return a pointer to this entry, and you just fill it up with this value, so walk page day is going to return a pointer to this particular entry, and you are going to fill it up with the physical address and the flags, right, so that's what it's doing, walk page day returns a pointer to PTE, and you just fill it up, star PTE is equal to PA and permissions and present flags, okay, and you keep doing this, right, walk page day, what is it doing, it's just doing exactly what we did on paper, right, which is just walk the page table, so it indexes the page directory using the top 10 bits of the virtual address, looks at that entry, if that entry is already present, then it gets the page table address, and it returns the PTE address by looking at the next 10 entries, bits of the virtual address, if it is not present already, then it allocates it, then it uses K alloc to allocate a page for the page table itself, and initialize it to 0, and returns the corresponding entry, okay, so this is called lazy allocation of the page table, you didn't allocate the page table entirely up front, you allocated it lazily, as in when you were mapping the virtual addresses, you started allocating the page table pages, and that's the reason a two level page table helps, right, that's the whole reason why a two level page table helps, because you don't have to allocate the entire page table up front, what is the size of a full page table, 4MB, because there are going to be 4K page tables, 4K second level page tables, and each page table will be 4K in size, right, and so actually it's going to be more than 4MB, it's going to be 4K into 4K, that's 16MB, right, so they're going to be 1K page, second level page tables, each of them 4K, so that's going to be 4MB of second level page tables, plus 4KB of the page directory, so 4MB plus 4KB, but you don't need to allocate it up front, you do it lazily, depending on what virtual addresses get mapped, assuming that the size of the virtual addresses that get mapped are small, then you're going to basically save some space, okay, alright, so that's fine, okay, so this walk page div function is basically doing in software what the hardware would have done on every memory access, right, the hardware does the same thing actually, when you say a virtual address, it looks at the top 10 bits, indexes the page directory, then indexes the page table and so on, except that there's one extra complication that if the page table is not present, here you're also allocating it lazily, right, so walk page div is just a software counterpart of what the hardware would do to walk the page table at runtime, okay. It is walking both levels, see it is actually, so it is dereferencing the page directory to get the page table and then it is returning the appropriate offset inside the page table as a page table entry, right, so it's not dereferencing the page table entry, but it's getting the address of the page table entry and then sending it back as a return value and so the caller is supposed to dereference the page table entry, so it's walking both levels. Alright, okay, okay, good, so now let's look at how the memory allocator works, right, so how does the memory allocator work? Recall that we have been using this function called kalloc and what it returns it to me is a virtual address, right, and then I have, there is another function that I am using that's called kfree, which takes a virtual address and frees it. In this case, you know, this is similar to malloc and free that you may have used in your program, the only difference is that kalloc doesn't take a size, it just allocates one page, right, also the other thing it has is it doesn't, it always returns an address that is page aligned, right, it doesn't just allocate a page anywhere, it allocates a page at an address that is page aligned, right, so whatever is the return value of kalloc, the last 12 bits of that address will always be 0. Why does it, why do you think a kernel needs an allocator that always returns a page aligned address? For, yeah, so for a lot of the things that a kernel needs to do, it needs to allocate pages, right, and then create mapping for them in the page table, right, for example, it wants, it wanted pages for the page table themselves, the page table recall had to be page aligned, right, similarly if it wants to create pages for the user process, it will need to create mapping for it in the page table, so for a lot of things you need page aligned addresses and so, you know, it is easier to basically just have an allocator that always gives you page aligned address, right, okay, so these functions always give you virtual addresses and if you ever wanted to convert them to physical address, all you need to do is say V2P of VA is going to give you the physical address, right, and V2P of VA, V2P is nothing but VA minus Kernbase, that is the nice thing about the organization that we have, it is just sort of, so how is this typically implemented, well, basically the internally, the kernel maintains a list of free pages, just a link list of free pages and then it is pointed to by some head pointer and when you say alloc, it just takes the first entry from here and updates head to the next pointer and just returns that address and when you say free, it just adds it to here, also notice that the next pointer itself is stored within the pages themselves, right, you do not need extra space to store the next pointer because these pages are not getting used anyways, so you can just use the space within them to store the next pointer itself, okay, so this is, you know, this is roughly how malloc and free also work except that malloc and free need to be more complicated because they need to allocate variable sizes of data, so they need to worry about fragmentation issues but if you are just doing a fixed size allocator, all you need to do is just maintain a list and use the next pointer itself is going to be stored in the list, okay, so and so what is going to happen is that initially, when we said k init 1 adds all these pages to the free list, basically what it does is it just calls k free on all the add pages present in the space, right, so it just keeps calling k free on all the pages in the space, recall that this is the kernel leaf and so all these pages need to be added to the free list, so one way of adding all these pages to the free list is just keep calling k free on all these pages, right, and so all of them get added to the free list and now your allocator and de-allocator work using k alloc and k free, so basically k init, the function k init 1 simply just you know, takes a start and an end address and just you know, iterates over this address and each page that it sees in that address, it just adds it to the free list using k free, so just say k free va and let us say for va from start dot dot end, right, of course I am simplifying something there, start and end need to be page aligned addresses and all that, okay, right, so if you look at the implementation of k init 1, you are going to roughly find something like this, right, okay, let us look at k, let us look at the calls to k init 1, little more detail, so k init 1 add all the pages starting at end till p2v of 4mb and add them up to the free list, right, that is what k init 1 is going to do and at this point you have some free list, so that you can satisfy some k alloc at this and the kv malloc and all the functions here are going to use the space which is within the 4mb, so notice that all these functions are going to be using only the heap which is lower than 4mb, right, any allocation all the space above 4mb in the physical address space is not being used at all at this point, right. Then there is another function called k init 2 that finally makes available the other physical memory also and what it does is it just says free all the memory starting at 4mb, p2v of 4mb which is you know current base plus 4mb to p2v of fizztop, so add all these pages from starting at 4mb till fizztop also to the free list and at this point you know your k alloc will also start taking pages from space above 4mb, okay, why is there a must come after start others, well there is a difference, so k init 2 relies on some you know initialization of locking subsystems etc., so k init 2 requires, so because xv6 is a multiprocessor operating system, the same memory allocator serves requests to all the CPUs and so there needs to be some locking inside the allocator, right, because if 2 people simultaneously access it there should be some issues, so we are going to look at it in more detail, but for now let's just assume that k init 2 requires to initialize the locking subsystem and to be able to do that it needs that other processors should have started, all right and after it has allocated all this memory, so at this, so why fizztop, is it okay to say fizztop, what if, what will happen if the physical memory, so fizztop is just a constant, right, in the xv6 code and fizztop just is a constant which is around 240 MB, right, what if the amount of physical memory on the machine was less than fizztop, is it okay to do this, so how many say no, 5 people, how many say yes, 0, okay, others are undecided, okay, so well, it's not okay, right, because recall that the free list is actually get, there is data that's being written in the free list also, right, the next pointer and so you need to dereference those values to be able to write anything on that and if there is no physical memory there, then dereferencing would generate an error, an exception, right, so in a way xv6 is lamely assuming that the amount of physical memory will always be greater than, you know, fizztop, okay, on the other hand if the amount of physical memory was greater than fizztop, is that a problem, no, that's no problem, because you are just using less than the amount of available memory, right, recall that you could, I mean here is the difference between mapping and allocation, even though the amount of physical memory was less than fizztop, I said it was okay to map addresses, right, I just created a mapping, as long as I don't dereference those mappings, it's okay, but once I start using them, that's the problem, right, and I can only use those places if I add them to the heap, right, that's the only way I can sort of start using them and then dereferencing them and all that, so it's not okay to use a memory less than fizztop if you are, because of this statement here, for xv6, yes, okay, so question is if you generate an incorrect address, incorrect physical address, right, so there are two different things, one is the program can generate an incorrect virtual address, which means that the address wasn't mapped in the virtual page, right, so there is a certain type of exception that gets thrown at that time, but if the page is actually mapped and the physical address is actually computed, but when you actually go on the bus and ask the memory for that physical address, the memory says, oh, I don't have that physical address, so what happens, right, so it's an exception that gets generated, okay, the alternative that was suggested by you is can the address get wrapped or anything of that sort, no, I mean wrapping is not possible, assuming that we are only dealing with 32-bit addresses and this is 32-bit bus, there's no wrapping that can happen, okay, right, and after that I'm going to call user init, which is going to initialize my first process, and after that my processes are going to run just like we have talked about in the Unix world, where the first process is going to get started, that's the init process, and the init process has some, you know, hard-coded code in it, which says, let's say, for the first process, and let's say the first process is, init process forks the shell process, and the shell process basically takes commands from the standard input, and depending on what the command is, it may fork more processes, and so on, okay, so that's how it typically works, that's how it typically works in Linux also, there's one init process that starts up, and it then reads some files, and depending on that, it starts up some processes that should be started up at the beginning, some of those processes are going to be, let's say, the login process, the X window system, or whatever, right, so notice that the first process is unique because that's the process that's created by the kernel, all other processes are not created by the kernel, they are forked by already existing processes, that's the only way to create new processes, right, it is the first process that gets created by the kernel, and that's what the user init is going to do, okay, okay, so I'm going to look at user init in the next lecture, but before we do that, let's review how this, how the system is going to run from there on, right, so we have initialized everything, we have mapped the entire physical address space, we've started the first process, the first process is going to make system calls, and I've also initialized my device subsystem, so there's going to be timer interrupts and all that kind of stuff, right, and so let's look at, you know, a sample execution of what's going to happen, what's going to keep happening, actually, so firstly, let's say this is the kernel, and this is process P1, which is the first process, process P2, let's say fourth and other process, and so on, right, I'm drawing it inverted, so let's say this is address 0x8, right, or current base, and so these addresses from here to here, which is let's say current base plus fizz talk, will be mapped inside the kernel, right, and everything from 0 to current base is the user side of things, so a kernel will have let's say its own code, somewhere here, and will have some data, each process, right, and similarly, he may have his code here, and his data here, and they will have some heaps and all that, and also there will be something called an interrupt descriptor table, we have seen this before, IDT, that's going to have pointers to which space, right, they're going to have pointers to handlers, and all pointers will be in the kernel space, right, so let's say P1 wants to make a system call, it uses a software interrupt instruction, the IDT gets consulted, the system call handler gets called, but the system, so in the context of the same process, in the same page directory, so while this process is executing, a certain page directory has been loaded into the hardware, when it makes a system call, you switch from user to kernel, but you use the same page directory, so in other words, you're basically using, you're executing in the context of P1 at this time, you're executing in the kernel, which is shared across all processes, but at the time of the system call itself, you're executing in the context of the process that made the system call, because, why? Because you're using the same page directory, you haven't changed the page directory, right, you just changed the instruction pointer. Also, so, you know, you're using P1's page directory, and you're using P1's kernel stack, assuming it's a process model, each process has a different kernel stack, so you're running on P1's Kstack, right, and how does the hardware load the P1's Kstack? Using the task state segment that must have been set up by the OS, we know that. All right, so it's going to execute in P1's Kstack, it's, when it executes in P1's Kstack, the first few things it's going to do is it's going to save all the registers of the executing process in the Kstack itself, right, so let's say this is the Kstack, the first few registers are saved by the hardware, namely, ES, EIP, SS, ESP, ECLAG, right, the first five registers are saved by the hardware, and the next few registers you can save in software, which is how xv6 will do it, and this is how most operating systems will do it, it'll just say push this register, push that register, those registers haven't been modified, so, you know, the values are still preserved, and you just keep pushing them on the Kstack. Once you have pushed all those registers, you have saved the state of the user process, you're going to execute some logic on behalf of the process, which may involve some privilege operations, and then you're going to say, let's return back, right, and returning is going to just pop off those values that you had saved on entry, one by one, some of those values are going to be popped off in software, and the last five values are going to be popped off in hardware by using the irate instruction, right, and you're going to execute back in the process mode, user mode. How does the process give arguments to the system call? One way that it just sets up its register values to indicate the arguments, right, in fact sets up the register values to also indicate the system call number, and how does the kernel give a return value to the system call? How does the kernel give a return value to the system call? Using the ex register, so but what does it need to do here? Modify the saved value in the stack, so whatever the saved value in the stack of the, at the place where ex is living, you modify that, so at the time of return, it's going to get popped off into the ex register, and the user is going to see the new ex value, right, it does, it's not, it's not, it's not good to just change your own ex, because your own ex is going to get lost when you return to kex, you need to change the ex that's saved in the stack at the right offset, and so when you're going to return back, that ex is going to get visible to the user, okay, all right. So this, this structure, so let's say this is the process, P, when it executes here, it starts at k stack, right, it saves aip, cs and so on, and it also saves other registers like eax in software, ebx and so on, right, this structure which lives on the stack is called the trap frame, while I'm executing in the kernel, I can look at the trap frame to look at my arguments, and also return a return value, right, so the first thing the kernel does is create at the entry, the first thing the handler will do, it's going to create this trap frame, the first five entries of the trap frame have already been created by the hardware, the next, whatever number of entries depending on the number of registers in the architecture, you're going to create them in software by hand, okay, and now you're going to execute the logic, so for example if you wanted to look at your arguments, you're going to look at the trap frame, and look at the value stored in, so let's say, you know, trap frame.edx contains argument number one to the system call, right, ecx contains argument number two, edx contains, so it's not the real register that's containing it, it's the save register which is in the trap frame that contains the arguments of the system call, and that's where you also write your value to give a return value to the system call, okay. What is the upper limit on the number of arguments that can be passed to a system call? That is defined by the OS designer, right, and clearly the number of arguments cannot be unbounded because, you know, you have a finite amount of kernel stack, typically, you know, on Linux you would have, you know, at most five, six arguments, if you wanted more arguments then you will use pointer chasing to do that, right, so it's possible that one of these arguments is actually a pointer that points into some structure which lives in this address space, okay, and so the kernel can look at this pointer, dereference it and get more arguments from there. And your lab two is actually going to expose you to this kind of argument passing from the user to the kernel for system calls, they're going to implement this argument passing, okay. So on a system call, control moves from here to here, the trap frame gets set up, the kernel executes on behalf of the process in the same address space as the process, and then at some point it returns, and the return is just unwinding of the stack, at some point you're going to unwind the trap frame, and unwinding of the trap frame means you just load the registers with the trap frame values, and then you call iret and you are back in the user space. The code, the logic can read the trap frame and write to the trap frame for arguments and return values. Same thing happens if there was an external interrupt, let's say there was a timer interrupt that goes up, right, so if there's a timer interrupt that goes off, that fires, then the execution moves from user space to kernel space, the trap frame gets saved, some logic gets executed, let's say the logic that gets executed is the logical scheduler, that at this point decides that you don't want to let this process continue running, and you want to switch to another process, in which case you will switch the address space, switch the kernel stack, and unwind it from there. Okay, we're going to discuss this more next time, how context switch works, so it's going to be very interesting, right, so let's do it on Thursday."}
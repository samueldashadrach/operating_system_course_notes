{"text":"Welcome to operating systems lecture 28. Last time we were discussing sleep wakeup on xv6 and we said sleep wakeup is actually identical to condition variables except that we do not explicitly declare a condition variable. We just sleep on some channel and that channel is some identifier and earlier in condition variables you would have declared a condition variable associated with that channel. Now you do not need to declare anything separately. Because a condition variable has no state, you do not need any space for the condition variable. So really this channel is nothing but an integer. Any 32-bit integer that can be used to indicate that I am sleeping on this channel and then you use the same integer to indicate that I want to wake up all sleepers on this particular integer. So that is what it means. And we said that we looked at some examples. We said look there is exit and wait. We understand this exit and wait system call in Unix and xv6 implements the same. So parent calls wait, let us say, and if it finds a child that is currently not a zombie and running or active, then it sleeps on its own PID. So the channel is basically its own PID. And if a child calls exit thereafter, then it calls wakeup on its parent's PID. And so that is how you basically ensure that you only wake up your own parents and nobody else. And we also said instead of this convention, if I had a more general convention where instead of sleeping on my own PID, I sleep on some global identifier, that would have been also correct provided you are enclosing the sleep in a loop which is checking the condition. So if a child calls wakeup on all the parents, then all the waiting parents are going to come out of the sleep only to go back to sleep. So that's okay. It's wasteful, so it's better to have as fine-grained channels as possible. And so this makes a lot of sense. It's exactly as fine-grained as you can get in this particular example. Yes? Okay. All right. So the question is, you know, in this case, if I'm using this convention that a parent is waiting on its own PID and child is calling wakeup on its parent's PID, do I need to enclose the sleep in a while loop? Can I just, you know, use if, you know, so I can be sure that if a parent has woken up from sleep, then definitely one of its children is zombie. And so it can be collected, right? Well, I mean, yes, you can do such reasoning. We have seen such a thing in single producer, single consumer case. But, you know, doing these kind of reasonings is usually error-prone. You know, and then as I'm going to show you next, there are other checks that you do make, whether the process has been killed in the middle or things like that. So it's always better to, you know, put it in, you know, recheck after coming out of a wait that whether the condition is true or not. And the overhead of rechecking is very small anyways, right? It's just a memory operation to basically do it. Also, it's possible that, you know, so you basically said, I want to, I'm going to use this convention for exit wait. But let's say a completely unrelated part of the code wanted to use some other synchronization, and it also decides to sleep on the PID of some process, right? So let's say there's some synchronization going on due to some other completely unrelated part from wait exit, right? And so that also sleeps on PID. And so now they can sort of, you know, cross communicate. And to protect from errors because of this cross communication, you should always enclose your sleep within a while, right? If you don't, then you have to be very careful. You know, it becomes a global invariant, and nobody else should be sleeping on the PID, for example, right? So today, I'm going to discuss another system call called kill, right? So we have seen the kill system call in the context of Unix, where we said that you can, you know, say kill on a PID, and that will, you know, send a signal to that particular PID, to that particular process. You can say kill PID with some signal, and that signal will be sent. X36 doesn't implement signals, so kill PID doesn't send a signal to the PID, but just terminates that particular process. The idea is, if I send kill on a process ID, then that process gets terminated. So how do you think kill can be implemented? Can I just, you know, if some process calls kill, can I just immediately acquire the P table lock, go to its process, and free all its structures? Does that make sense at all? Does that make sense? Yes? No? Why not? One process called kill PID, that process just acquires a P table lock, goes through the proc table, finds the process with that PID, and frees all its structures. Is that okay? What if that process is currently running? Right, it's in the middle of something, and now you have just, you know, freed up all its structures. Let's say, you know, you freed up its Kstack, and it was running in kernel mode, you know, suddenly there will be some bad thing that is going to happen. It could be in the middle of some operation, you know, it has not finished its operation, and now you free it, or you completely terminate it. You know, firstly, you know, it's running, so how can you just free it? If you free it, then you haven't told it to stop. You have to, you know, have some way of asking it to stop. Also, it could be in the middle of something, and you want it to come out of wherever it is, and then exit gracefully, right? And so the way you would implement this kind of a thing is that, you know, you will basically have a flag inside the proc structure called killed, right? So there's a structure called killed inside a proc, and if one process calls kill PID, then I will just iterate over the procs table, find the process, and set its killed PID to 1, right? So by default, it's 0, but I'll just set it to 1. Now, it is that process which will basically, you know, if it was in the middle of something, then it will just, you know, when it comes out of it, it's that process's responsibility to know that I have been killed, and so it should exit. If a process has been killed, it should exit, and exit will not free up its data structures either. It will be its parent who will call wait, and then that will free it up, okay? In any case, the point is that, you know, kill cannot be done immediately, because the process may be running. So the way it's done is you just set a bit in that process's structure, and let that process run. When the process, you know, finishes, comes out of wherever it was, then it should really check whether I've been killed or not, and then it will exit, all right? So of course, when you set proc.killed, you are accessing the shared proc structure, so you should be holding the P table lock, right? So you just hold the P, you use the P table lock to basically set this bit, but after that, it's that process's responsibility to basically exit after it has checked that it has been killed. All right, okay? Yes? Is any process allowed to kill any other process? Well, in Unix, if the processes belong to the same user, then a user is allowed to kill its own process, basically. But one user is not allowed to kill another user's process. Also, you know, modern operating systems like Linux have a concept of root user, which we all know that root user is super user, so root user can kill any other user's process, for example. So you can have this access control mechanism, but, you know, in xv6, you just have one user, so any process can kill any other process. Yes? Okay. All right, so I'm saying that one process just sets the killed bit of the other process, and I now expect that process to basically exit, right? So, you know, what if it doesn't exit? You know, what if it's a malicious process? How do I make sure that that process will definitely exit in some bounded amount of time? So firstly, you don't trust the process's user space, but you definitely trust the process's kernel space, right? Anytime the process is executing in the kernel mode, it's your code that's running, right? It's not the user's code that's running, it's your code that's running. So you always trust the process's kernel space, right? Because process in the kernel space is just a kernel thread, and you completely trust that code. So anytime the process is executing in the kernel, you can be sure, and because you have it in the kernel code, you can be sure that it will call exit whenever killed bit is set. Now you can say that what if the process remains in the user mode and never comes in the kernel mode? See, but that's not going to happen because, you know, you have a timer interrupt that makes sure that every process periodically comes in the kernel mode. So whenever it comes in the kernel mode, it is going to check whether something, you know, whether it needs to exit or not, okay? Once again, this orchestration has been done by the kernel programmer, okay? All right. Also let's say I set the killed bit of a process and it was sleeping when it was killed, right? So let's take a few cases. Let's say, let's say this process was running when it was killed, and let's say it was running in user space when it was killed. No problem. Eventually it will come to the kernel space either because it made a system call or because of the timer interrupt. And as soon as it comes into the kernel space, it should check whether I've been killed or not. And if it has been killed, you know, right at the entry, you should put a check that if I've been killed then I should exit. And that's a very safe place to exit because you are not in the middle of any kernel operation. You've just come from user to kernel and you can just ask him to exit right there. So this is easy. Let's say I was running in kernel mode, okay? So I'm running in kernel mode. I could be in the middle of doing something. Of course, I'm using the case stack and all that. And so basically I should wait for the kernel to finish whatever it's doing and then come back. Quite likely if it's running in kernel mode, either it will return back to the user mode eventually. So that may be a nice place to check the kill stack, right? Just before re-entering the user space, you can check the kill stack and call exit before it re-enters the user space, right? That's one thing. If it's running in kernel mode but it's not going to re-enter the user space, it's possible that the only other possibility is that it's going to sleep, right? Or it's going to do something else. So all these places where it could be going to sleep, for example, before you do that, you should check that it's killed and you should check it all these sort of boundaries where you're not in the middle of something. So at any place where you are sure that all the kernel data structures are consistent, at that point you can put the check that if I am being killed, then I should exit. Okay? Now let's say I was sleeping. Sleeping, of course, can only happen in kernel mode, right? It doesn't make sense that a user's process is sleeping in kernel mode, in user mode. If it's in the user mode, it must be running something. If it wants to sleep, it will come to the kernel mode and then it will call the sleep function to basically sleep. So let's say it was sleeping in the kernel and you basically said frog.kill is equal to zero. What will happen? It's equal to one. What will happen? The process was sleeping, it will never get scheduled, and so, you know, it will not get, you know, so killed is not going to have any effect. It's just going to sleep forever, maybe. So not only do you say frog.kill is equal to one, you also say if it was sleeping, then mark it as runnable, right? So here's something sort of dangerous looking. I'm saying any process who is sleeping, if it has been killed, just mark it as runnable, right? Irrespective of, you know, what was the condition on which it was sleeping, what was the channel it was sleeping on, doesn't matter. Just mark it as runnable. It will get scheduled eventually and when it gets scheduled, it will get to run, okay? Now it's the responsibility of the programmer to ensure that whenever a process comes out of the sleep, it also checks whether the killed flag has been set or not, right? And if so, then it should exit, okay? Once again, it's a kernel programmer who is making sure that, you know, firstly, you need to do this because otherwise, you know, a sleeping process will never get killed and if you need to do this, you are violating some, you may be violating some invariance because after all, the process went to sleep on some condition and that condition has not yet become true, but you still made it runnable and so it will come back and it will basically, but before you start doing anything, you should probably check whether it has been killed and if so, it should exit, right? Okay, if it is sleeping, I can assume that after some time, it may wake up and then it can exit. Well, I mean, so let me think of an example where it may be sleeping and it may not wake up. So, let's see. So, let's say I was a parent and I wanted to wait on my child to exit, right? And so, my child is going to run for a long time and somebody wants to kill me, right? So, should I wait for the child to, you know, finish its execution before the parent gets killed? Maybe not, right? So, you want to basically kill it right then. You know, there should be some bound on the time it takes between the kill operation and the actual act of getting killed, right? Otherwise, you know, you have killed it but it still appears on your process table. That's not a good idea. Okay. All right. So, okay. And it may not be always necessary that when you come out of sleep, you always check the kill and you exit. You know, it really depends on the semantics under which you are sleeping and I'm going to show you a couple of examples to show when you need to exit on being killed and when you don't need to exit on being killed. Okay. All right. So, let's just, let's just look at the code. This is sheet 31. This is the kill function, all right? So, the first thing you do is acquire p table lock, right? Then you check, you iterate over the p table, write a process whose PID is equal to the argument, set its kill value to 1. If it is sleeping, mark it runnable, release the p table lock and return, all right? That's it. Okay. So, now let's see where the kill is being used. So, this is sheet 26. Sorry, not 31. Sheet 26. All right. Let's look at sheet 31 where the kill flag is being checked. So, this is a trap function. Recall that the trap function gets called on every trap. A trap is both a system call or an external interrupt like a timer interrupt or any exception like a page fault, right? So, all these are basically traps. And so, the trap function gets called. Recall that the all traps function, all traps assembly code used to call the trap function. So, the trap function gets called every time. And you can see here that at entry, you are checking if frog.killed, exit, right? Similarly, after that, you basically execute the system call and on exit, you are saying if frog.killed, then exit, right? And so, you will see similar sort of happening of this code if frog.killed, exit at other places in the code. For example, here's another example. Let's say if frog and frog.killed and I was executing in user mode, then exit, right? So, for example, there's a timer interrupt while I was executing in the user mode and the process has been killed since in the past, then exit. Similarly, you know, you'll see something somewhere. So, these are the places. Notice that he's basically identified some safe places where you should exit, you should check and exit. Also, he has made sure that there is a bounded amount of time within which it will exit. Okay. All right. Now, let's look at the wait and exit code that we were looking at last time, right, just to complete the discussion. So, here's let's say the wait code, right? This is sheet 24. I'm looking at the wait code and recall that I was acquiring the p table lock, iterating over the p table and, you know, and if I find that there was some child, if I have a, if this process has a child that has not, that is not yet a zombie, then I will go to sleep, right? So, let's say I was sleeping. So, let's say this process was sleeping here and it's waiting for one of its children to exit. Now, somebody calls kill on this particular PID. So, what will happen? It will be marked runnable. It will come out of sleep immediately, even though none of its children have actually become zombie yet. It will come out of sleep. It will, the nice thing now is I'll go back and check the condition again, right? So, here's an example where, you know, you actually, even though you have chosen the channel correctly, you had to check the condition again because you, there are other reasons why you could have woken up, right? You check the condition again and once again you find that, you know, there's nothing that has yet become a zombie. None of my children have become a zombie. I come here but this time I find that I've been killed and so I release the p table lock and return minus one and return minus one will, you know, eventually go back to a system called exit and there you're going to check whether it has been killed. Then it is going to call actually exit, right? So, in this loop of checking, here's an example where you basically, you know, if somebody has been woken up from a sleeping state unceremoniously, not correctly, then you will basically hand, the programmer is handling correctly and this is very important to handle it correctly, okay? All right. Okay, now let's look at another example of how wait and notify is used and I'm going to look at the IDE device driver, the disk device driver. So, IDE disk drive, device driver. You all know a computer system is made up of a CPU, main memory and a lot of devices, right? And one of these devices is the, is the disk, hard disk, magnetic disk, let's say. And IDE is just one interface, one standard interface to communicate with the disk. So, it's a standard, the IDE device manufacturer will conform to that standard and the operating system developer will also conform to the standard and so they can talk to each other. All right, so let's, let's see what happens. Basically, there are multiple processes, right? And they may be calling read or write system calls and eventually, you know, the file descriptors of these read and write system calls may be pointing to the disk. So, when they make a system call, they become kernel threads and these kernel threads will try to access the disk and read or write data from the disk. So, what sits in the middle is this IDE driver, right? On, on the xv6 code, this function is called IDE RW, IDE read write, all right? The multiple threads who are coming inside, inside this, trying to access the disk and they all go through this device driver to be able to access the disk. Also, because the disk is very slow, as you, as you already know, what we also keep here is what's called a cache. If you read something from the disk, you basically store it, keep it in the cache so that, you know, if some, if somebody else wants to access it, then it just gets satisfied from the cache. And notice that this cache is a shared cache. It's shared across all the processes, right? So, if one process tries to read something, then it comes into the cache and another process tries to read the same thing, then it doesn't need the disk access. You save disk accesses because of a shared cache. And so, because it has to be a shared cache, this cache has to be implemented inside the kernel, right? If it was not a shared cache, you could have implemented the cache at user space also, I mean, it doesn't matter, right? But because it's a shared cache, it has to be implemented in the kernel and almost every kernel has it and this is called the buffer cache. That's a common name for it, right? So, buffer cache has many buffers and so it just reads data from the disk into the buffer and all subsequent requests are checked against the buffer cache. If you can satisfy it from the cache, then you just return it from the buffer cache. Otherwise, you go to IDRW to read the disk. All right? Okay. All right. So, firstly, there's just one disk and there are multiple logical processes, right? And multiple threads. The threads could be logical threads or, you know, there could be logical concurrency or physical concurrency. In either case, you need to provide mutual exclusion on your accesses to disk. So, only one thread should be accessing the disk at any time, right? So, that's needed. So, basically, what do you do? Inside IDRW, you have some locks. So, on x86, you have an ID lock. So, every thread before it tries to access the disk must acquire the lock and then access the disk. So, make sure that only one thread is actually controlling the disk at any time. So, one thread comes in, talks to the disk, gets its data or writes the data, reads or writes the data, goes out, then another thread comes in, and so on. So, it's completely sequential in that sense. Also, as we know that a disk is really slow, right? So, it's quite likely that there are, you know, lots of threads that are waiting for the disk to be available. If there's a very slow thing, then a queue will usually get built up in front of that slow resource, right? And so, the best thing to do would be to sleep as opposed to spin, right? Because the disk is basically milliseconds, and you don't want to spin for milliseconds long. So, you would probably want to sleep. So, you will basically sleep on something. And so, when the disk actually gets done, then you will wake up the corresponding process, right? Also, device drivers are basically written in one of the two ways. One is called polling, and the other is called interrupt waste. So, what this means is, let's say I request the disk to do something. Let's say I ask the disk to say, to read some data. I want to read the sector number 10. Now, I can keep asking the disk. So, the disk is going to take some time. And so, I can keep asking the disk, are you ready? Are you ready? Are you ready? All right. So, that's called polling, right? You keep polling the disk for the data, right? So, you basically just keep checking at some periodic interval, whatever you think is valid, you just keep polling the disk at periodic intervals, and as soon as you get the data, you give it back, right? Polling is, all right, so that's one way to do it. The other way to do it is interrupt waste, where you ask the disk to do something, and then you go to sleep, right? And now, the disk has been configured to generate an interrupt whenever it finishes. So, I don't need to continuously keep asking it. It will call me back using an interrupt. So, it will generate the interrupt, and the interrupt handler, when the interrupt gets generated, I can check whether my job has been completed, and if so, I will take it, right? So, there are two ways to deal with devices in general, polling and interrupt waste. Slow devices are better dealt with in interrupt waste manner. Faster devices are better dealt with in polling waste manner, all right? So, the other thing is this IDE device has to be interrupt waste. So, what's going to happen is that a thread is going to take the lock, it's going to enqueue its request into a list, into a queue, and then it's going to go to sleep. Whenever the device finishes, it's going to generate an interrupt, and the interrupt handler is going to call wake up, right? So, that process can actually continue. So, whosever job has been done, that process will be called, you will basically wake up that particular process, all right? All right. So, the way it works on xv6 is basically that you have a queue, which it calls IDE queue, and this has all the buffers that are waiting for disk access. Each, and so, there are multiple threads that try to add to this IDE queue. So, you basically take, so, protect it by IDE lock. So, if there are multiple threads who want to access the disk, they are actually trying to, they first contend on IDE queue. So, they contend on IDE queue, and enqueue their request on this IDE queue, and this IDE queue is processed in C4 order by the disk, right? Now, the disk, so, now the driver basically picks up one request from here, and asks the disk to do it. The disk generates an interrupt when it's done, and it basically, so, whoever was the process that requested this particular thing, that particular process is woken up, and that process can now go on its way. So, a process enqueues its request on the IDE queue and goes to sleep, right? So, enqueue and sleep, and when the, and the IDE device takes one request at a time, and when it's done, then it wakes up the sleeping, corresponding sleeping process, right? So, let's look at this code. This is IDRW on sheet 39, okay? So, this is the function IDRW. It takes an argument, a buffer, which is, you know, some pointer into a buffer cache, and the semantics are that if the buffer is, you know, buffer, the strut buff has a field called flag, and if the be dirty field is set in the flag, then you should write, treat it as a write request, so you want to write this buffer to the disk. Else, if be valid is not set, then read the buffer. So, you know, whether it's a write request or a read request is encoded within the buffer, and it flags. Whether, if it's valid, if it's not valid, then it's a read request. If it's dirty, then it's a write request. So, here are some debugging aids. You know, firstly, all right, so we can ignore this for a minute, and we say, either it should be valid or it should be dirty, right? It cannot be that it's neither, and, or, I mean, either it should be not valid or it should be dirty, basically, okay? So, it should be either a read request or a write request. The first thing you do is you acquire the ID lock. That's mutual exclusion. The next thing you do is you append the block, the buffer, to the IDQ. So, IDQ is some shared structure. It's a global variable, and you just append the block to the IDQ. You append it to the end of the IDQ, because it's a FIFO, so you append it to the end of the IDQ. So, you just iterate over the IDQ until you reach the end, and then you append to the IDQ, right? So, just, in this figure, just go to the end, and then put your new buffer here, all right? Finally, we check if IDEQ is equal to B. So, B is the buffer that was the argument to this function, so this is the buffer that I want to read or write. If IDEQ is equal to B, it's checking what? If I'm the first element in this queue, that's what it means, right? If I'm the first element in this queue, then start the disk, right? So, basically, it means that the queue was actually empty right now, and this is the first request that's been made to the disk. So, the disk is actually not spinning right now. It's not working right now. So, I need to start the disk. So, there's a function called ID start that's going to use in and out instructions to basically tell the disk to start. There's some standard which is basically telling it to start. So, the disk has been started. If I'm not the first element in the queue, then I don't need to start it. It's already started, right? And if it's already started, it will, you know, it will, as you're going to see, it will basically just, it's just serving one request, and as soon as it's done serving that request, it will take the next request in the queue and so on, right? So, I don't need to do anything. If it's already started, it knows what to do next. As long as I've appended something to the queue, I'm fine, all right? And then I keep waiting on this condition. The condition is that whatever I wanted to do, read or write, if it has happened, if it has, till it has not happened, keep sleeping, right? The mutex is ID lock, and the channel is the buffer on which you wanted to do this operation. All right. Let's look at, you know, maybe it will become clearer if we look at what happens if the disk finishes. So, when the disk finishes, the IDE interrupt function gets called, the interrupt handler, and what it's going to do is it's going to again acquire the IDE lock, right? Once again, so the interrupt handler, so the disk is finished. It has called the IDE interrupt handler. It will acquire the IDE lock, and it will check if the IDE queue is now, if the IDE queue is null, that basically means I don't know why I got this interrupt. It's possible that a device created a spurious interrupt, so I just say, you know, it's a spurious interrupt. Don't worry about it. And usually, if I got an interrupt on the disk, it basically means that there must have been something in my IDE queue, right? That's why I was working, and that's why I generated the interrupt. But if the device, for some reason, generated a bad interrupt, I should tolerate it, so the programmer is tolerating it. Otherwise, you basically say that whatever was the top of the queue has been addressed, has been serviced, so you basically move the top of the queue to its next. You read the data using the in instruction from the disk into the buffers data, v.data, okay? And so, B is the top of the queue, right? So you are serving the top of the queue. You check. You read the data into B's buffer. You set its flags to say that now it's valid, or, you know, it's not dirty anymore, depending on whether it was a read or write request, and then you call wakeup on B, right? Why do you call wakeup on B? Because the process who was, who made this request must be sleeping on B. So now you call wakeup on B, so that's how you basically coordinate between a process who made the request and the disk who completed the request for that particular process, okay? All right? And finally, if the queue is still not empty, which means there are more requests to do, then you restart the device for the next buffer, okay? All right. So, you know, details aside, I mean, let's forget about how exactly the disk is being, you know, what's the interface, you know, what does nsl mean, and how does id start work. These are all sort of very, you know, too much detail that we don't really need. But what's important is how is synchronization happening, right? So there's a process who appends something to the queue, goes to sleep on the buffer that he wanted to actually read or write. The disk, when it goes to sleep, it also releases the id lock. The disk, when it finishes, generates an interrupt. The interrupt handler also needs to acquire the id lock, because it needs to operate on the, it needs to manipulate the id queue. For example, it will move the top of the id queue to its next pointer, right? So it will operate on the id queue, so it needs to take the lock, and then it calls wakeup on any process that was waiting on that id queue. So basically wakeup makes it runnable, and so that process can now return from wherever it was. Okay, good. So what if a disk generates an interrupt while I was, so before that, what if a disk generates an interrupt while I was somewhere here? So I started the disk, and before I go to sleep, the disk has finished. So let's say the disk is really fast, it just finishes immediately, right? Right. So basically, because I have acquired the id lock, interrupts are disabled at this point. This is a great example to understand why we need to disable the interrupts when we are holding a lock, right? If we didn't disable interrupts, the interrupt handler could have run here, and bad things could have happened. Because I'm holding the id lock, this entire region, the interrupts are disabled. Interrupts get re-enabled only when you sleep, and you release the lock, consequently, right? So this entire region, the interrupts are disabled, right? So if an interrupt occurs, what happens is that the interrupt gets buffered by the hardware, and as soon as you re-enable the interrupts, the hardware basically gives that interrupt to you. That buffer is very small, you know, one or two interrupts, it's okay, right? You know, you're probably worrying about the situation, what if the interrupt gets lost, and no future interrupt comes? I think we have discussed this before, so let's say, you know, usually the protocol is that if a device makes an interrupt, it expects for an acknowledgement from the CPU. So if it hasn't received the acknowledgement, we'll retry the interrupt. So there's, you know, that kind of a protocol going on. Okay? All right, so if an interrupt occurs here, no problem. Interrupts will be served only as soon as the id lock gets released. And so the interrupts get re-enabled. The id interrupt, when it gets to run, will try to acquire the id lock. You can be sure that if it was only one CPU, then it will get the id lock, right? The only reason that the interrupt handler may not get the id lock is because another CPU is holding it. But the same CPU couldn't be holding this id lock, because after all, the interrupt got to run, right? So the interrupt got to run, that CPU couldn't have been holding the id lock. If it was holding, then interrupts would have been disabled. The whole reason, the whole point, the whole fact that the interrupt handler got to run means that the CPU was not holding any lock. So, you know, that basically means that you will eventually get id lock, so there's no deadlock problem here, right? And then you will perform this operation, and then you will wake up the protocol process. When you call wake up, that process may not necessarily run immediately. Let's say it was a uniprocessor system, this interrupt handler is running, so how can that process run? You have also disabled interrupts completely here. But when you release the id lock, and then you return from the interrupt, the interrupt gets enabled again, and because you have woken it up, it has become runnable. Whenever the scheduler gets run next, it's going to get picked up, and it can now proceed, right? So let's say the process wakes up from sleep, it checks the condition again, this time it finds it to be true, false, and now it can go on sleep. All right. Notice that here, inside the loop, when I'm saying while some conditions sleep on this, I have not really checked for p.kill, right? I said that usually when you come out of sleep, you should now, because you are doing this thing that any sleeping process will be made runnable, is it incorrect to not check for p.kill? Well, I mean, it doesn't matter if it's going to check the condition, even if the process was killed, you still want that the buffer has been read, lock has been released, and now you can go on and check later. So it's okay in this case. So it's not necessary that every sleep loop needs to have the kill condition, kill check. Some need, some don't. One has to reason carefully about what needs it. So one way to think about it is that eventually, it's going to come out, right? So it's not a very long time that it's going to stay there. I'm not waiting for some child to exit, for example. I'm just waiting for the disk to finish. So it's better to let it finish, and then release the id lock, and then basically let this caller call. So let the thing be in a more consistent state. I don't know whether the caller is leaving things in a consistent state or not. So let it reach some boundary. This may not be the right boundary. This may be the innermost sort of thing, and if I just sort of start returning minus one from here, that may not be the right thing to do. So just an example, sometimes you may want to check it, sometimes you may not want to check it. But the thing is that within a limited time frame, you should basically be exiting that particular process. Okay. All right. Here's another example. This example is also an interesting illustration of why recursive locks are a bad idea, right? So recursive locks are a bad idea here. Why? Because notice that mutual exclusion is required between the thread and the interrupt handler, right? And the mutual exclusion is being done using the id lock. Instead of making id lock like the way it is, if I made the id lock recursive, and the interrupt handler was actually able to get the id lock also, then bad things can happen, because you can take a lock, you could be in the middle of something, and now the interrupt handler gets called, now it takes the id lock, and it assumes some invariants which are not guaranteed to be true, right? So recursive locks, especially in presence of interrupts, are definitely a bad idea. In general also, you know, it encourages bugs, but if you're providing mutual exclusion with respect to interrupts, then recursive locks are a bad idea. Also, because I have, you know, I'm holding a lock, I'm trying to acquire id lock, I need to basically ensure that there's some kind of ordering. So any caller, it's possible that the caller is also holding certain locks, so this id lock needs to be ordered with respect to whatever locks the caller is holding. So, you know, one invariant it could be that the id lock will always be the innermost lock. You'll never hold id lock and then try to acquire another lock, so that way you can prevent deadlocks, right? So you have to worry about these things also. So another example of why locking and modularity don't exist, because here you have to worry about, okay, so I'm taking id lock here, I shouldn't be taking id lock somewhere else, where it's possible that you take the id lock and try to take id lock somewhere, you know, another lock after that. Okay, good. So with that, I think, you know, we have done a lot of synchronization, and synchronization was, you know, by far one of the most sort of important and practical topics in programming in general and in operating systems. Now I'm going to talk about demand paging. So we know that, we know, we've looked at virtual memory, and we saw virtual memory using segmentation, where there was a base and a limit. We also saw virtual memory using paging, and we said, you know, paging is more flexible, although paging has more overhead, because you have lots of page size, you need to maintain a page table. You need to maintain a page table. And so, but we said, then there is a cache called TLB. Right, so there's a TLB that caches page table mappings. Okay. And assuming that this cache has a very high hit rate, and this cache is very fast, and by fast, I mean, it's, you know, sub-nanosecond, and the time it takes to actually dereference the TLB is roughly equivalent to the time it takes to dereference a register. Right? If it's that fast, then, you know, paging makes a lot of practical sense. And so, you know, hardware developers have, so TLBs actually work in practice, because usually programs have a lot of locality, a lot of spatial and temporal locality, which means that the same locations are likely to be accessed over and over again. Also, if you access a location, then very likely you're going to access locations close to that. So because programs exhibit a lot of spatial and temporal locality, the hit rates of TLB caches are usually very high, and, you know, on the order of 99.99% or something. And so, you basically, you know, do not pay the cost of paging. Right? So the cost of paging was basically this dereference of page tables, which is costly, but that gets eliminated. And so usually, so here is how your memory will look like. So let's say this is the physical address space, and these are multiple virtual address spaces. Let me draw this with a different color. Let's say this is GCC, and this is, let's say, VI, and so on, this is browser. Then some page is going, the pages are strewn across like this in the physical address space. And these lines are page sized. You understand all this. Now in the simple world that we have discussed so far, we said that whenever you load a program, the entire memory of that program, the executable and whatever other data it needs, is basically loaded from the disk into the physical memory at load time. Right? So basically, initially, the program lives on disk, let's say GCC and VI, including its code and data. And as soon as you load it, we said that the entire, you know, there's some format called a.out for the executable, and so the a.out format is fast, and the loader basically creates an address space, allocates pages in the physical address space, creates an address space, and loads the entire contents of the executable into physical memory. All right? It's quite possible that, you know, the process was just started to stop immediately, or it's not going to access all the memory that it actually has in the executable. So it's going to access only a fraction of the memory that's going to do it. So it doesn't make sense to actually pull all the things at once. And so what you can do is you can pull things from disk on demand, and that's what's called demand paging. Right? So the idea is that whatever you basically, at load time, you just create an address space. All right? So let's say this is an address space. This is a virtual address space. And let's say this is the physical address space. And let's say this is a disk. Then you have created the address space. Let's say these, you know, these slots are pages. So some of these pages are currently mapped inside your physical address space, and the others are not currently loaded, and are actually pointing to the disk at some disk lock. Right? So it's not actually a loaded, so the page is not loaded immediately, but in the page tables, you have stored this information that this page corresponds to this particular disk block. All right? So, and you say that it's not present. This particular page is not present, so the present bit is off in the page table. And you have stored this information that this particular page actually lives on the disk at this particular offset. So when you run this process, you are going to, you know, if you don't touch this page, and you exit, you know, you have saved a lot of work. If you touch this page, then you basically take a, an exception. Right? An exception happens because you try to access a page that's not present. Right? And so this exception is called a page fault. If you try to access a virtual address that's not currently mapped in the page table, or it's not currently present in the page table, you take an exception that's called a page fault. The page fault will cause the operating system to run, the operating system's page fault handler to run on the kernel stack of that particular process. And in the previous discussion, you were saying that this, the page fault handler may want to kill the process, or it may want to send a signal to the process, depending on whether the operating system implements signals or not. But in this case, you may want to do one more thing, which is to check if this page is actually mapped to a disk location. And if so, it shouldn't do any of these, it shouldn't kill the process. In fact, you know, this is the operating system playing tricks under the carpet. The process was actually, you know, doing everything in good intentions. It's the operating system that's playing tricks under the carpet. So what it should do is it should allocate a page here. Let's say it allocates a page here, loads from the disk block to here, marks this present, and creates a mapping like this. Right? So that's called demand paging. And demand paging is a very, very sort of useful optimization, because, you know, for the common case, you don't need, all parts of the executable are not going to get accessed. Only some parts of it are going to get accessed, and so you save a lot of disk reads. Right? And also, you reduce the pressure on your memory. You don't need to allocate that many pages on your memory, so there's more free memory available on your system. Right? In general, you know, your system may be running only on a small amount of memory. Let's say your system is running on 512 megabytes of memory. Yet, you can, your operating system will allow you to load larger processes. So for example, your operating system will allow you to load, you know, gigabyte size process on a machine of size 512 memory. It's done because of the demand paging running underneath the covers. Right? Yeah. Okay. Yeah. Good question. We want to discuss it very soon. So basically, there's some instruction that tries to access that particular address, and so a page fault occurred. The operating system is going to get to run, and it's going to load the page, and now you will need to restart that instruction. All right? And so that's how it's done. Basically, you just restart that instruction. What you need to make sure is that if you run the instruction twice, or, you know, the first, if an instruction causes an exception, it doesn't cause any partial execution of its logic. Right? So either the instruction completes successfully, or it doesn't do anything at all and causes an exception. All right? So this is a property of the hardware, or the architecture, and this property is called precise exceptions. If an architecture supports precise exceptions, if there was an exception at an instruction, it is safe for the operating system to restart that instruction, and basically assume that nothing happened in the previous execution of that instruction. Okay? All right? So we'll continue this discussion next lecture."}
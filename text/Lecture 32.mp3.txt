{"text":"Welcome to operating systems lecture 32 and we're talking about file system implementation and yesterday or in the last lecture we were looking at on-disk data structures you know which is basically the file system is nothing but an on-disk data structure and we looked at two options one was a contiguous file system where contiguous allocation where a file or an inode is defined by or stores a base and a length and that's where the file resides then advantage of that is that contiguous bytes in a file are also contiguous on the disk so it makes a very fast sequential access of the file the bad thing about that is fragmentation and growth right so it is similar to what we saw with segmentation in virtual memory it has those problems the other on this data structure we looked at was a linked list which if you said that let the file or I know it contains a pointer to the first block and then each block has a 4-byte next pointer this gets rid of the problems of fragmentation and also growth growth is very easy fragmentation is no problem but it is very very slow right it's slow not only because of sequential access because you know for sequential access you have to just keep seeking because the file blocks will be strewn across all around the drift disk but it's especially bad for random access you have to actually traverse the entire linked list to get to any block in the file moreover notice that recall that our magnetic disk has this problem that you know it's it's it's better for to give lots of IOs in flight simultaneously recall that the disk controller is doing some scheduling internally and so it will be best for the OS to have lots of outstanding IOs for the disk so that the disk can schedule them in the most optimal way but if you have a linked list allocation then and you are traversing the linked list you can have at most one IO in flight at any time right because you have to wait for the first IO to finish and get the data before you get the next pointer and then you issue the next IO so there can only be one IO in flight and that's a really bad thing from a performance standpoint and the third thing we said was bad about it was basically reliability so one link goes bad or one block goes bad the entire file gets it's corrupted so let's talk about some more realistic file systems and one successful idea has been what's called FAT or file allocation table yes yes question okay so here's a suggestion that instead of using a singly linked list as I said let's have a doubly linked list and that would improve reliability by some degree but really would it I mean if you just firstly it's it has all those problems of being slow right so that's you know that's one big con of this the other thing is even if you have a doubly linked list if one block goes bad then the next point is gone and the previous point is gone so I don't see how okay I see I see so you're basically saying that inside my inode I could just store the pointer to my inode let's say for each block I could store a pointer to the inode and so I know that these blocks belong to this inode okay I see so if the block gets corrupted then you can travel in the reverse order you can travel from the tail and you can organize your data such as that two block if only if two blocks get corrupted then the file gets yes it's a valid thing you can you could do that but yeah so you know you could solve the reliability problem by adding more to this linked list idea but I mean it's it's bad anyways right it's bad because of performance reasons okay so so here is an here's a here's a very very nice extension to the linked list idea which is file allocation table first used in MS-DOS which was basically the idea is that this maintain this linked list not in the blocks themselves but have a separate file that maintains this linked list right so have a file which you will call the file allocation table right so this is the file allocation table or FAT and this has all these entries for each block and now inode just points to so inode points to the head pointer which points somewhere here and within this file you have pointers like these and so if you want to go to so a file basically points to some entry here and that entry says that the first block it contains the block ID okay so block ID or block number of the file and on the disk and so you can read that block so that's the first block and if you want to get to the second block you change the pointer from here right so let's say if you wanted to get to the NS block you need to do pointer chasing within this table you don't need to actually fetch the real block you only need to do pointer chasing within this table and the idea is that if this table is small it can be brought into memory in one go and then this pointer chasing can be done completely in memory right and so if you can do the pointer chasing in memory then you have eliminated much of the problems of the linked list allocation that we had before so let's see how big does this file need to be well for every block we'll have one entry right so what does the block mean a block could mean one sector or some small multiple of sectors right so maybe you know 8 sectors or 16 sectors the the MS-DOS block size range between you know 512 bytes to actually or 2 kilobytes for the FAT32 system to 32 kilobytes so a block could be anywhere between 2 kilobytes and 32 kilobytes the block size needs to be decided at a time of format right so a disk partition will have a constant block size throughout the life of that partition right and so depending on the block size you know you will basically name the name the disk blocks right and and so each entry here needs in so the the first incarnation of this idea was in the FAT16 file system and the reason it was called FAT16 was each entry was 16 bits so each entry was 16 bits and a block could be between 2 kilobytes and 32 kilobytes so what's the maximum size of a disk that you can support you could have at the most 2 to the power 16 blocks in your disk and each block being let's say 2 kilobytes so if the entry size is 16 bits the maximum size of the table can be only 2 to the power 16 right that's the number of unique blocks that you can address and so that's 2 to the power 16 blocks and into the size of the block so let's say it's 2 kilobytes then that's roughly 2 megabytes and 64 megabytes or 128 megabytes let's say the block size was 2 kilobytes and you have a 16 bit entry in your file allocation table you basically have a 128 megabyte disk that you can support with this organization so just to make sure that everybody understands it let's say I have an other file so let's say this is A's inode and this is B's inode then B's inode will point somewhere else and then it will have its own linked list to follow and one block will only be part of one linked list so one block can only be part of one file there's no sharing between files of blocks so for a one so the FAT16 file system with a 16 bit thing could support a disk of at most 128 MB doesn't seem very large by today's standard but at that time it was a reasonable size given the technology of that time roughly late 70s early 80s and what the size of my FAT16 table? 2 to the power 16 entries each entry being 16 bits so that's what 2 into 2 to the power 16 right that's 2 to the power 32 or 2 to the power 17 that's 128 kilobytes right so 128 kilobytes at that time memories were typically bigger than 128 kilobytes and so it was it was a reasonable scheme to have okay all right so but you know it doesn't make sense in today's technology so there's a there was a so it was extended to what's called FAT32 today and FAT32 had instead of 16 bits 28 bits for each entry and it supported block sizes between 2 kilobytes and 32 kilobytes and with this you can have a maximum file size of 512 gigabytes so let's say you have 2 to the power 28 entries what's the size of how big is FAT? 2 to the power 28 into 4 so each entry is 4 bytes that's 1 gigabyte and how how big can the disk be? 2 to the power 28 let's say I was using block size of 2 kilobytes then I have 2 to the power 28 into 2 kilobytes that's equal to 512 gigabytes so you can support a maximum size disk of 512 gigabytes with the FAT32 file system with a block size of 2 kilobytes if you want to have a larger disk one straightforward thing to do is increase the block size so you could you could take it up to 32 kilobytes and that way you can you know multiply this number by 16 what's the and once again the block size is decided at format time and just remains constant for the life of that disk partition so so what's the advantage of having a small block size versus a large block size what is the trade-off what are the trade-offs involved one clear trade-off is the larger the block size the larger disk you can support but what are the other problems firstly there is you know what's called internal fragmentation so I want I was interested in let's say 16 bytes you know in of the disk but I have to read the entire 32 kilobytes right so there is more extra things that you may need to read into the memory right you need to maintain the buffer cache in that way and also you so that's one thing so you need more time for the data transfer also you have you buff pollute a buffer cache so the more data you bring in the more data you need to evict and if that extra data is not really useful then you are polluting or buffer cache the flip side of it is the larger the block size the more the more spatial locality can be exploited right so it's really a trade-off between spatial locality and internal fragmentation so the larger the block size assuming your program has a lot of spatial locality a better thing to do is to have a larger block size on the other hand if it doesn't have that much spatial locality you know the smaller block size would have performed better all right okay what is the space overhead of a fat file system if I were to say you know space overhead of a file system I basically say amount of metadata divide by amount of real data so how much metadata is stored per unit of real data in in the file system well I'm storing let's say 4 bytes per per 2 kilobytes if I'm using a 2 kilobyte block then that's roughly 0.2 percent so that's not too bad that has a space overhead of of this file system okay what about reliability so let's first talk about efficiency right so what were the few things that we were concerned about when we talked about efficiency number one we wanted to say how good is sequential access so let's say I wanted to read the file sequentially from you know some X to X plus 100 or whatever and and so what should be my what should the speed be well in contiguous app it was great what do you think in linked list it was very bad what do you what do you think about fact it's better than linked list definitely better than linked list because you can you can you can compute in memory the list of blocks that need to be read a priori you don't need to wait for blocks one by one right so you get you know the exact hundred blocks these hundred blocks may be strewn across the disk so they may not be contiguous necessarily but you can give a hundred blocks on in flight to the disk so you can have 100 outstanding IOs simultaneously and the disk scheduler can schedule those hundred blocks efficiently and give you much better performance and the linked list allocation but it's but it's not as good as the contiguous allocation of course because the contiguous allocation would have take just use one seek and one latency and the rest would have been the data transfer time here you will have multiple seeks and multiple latencies but at the same time you know because you have so many outstanding IOs the the effect is amortized right the disk scheduler can schedule things properly what about random IO let's say I just want to say get to the offset X in a file is it is it any is it fast or is it slow it's as fast as it can be right assuming that the file allocation table is in the memory you just chase the pointers inside memory you figure out what disk lock you want to read and then you issue that that request just and now that's the minimum you need to do anyway yes right okay good so that's efficient so we have talked about efficiency let's talk about so this is time efficiency of course and then let's talk about reliability so these are some parameters we are sort of evaluating our file system design on so is it reliable okay and here's an answer provided memory is reliable no we're not talking about reliability in terms of we're talking about reliability in terms of durability of data you know it's we expect this to live for multiple tens of years if not you know more and so if this clip for that long the probability that one sector and the disk gets corrupted is very high relatively high right and but we also want and the idea of using this is that a data remains durable across tens of years let's say right so is it possible that one disk block gets corrupted and that causes lots of data loss in in in this organization well if the fat block gets corrupted so after the fat is also getting stored on the disk right so there's a fat block gets corrupted then yes you will basically suffer a lot of data loss so what's what's one easy way to fix it have multiple copies of the fact that's all right so have multiple copies of the fat I said point two percent overhead now it will become point four percent overhead space overhead but you know you'll have you know significantly higher reliability right so that's easy so typically you will have multiple copies of lab two copies of the fact in your on your disk to ensure the reliability question when we copy something or write something we have to update the table yes right right so you know when I talk about reliability I'm talking about of a stationary disk all right so what happens if you know what happens while while the program is running and some crash happens you know that's not going I'm not going to call it reliability I'm going to call it durability guarantees of the file system and we're going to discuss that very soon okay but I'm talking about reliability I'm talking about stationary disk and what's its reliability yes for fact 32 we cannot keep the whole fat table in memory but yes you I mean you so of course you don't need to keep the whole fact table in memory there is some caching that you can do there also you can treat the physical memory as a cache for the fact table itself and assuming there is locality of access in the fact table the cache should have a very high hit rate all right okay finally how do you bootstrap the system so in general for every file system so let's say bootstrapping by bootstrapping I mean how does the OS know where the fact lives right once it gets to the fact then it knows where all the files live that's no problem but how does the OS know where the fact lives well one you know one typical way to do that is let's say this is the disk and the zero sector we call is the boot sector so we don't use that for the file system at all okay the boot sector is completely independent of the file system it has nothing to do with the file system recall that the boot sector actually contains instructions that need to be executed at boot time so it has nothing to do with the file system and you know the first block is assumed to have some it's called a super block and this block contains information about the fact so here's the fact then the fact has pointers to everything right okay so fact is actually a real file system that that you use the other type another type of file system is called what's called indexed and the idea here is simple in the fact file system we had the I node point to the head or the first block of the file in an index file I node contains an index so here's an I node and it contains many rows and it has an index basically saying that the first block of the file is at this location the second block is at this location and so on so this is an index file so you have more information in the I node and so once you read the I node into memory then you can get to all the blocks of that memory of that I know this is an alternate organization you just have an index over the thing so let's see what are the pros and cons of this this index lives on this yeah definitely these are all on this data structure right so so now if I want to access a file and I know so this is called the I node right this index is also this index is stored in the I node so the I know needs to be brought into the memory and then you will look at the index to get the block right assuming that I know it was previously cached you know you get only you take only one disk access if the I node was not previously cached then you take two disk accesses one for the I node and one for the disk block right it's not very different from the FAT file system also you know you cannot you know it's not possible to store the entire FAT in memory or you may not want to store the entire FAT in memory all the time so sometimes you may take a miss on the FAT itself right so that it's very similar to that okay so so this is an index file system so what's the problem firstly how big can the index be right so how big can the index be you would want that the index is not bigger than the block right or the I node is not bigger than the block and so you know let's say your block size is block size let's say then block size divided by entry size and let's say entry size was so but by the entry size is the size of your index right and let's say typical block size is let's say you know just take an example it's a 512 bytes and entry size is 4 then you have you know 512 by 4 that's 128 entries and so what does it mean it basically means that there's a limit on the maximum size of a file that you can have right so what's the maximum size of a file you can have 128 entries into a block size of 512 bytes you know that's roughly 128 into 512 that's 64 kilobytes so you know index files look good but you know for example for a block size of 512 bytes I can only have a file size of 64 kilobytes a block size of 2 kilobytes will increase this number by a factor of 4 but that's not good enough so it's not it's not great because unless I you know increase the size of my inode so but so it's a it's a trade-off between the size of the index and the size of the file so you know the larger the index you can support but that also adds to space over here so what's a better thing to do now this is a one level index one level index can only grow to that you know one level index can only point to that much data so you want to have a two level index that's one way of you know we all studied things like trees in our data sectors course but if you have a two level index and the trade-off is that I have to make two disk accesses before I actually you know actually get to the block so actually three total disk accesses so it's not and is given that most files are small right so most of most of the files in your file system if you think about it are executables which are roughly few kilobytes in size or configuration files which are just small text files or code files dot C or dot H files or Java files these are also you know small relatively small files few kilobytes and so I want to optimize for the common case which is lots of small files but then I have some files that are very large right like log files which run into megabytes hundreds of megabytes or even gigabytes right so my typical workload or you know file distribution is lots of small files some very large files okay and I want to optimize for that so instead of having a uniform two-level structure what's done is you have a multi-level index what this means is that the first few entries are single level then few entries are actually double level which means they point to other indexes that point to more or blocks and then the last entry or last few entries are actually triple level or actually this is called double level yeah so then there's triple level which means you know it's a three-level hierarchy so what you have done is that for the common case that you have small file you have only one access in one metadata access and for for the other common case which is very large file small number of large files you will have to make two or three metadata accesses but those accesses are likely to be get the great or more times over a large number of blocks right after all that was a large file you're going to probably access a lot lot of blocks in that file if you are accessing it so that's let me draw this again this is a multi-level indexed file so let me take the example of a real operating system 4.3 BSD Unix and let's look at its file system structure which uses multi-level index file I I note contains this is I note contains 14 single 14 single level pointers each 4-byte next entry contains one W index pointer or indirect block one in you know the other way to call it so instead of calling it double index double level I'll call it one indirect so these are direct pointer and one indirect pointer that points to an index with 1024 direct point and last index so this is this one entry and then last entry points to one doubly indirect by doubly indirect I mean it points to a block that contains pointers to more indirect so it's a it's a three level hierarchy right so it's a two level hierarchy from here on here there's a one level hierarchy and here these are direct pointers so with something like this you have optimized for the common case which is that small files so no small files of size less than let's say my block size was 512 bytes then files of size 14 into 512 bytes that's 7 kilobytes the files of up to size 7 kilobytes will need only one metadata access to be referenced right files of size you know so one indirect pointers with 1024 direct pointer so that's 1024 into 512 bytes so that's 512 kilobytes so files of size up to 512 kilobytes will need two metadata accesses to be able to you know deal with them and then files bigger than that which can you know which can which will be 512 megabytes of larger or can be done using three metadata access that's basically done till you have a size maximum size limit on the maximum size file you can have so you know every file system will have some limit on what the maximum size of a file that you can have and but all you are doing is just making that limit really large and depending on the current technology that may suffice and or may not suffice depending on for example you know for a long time Linux didn't support files larger than 2 gigabytes right no example I remember till early 2000s you know Linux wasn't supporting files greater than 2 kilobytes but then you know future versions of the file system basically allowed bigger files depending on the hardware technology you will basically revise this as it goes okay so that's basically the file system structure we have looked at the FAT file system which is an in-memory linked list and then there's an index file system and both are widely used index file system is using Unix and also the NTFS file system is an index file system and the FAT file system is also you know by its name one of the things that you do worry about in a file system is what happens on a power failure or a crash you're in the middle of doing something and a crash happens and then you come back again your things may not be in a consistent state how do you deal with that right so one way to deal with that is that you you don't worry about it at all right you just say if a crash happens in the middle of something then I admire at reboot time I will run a program for example you know the Linux or Unix systems have this function program called FS check so you run the FS check program gets to run on a reboot and it will you know scan do a global scan over your file system and see if it finds something wrong and sometimes it may not be able to automatically decide whether what what should the fix be so if it finds something wrong what should the fix be it may not be or be able to automatically decide so it may need to actually ask the user and you know it's a it's a very painful decision procedure for the user to figure out you know what what happened and what could have what should the right thing to do and you're going to look at what kind of questions can come up and and what kind of things that can go wrong right the the problem with this the nice thing about this is that in the common case when there's no crash things can work at full speed and very simply no not no problem the bad thing about this is that the FS check program can take a long time in the early days 90s this used to be small so global scan was possible in a few seconds maybe you know tens of seconds or minutes but this sizes of 512 gigabytes to 2 terabytes you know these this stands and easily take up to you know half an hour or one hour or maybe more okay so that's a that's the cause of concern and so this technique while was used for a long time in real operating systems is no longer used and some other things are used the other so so that's one thing the other thing to do is basically say that I will ensure that you know so there's something called journaling and we're going to discuss what it means so journaling basically ensures that your updates to the file system are atomic with respect to the power failure right so there's a way to there's a way to ensure that updates to the file system are atomic so if a power failure happened in the middle of an operation then it's as though the operation ever took place all right so that's you know you maintain a data structure that ensures that on and on this data structure that ensures that it doesn't take place or and if it happened after the end of the operation then you know the operation so either the operation has taken place in full or not at all so that's atomic so one thing is journaling everything which means you journal both the metadata which is you know these inode structures that you have and the data of the user that that will provide you very good guarantees of over atomicity and the user can be sure that whatever he's doing is correct and the other option is to journal only metadata here you're saying that I will make basically make sure that my metadata or the inode structures and other things that I'm using for my file system are remain consistent across power reboots but the user's data may become an inconsistent right it's something similar to you know killing a process when you kill a process you make sure that the kernel side of state is cleanly freed right recall that you don't just free the process you just wait for the process to reach some clean boundary before you actually create but at the same time there's no guarantee for the user right the user could be in the middle of something and he can immediately get vanished right so it's a you and the user should expect that right so so that's the other approach which is usually only the metadata okay and we're going to discuss this again the other thing you have to worry about is of course efficiency so how do you provide efficiency well firstly you you know data structure design that we have already discussed so like them and this is basically about minimizing seeks so something that can be done here is locality so by locality I mean try to place blocks consecutive blocks of the file consecutively on the disk because assuming that the file has spatial locality it will automatically it'll directly translate into spatial locality on disk and so you will reduce the number of disks this seeks right so for example your disk defragmenter program that you may have seen in in some operating systems we'll do we'll try to improve locality to get better efficiency then you know intelligent indexes intelligent indices and example you know multi-level you have seen there could be you know you could use B trees and choose so B trees with carefully chosen values of B can basically optimize performance because your B can be tuned to the size of your block on the file system right so if you carefully choose B trees with the carefully chosen these then you can optimize these things and you know databases use this a lot and the other way to minimize seeks is what's called logging so here the idea is that try to make right to the disk as sequential as possible right so instead of right let's say I wanted to write 10 different files at the same time and these files are completely strewn across the disk so instead of going to each file separately and writing to them could I you know organize my data such as that that all these rights appear as a log and so it becomes one sequential right and that's what gets written to the disk and asynchronously it gets updated on the real file system okay and so you using that you can basically minimize the seeks required on the on the fast path which is you know when you waiting for the disk to finish so you can just log the data onto this in one go and asynchronously transfer it to the file and then we're going to look at examples on how to do this the other thing you can do is prefetching of course so you you read some data you have some algorithm which basically figures out that there's a lot of spatial locality so you prefetch data of course there's a there's a there's a trade-off trade-off about how much to prefetch and how much how much you cannot prefetch and overlap communication computation with disk access it's a good idea to you know while you're doing the disk access to also keep computing so that firstly you will keep your CPU busy and secondly your computation may lead to more disk accesses and that may lead to better disk scheduling overall right so we're going to look at you know so these are the basic sort of design principles on which we we're going to decide what is a good file system and it's not a bad file system but let's first start with a simple file system which is the x86 file system and let's look at a realistic implementation of a very simple bare-bone file system okay so so here is the x86 file system let's say this is my disk and this is block 0 that's the boot sector this is block 1 that's the super block and and then from block 2 to some number they have I notes then to some point they have what's called a free block bitmap and then you have the blocks and let's look at it so so the first two sectors are clear boot sector and super block the next few sectors are reserved for I notes it basically means that all I notes will be allocated from here right so all the so that basically immediately puts restriction on the maximum number of files that you can have in a system one advantage of putting all the I notes together like this is that often you may want lots of locality between your I notes right so let's say you are doing LS right so LS basically wants to look at all the files in a directory and all it cares about is you know things like last modified time and some characteristics that can be just you don't need to look at the data block you only need to look at some statistics about that I note right and so if lots of I knows are being read there's a lot of locality between the I knows and so you can service a lot of requests from here right but on the other hand conversely you also expect there to be a lot of locality between I know the data blocks right it's quite also quite likely that when you access an I note then you're going to access the data block corresponding with I note but this organization does not exploit that locality right so there's a trade-off then there's a free block bitmap which basically says which of these blocks are free so it's basically maintaining a list of free blocks right and basically using one bit per block indicating whether that block is free or not once again you expect that this free block bitmap is a very sort of hot region because if you're creating or deleting a lot of files or and so on or writing to a lot of files then you probably need to do the have this and so it's good to have this in a very local way so there's locality in free block right let's look at the I note structure so they use index files and the I note structure has 12 direct pointers and one indirect pointer block size is 512 bytes indirect pointer points to a block with 512 divided by 4 that's 128 pointers notice that the I note itself has only 12 pointers 12 plus 1 13 pointers where the indirect block can have more pointers right well the I note has also extra information to store like you know things like what what the permissions are who owns it what's the last modified timestamp and other things right so there's more information in the I note so that takes up some space so you have only space left for 13 pointers in the I note but in the indirect point block you have the whole space available for point so you can calculate what's the maximum size of a file that you can have you can have 12 into 512 bytes plus 128 into 512 right that's the maximum size of a file you can have roughly 64 kilobytes okay so what about directories our directories implemented directories are nothing but files but special the special in that the user cannot read them directly it's the operating system that can read it all right and it's the only the operating system that can interpret it right so directory is a file with records so directory entry and on xv6 it's represented as an array of directory entries so for example if you have a directory let's say you have a directory called slash foo then slash will point to an I know there will be some status file status flag in the I know which says I'm a directory all other files will have the status flag saying I'm a file but a directory so that so there will be a bit which say distinguish between files and directories and then just like everything else it will have pointers direct pointers so these are and these are data blocks but these data blocks will contain directory entries so basically of a directory is nothing but a file which stores directory entries in them and directory entries on xv6 are represented by a structure which is which is six size structure which contains two fields name and I know number so a directory entry contains two fields the name of the file or the directory right for so this name could be the name of file or the nested directory and the corresponding I know number and xv6 is you know I can I'll only allow names up to 14 characters long so you have a fixed size on how big the name can be I know number is fixed and so there's a fixed size structure of directory entry and that's basically you know used to implement directories what the maximum size of what the maximum number of files you can have in a directory let's say my directory so the maximum number of files I can have in a directory is basically what max size of file which we computed earlier which was let's say 64 kilobytes on xv6 divided by size of directory entry let me call it dirent so that's basically the maximum number of files you can have in a whatever the maximum size of file you can support that's the amount of space you can have for storing directory content and so you can have that many entries inside of that so if I were to draw a diagram let's say this is slash so that's the slash directory the root directory that points to an I node and these point to different so these have you know the name can be let's say use slash user it's pointing to another I node sorry so these point to data blocks right so I note themselves point to data box let's say the slash directory has only 10 files and 10 files can fit in one data block so you only have one data block all the others are 0 right and this data block will have directory which will be mapping names like slash user to I know numbers and they themselves may be directly which means they themselves may now have this structure within them or they may be files in which case these data blocks don't have any special meaning they are something that the user has defined so let's look at the xv6 I note structure once in detail a little bit you have a type which says whether it's free or directory or file right you have n link which says how many inward links do I have right what's the size the size basically means what the size of this file for for a file and for the directory it basically means the number of directory entries into the size of the directory entry right so in both cases size basically means the size of the data blocks the size of the useful content in this file or directory then you have the addresses or pointers we call the 12 plus one thing right direct and indirect so let's say I wanted to create a file so let's say you want to create a file on xv6 and let's say you did that using this command called echo greater than a so what happens you know just as a recap you're running the shell process you type this command it calls folk it calls exec echo echo program gets to run with its output redirected to the file a right now before but but a let's say does not exist earlier so the first thing the program needs to do the shell program needs to do is to create the file a right so let's look at from a disk perspective what all needs to happen for the file to get created let's look at this figure I want to create a file a so first I will allocate an I know how will I allocate an I know I will go through these list of I know and find the first one that's free so that's allocating and I know so that's one discusses and once when I allocate it I'll also mark it as as a file instead of a free flag I'll mark it as a file flag okay then I will update I note which size zero you've allocated an I note and you will update the I note with a size equal zero and you may want to update other things like n link etc for example now there's a directory that's pointing to me so you won't want to increment the end link of this particular and you may also you may also want to zero out all the direct and indirect pointers so you know so that's another disk access you could have potentially combined the first two disk accesses if you are if you are if you are being smart about it then you add entry for a in parent ID so how do you do this assuming that you know you basically look up the parent directory directories file and the file contents are going to live somewhere here and there you basically append to the directories file and another directory entry which has name equal to a and I node number equal to whatever you allocated what do you found earlier right so that's another disk right so I'm actually just counting the number of disk rights I'm not counting the disk reads at all here right you may actually need to go through the directory directory I node and the directories data blocks to basically get to that point and then you update the right directory data so in this case the updation of the directory data block means adding or appending to its contents so what's the last thing you need to do update the size of the directory right this you have appended to the file of the directory so you need to update the I node of parent directory particular size at this point you have created the file you have allocated an I node initialized it created an mapping using by appending a directory entry to the parent directory and updated the size of the parent I know okay so many disk accesses for one app operation so so let's stop here and we're going to continue this this method of looking at what happens on a file operation and in particular we're going to look at what happens if people can if multiple processes can confidently try to write to the same file for example or how does data get appended to a file and how do files get removed from a directory so what are all the operations that need to be done"}
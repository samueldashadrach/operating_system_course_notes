{"text":"So far, we have been looking at logging as a way of ensuring that the system can recover after crash. In other words, ensuring that the disk does not get so corrupted that you cannot even recover your data out of it. The first thing we had looked at was ordering, where we said that we're going to order the disk operation as they go to disk in a certain way so that we don't lose data. We may have space leaks, temporary space leaks, but they can be fixed whenever we need. But there were problems with that. The problem was that recovery was really slow, and the other problem was inconsistencies were still possible. Logging was the other way, where basically the file system consisted of a tree, which is your regular file system tree, and a circular log. You will have one transaction at a time. So I'm talking about the exe3 file system. You'll have one transaction open at a time, which you will close periodically. So let's say you close a transaction every five seconds, for example. And all the atomic disk operations that are started at any time will be associated, will be tagged with the current transaction, with the current open transaction. The atomic operation will either belong completely to one transaction or not belong to the transaction at all. It's not possible for an atomic operation to be half in one transaction and half in another transaction. Once you close a transaction, you also open the next transaction. So all atomic operations that start after you close the transaction will belong to the next transaction. All atomic operations that started before you close the transaction, irrespective of whether they have completed or not, will belong to the previous transaction. If they have not completed, the transaction will wait for those operations to finish before it starts committing them to disk. So all atomic disk operations are associated with the current transaction. And transaction is atomically committed after closure. And as we saw last time, committing the transaction, before you start the commit of a transaction, you have to wait for all the atomic operations to finish, number one. Number two, you also want to make sure that no atomic operations of the second transaction or the next transaction have started before all the operations of the previous transaction have finished. Otherwise, inconsistencies can result, and we have seen some inconsistencies last time. That can happen. We also said, in this case, we logged whole data blocks. Atomic commit of the transaction is implemented by the write of a special commit record at the end of the log. And assuming that this write of the commit record is atomic, you are basically sure that either the transaction will be atomically committed or it will not be committed at all. If it's not committed, it means nothing happened. If it committed, it means everything happened. So there's no intermediate state. So there cannot be any inconsistency, assuming that commit is atomic. So we have been, so far, assuming that the commit is atomic. We have been, so far, assuming that the disk actually behaves exactly like the way we expect it to behave. So, for example, we assume that if we tell the disk to write to a particular sector, it has written to it before it actually comes back to us. The truth, in fact, is that the disks have caches. So in the real world, disks are not really truthful, not necessarily truthful. You can imagine that disks have been manufactured by different manufacturers. And for better performance, these manufacturers are putting special, volatile caches, which means they're either using technologies, the same technology that you're using for DRAM for your main memory into your disk. And so even though the disk has said that it has finished, it may be doing some optimization at the back end where it may not have actually written to the magnetic platter, to the actual magnetic platter. So if something like that happens, then all your reasoning about correctness actually goes for a toss. Because if you ask the disk to write the log and wait for the disk to respond, and then you ask the disk to write the commit record, and the disk internally has cached the first write, hasn't actually committed to the magnetic platter, and it commits the commit record before the actual contents of the log, then when you recover, you will see that there's a committed transaction, but the transaction's contents may actually be junk, right? So these kind of things are possible, and so EXT3 doesn't deal with these kind of problems, but the next file system, EXT4, introduces checksums in the commit record. The idea is that the record, the commit record, will have a checksum or some kind of one-way hash of the contents of that transaction, right? So when you are recovering, you can check that the checksum actually matches the contents of the transaction. And if not, then you can say that something fishy has happened, and you shouldn't be actually replaying this transaction. So that's one way of dealing with these kind of issues. So as we have discussed logging, we were logging whole data blocks, both data and metadata blocks. If I were to look at the file system, and I was to look at all the blocks in the disk, I could divide the blocks into either they are data blocks, which means they are blocks that hold the contents of the files that the user is actually writing to, and there are other blocks which I can call the metadata blocks. Metadata blocks are blocks like the super block, the inode blocks, the free bitmap blocks, the directory, the blocks that contain the contents of the directory, even they are metadata blocks, right? So all the blocks that are associated with the semantics of the file system are metadata blocks. All the blocks that are not associated with the semantics of the file system are data blocks, right? So for example, the contents, the blocks that are stored in the contents of a file has nothing to do with the semantics of the file system. So they are metadata blocks, and everything else is metadata blocks. And so far, as we have discussed the logging file system, we are basically saying that we log everything. We log both data blocks and metadata blocks. But notice that logging data blocks is not necessary for making sure that your file system remains consistent. And the other thing is that logging all data blocks may actually be expensive. If you can avoid logging data blocks, and only log metadata blocks, and don't, so you avoid the 2x writes on the data blocks, you only do 2x writes on the metadata blocks, that's likely to be more efficient than logging everything, right? So that's actually the default mode. So exe3 has three, two modes, ordered mode, which says log only metadata blocks, and journal mode, which says everything. And the ordered mode is the default mode. So most of us, most people use the ordered mode. In the ordered mode, you only do this logging or atomicity maintenance for metadata blocks. But you need to be careful, because imagine if the inode has been committed, but the data block that the inode is pointing to has not been committed to the disk, then you will have a dangling pointer in your inode. So in the ordered mode, the invariant that's followed is that you will flush or write to the disk all the data blocks belonging to the transaction before committing the transaction, which contains the log of the metadata blocks. So in the ordered mode, you basically ensure that all the data blocks are written to disk before you commit the current transaction. That's all. So instead of logging the data blocks, you just make sure that there's an ordering relationship between the data blocks and the metadata blocks. And so the ordering relationship is something like this. You flush all data blocks before commit, transaction commit. So you flush all the data blocks before you do a transaction commit. Notice that in this EXT3, in this ordered mode of EXT3, I'm using both ideas from the logging idea and ideas from the ordering method. I'm saying I will flush all the data blocks before I commit the transaction. So let's see what happens. If I flush all the data blocks and I haven't yet committed the transaction and there's a failure, what can happen? Well, you have just updated some data blocks on the disk, but you haven't really updated the inode corresponding to those data blocks. So there's really no problem. The inode is probably pointing to the old data blocks. Some data blocks have been updated. Some have not been updated. But the file system remains consistent. The contents of the file may have changed partially, but the file system itself remains consistent. So it's possible that the user wrote 10 blocks, only 5 blocks have been written to disk on a crash, and 5 haven't. But the file system itself is consistent. So that's the important thing. So the difference between the ordered mode and the journal mode in EXE-3 is, ordered mode is not concerned about atomicity of full operations. Ordered mode is just concerned about atomicity of all the metadata operations to ensure that the file system remains consistent. It doesn't care about the user's size or the user's data. The user is really left on his own devices to basically make sure that his logic remains correct. So that's one thing. So now let's talk about how does the user... So firstly, I hope you are all convinced that using this method, we can be sure that the file system remains consistent. There are a few things one needs to be careful about, the few details about the EXE-3 ordered mode. For example, if you, let's say, delete a block, you cannot use it in a free list. So you cannot recycle blocks before a transaction commits, because otherwise there can be inconsistencies. So there are some details that I'm skipping over. But basically, at the high level, it's basically saying that you will flush the data blocks and you will not provide any consistency on the data blocks, but you will make sure that all the metadata blocks remain consistent. So how does the user... This gives no guarantee to the user. The user is doing something. How does he know whether what he has done has actually been written to disk or not? So for example, I've given you an example of an ATM machine. Let's say your ATM program was running on top of an operating system, and the ATM program said, I want to make this transaction, and he debits my account with some money and gives me the cash. But the debit hasn't actually been reflected on disk. So what's the device that the user has to make sure that the thing has been committed to disk? And so there's a system called fsync, or different operating systems can have different versions of this. And you can say, I want to flush the contents, the data blocks of this particular file to the disk. How will the file system implement something like fsync? How will exe3 implement fsync, let's say? In the journal mode. So there are two modes in exe3. There's a journal mode, and there's an order mode. So let's say in the journal mode, if the user calls fsync, what should the operating system do before it returns from the system call? It should commit the current transaction. It should commit the current transaction, and that's it. Does it need to wait for the transaction to get applied to the file system? Before it returns from fsync? How many say yes? One. Two. How many say no? Two. Everybody else is undecided, okay. None of the above. All right. So the answer is you don't need to wait for it to apply. Commit is enough. Recall that the semantics of the file system is that anything that's been committed is as good as done. It's just a matter of syncing the state to the tree. That's just something that you can consider as an optimization so that the next time you're looking through the tree, you don't have to go to the log to look at the latest contents. You can just do it from the tree itself. So as soon as you commit the transaction, it's as good as it's done on the disk, and it will persist across file systems. So when you do an fsync, the operating system just in the journal mode just commits the current ongoing transaction and so closes the current transaction and commits it before it returns. Okay. So let's say if there's a power failure after fsync and, you know, you recover, then the question is shouldn't you require that the tree is correct? Well, not really, right? I mean, at recovery time, you will just, you know, you know that there's a log. So the tree could be in an instance. The log is showing committed, but the log has not been freed because that the ASCII file system first commits the log. After the commit, it starts applying the log to the file system tree. If there's a failure in the middle or at the beginning of this application, it's okay. You know, you haven't freed the transaction. You've just committed the transaction. You will free it after the transaction has been applied completely to the file system. At that point, you will free the transaction. So in the journal mode, it's enough to basically commit the transaction and then return. So, but, you know, an fsync is a relatively slow call, as you can imagine, because an fsync cannot return without actually making a disk access. And that's expected. Right? Unless, of course, there were no dirty blocks in your block cache, in your buffer cache. On the other hand, most other operating system, most other system calls, which access the file system, don't actually need to go to the disk because we are using a write-back cache for the buffer. Right? So the fsync is a device for the user to basically make sure that things are getting flushed to disk. So what happens if the user is using fsync too often? System becomes really slow. Your write-back cache becomes completely ineffective. You basically come, you know, you basically start looking like a write-through cache. Let's say he's doing fsync after every system call. It's basically like saying that every system call becomes one transaction. So this system becomes really slow. Right? And it becomes even slower for something like a transaction, from something like a logging system like exe3. Right? Exe3 logging was actually heavily relying on the fact that you're batching lots of writes. You're doing 2x writes, but because you're batching them, the performance is not really 2x slower. Right? But if the user is actually calling lots of fsync, you are actually 2x slower. You're writing small transactions to the log, and then you are applying them to the system tree. Okay? Let's see, what about the ordered mode? So if I'm using the exe3 ordered mode, and if the user calls fsync, what do I need to do? I need to flush all the data blocks, and I need to commit the transaction which contains all the metadata blocks. Right? That's all. So what are some types of applications that require fsync? Right? That require that data be on the disk before, you know, you do something. And most of these, such applications are usually what are called transactional applications, or transactions, where, you know, an ATM transaction is an example of that, or a bank transaction is an example of that. You basically want that, you know, you basically have committed to the disk before you actually display to the user that your amount has changed, or you actually dispense cash to the user, et cetera. Right? So you would want something like that. And how are such applications typically implemented? These such applications are typically implemented by using what's called a database. Right? So database basically maintains all the state, you know, who has how much money, et cetera. And database is supposed to give you guarantees that, you know, if you have said something, you've asked the database to do something, it has actually done it on disk, it has committed the whatever operation that you've done, by a commit in a transaction of a database, you basically make sure, basically mean that the data will persist across power failure. So if you're running a database on top of an operating system, you know, as an application, then the only way the database can provide you those guarantees is by calling the Epsilon call. Right? So database is an example, a user space database, or a database running as an application is an example of an application that makes a lots of, lots of extreme calls, and is likely to be very slow on something like this. Right? And that's the reason you would typically implement a database as a standalone system without an operating system below it. Right? So you won't implement a database on top of an operating system, because you have two layers of management of this, it's, you know, if the disk, if the data, the database should optimize itself. If the database had direct access to the disk, it would have been able to optimize these things much better. Right? As opposed to sitting on top of an, a file system like EXE3. On the other hand, most other applications don't care about persistence for transactions or, and so they, they can run easily, and they don't need to call Fsync calls, and they perform excellently on something like EXE3. Does the DBMS have the privilege levels to access the disk directly? Well, I mean, so, so I said there are two ways to implement a DB, a database management system, DBMS. One is you implement it as an application on top of an operating system, in which case it cannot access anything. The other thing, way to implement a DBMS is to implement it as a kernel itself, or within the kernel. Right? In which case it has all the privileges. Right? And so what I'm saying is, you know, here's a very good example why you would want to implement in the kernel, as opposed to doing it at the application level. Because if you do it at the application level, you have to go through the operating system interfaces, and the operating system is playing tricks underneath, and then you want certain guarantees out of it, and so the total performance, some total performance, is really not what you would like it to be. On the other hand, if the database had complete direct access to raw disk, it would have been able to optimize these things much better. Okay. So, so that's, you know, I'll finish, I'll wrap up the topic on file systems with this discussion, and I'm moving on to the next topic, protection and security. Okay, so we all know that we need, you know, we need lots of security or protection guarantees from an operating system. Your files on the shared infrastructure, like the shared lab that we have, shouldn't be readable by other people, shouldn't be writable by other people. And so on. And so you have a notion of these are, you know, these are my files, these are your files. You also have, firstly, you have a notion of identities, so there are different identities. Each of us has a different identity in the system, right? So protection and security is made up of three things. Authentication, which is a method of saying who is who, right? So our login IDs or, you know, some other names basically say that who is, who is behind this action. So we associate, we have some notion of entities, and we basically have some way of ensuring that this person is behind this, this action, or this entity is behind this action. This entity is also called principle. So authentication identifies the responsible principles behind each action. Then there is authorization. So this says who is the principle behind, I'll say this, authorization is what can the principle do? Basically say that user XYZ can access files ABC in read mode and access files DEF in write mode and so on, right? User root can access all files in ABC in read write mode, for example. So these are all examples of who can do what, right? So that's authorization. Who is authorized to do what action? And then there's access enforcement. You have, you have a method to do authentication, who is behind this action, you have a method to do, you have a method to do authorization, what can this principle do? And then there's an access enforcement, which ensures that only legal things are possible, which means only, only things that a principle is allowed to do is, is possible, right? So these are, these are, these are the three sort of aspects of protection and security. And if there's a flaw in any one of these, then there's a security attack. So let's say if there's a flaw in the authorization and you can impersonate as me, then you can do anything you like. If you can make, you can add a flaw to the authorization table and say, you know, I can do something that you're not supposed to do, then there's a problem. And thirdly, even if you have all these things correctly, but if the access enforcement is not correct, then you know, there's a problem. Okay. Let's look at, you know, how these things are done. Authentication. Let's say passwords, you all know what a password, they are relatively weak way of, of establishing user identity. Usually stored. Obviously they are secret and stored in unreadable form or not directly readable form. The way passwords work is that you store, so let's say I have a password on a system, then you will use some kind of a one-way hash, let's say there's a, there's a famous, there's a popular one-way hash called SHA1 and you will apply the SHA1 to my password and you will get a large string. And this is the string that you will store on your file system. And this, this function is what's called a one-way function. So by one-way basically means that it's very easy to get this string from this password, but given the string, it's very, very hard to recover the password, to know what the password is. So it's, it's very hard to recover. So even if you have the string, you will not be able to, you know, get the password. And so even if you have the string, you will never be able to log in to the system because you'll not be able to get the password. So that's, that's typically how you will store these things. The, the best attack, you know, assuming that, you know, our cryptographic algorithms are correct, our axioms in computational theory are correct, then the only way to guess or to break this password-based authentication is through brute force attacks where you basically go through all possible passwords up to a certain length and you basically check. And so there's, and so the way to make this secure is to make sure that your passwords are long enough so that brute force attacks are relatively ineffective. So that's basically, that's pretty much mostly how authorization is done. Alternate form of authorization is badges. If everybody has a badge, a badge could be something, you know, a card that you're using to authorize yourself, or it could be a USB, USB device that you have to plug in, et cetera. It's, it's, it's, the advantage of something like that is it doesn't have to be kept secret, it should not be forgeable or copyable, but, you know, if it's stolen, then at least the owner knows that it's stolen and can register a complaint, et cetera, and, or change the, change the authentication mechanism, okay? If you're using badges, you know, there's an interesting paradox that the badges should be easy to make, or cheap to make, so that you can distribute lots of badges to lots of people, but it should be very hard to duplicate badges, so it shouldn't be possible that if you have a badge and I just get access to it for a few, for some time, I shouldn't be able to duplicate it. So, you know, there should be some technology there that ensures that it's not possible to duplicate it, and yet it should be very cheap to go to manufacture. Once authentication is complete, you basically, all the actions that are performed are basically done with that particular principal's ID. What does this mean in the context of an operating system? It basically means that all the processes run with that user ID. So basically, on Unix, every process associated with UID, right? So recall that process control block that we had for every process, so apart from all the other meta information, another information that you have is basically who is the user ID of this particular process, and that, so whichever process is running, you always know who is the UID of that particular process. All right. So let's see authorization. So who is authorized to do what? First, let's look at the, you know, what does authorization mean in the most general sense? Authorization is nothing but a matrix. Here, let's say you have one row per principal. So these are principals. Let's say this is user A, user B, and so on, and on the columns, you basically have objects, for example, file A, device B, memory region C, and so on, right? These are all examples of objects that you have. And this authorization table basically says that user B is allowed to access memory region C or not, and in what way? So let's say read or read plus write, et cetera. That's basically at a logical level, that's what an authorization matrix looks like, and this is also called an access matrix. So this is a logical representation of who is allowed to access what, but different things different authorizations are implemented, so this is the logical authorization mechanism, but different authorizations or different authorizations for different types of objects are implemented in different ways. For example, authorization for memory is implemented using virtual memory subsystems like page tables and segmentation, right? So whether you are allowed to access this particular region of memory or not is basically authorized, the authorization is implemented using some kind of a page table. Authorization for a file is implemented in a different way, okay, so we're going to discuss that very soon. So in practice, you don't store the full access matrix, there are two ways to store the access matrix, either you store what are called access control lists, or ACL, per object. So here you're basically saying that I will organize things by column. So who all are allowed to access memory C, or who all are allowed to access file A? I'm going to have, with file A, I'm going to have a list of all the users who are allowed to access it, and in what way are they allowed to access it, whether read or write or execute or whatever else. So that's an access control list. So per object, so organized by column, per object, list of user privilege pairs. So let's, now this list can actually become really large, so typically, typically makes groups and indicates that this particular resource is accessed by this group. So you organize users into some groups, and you say that this particular file is accessible by this group, so all the users in that group can access it with those privileges. Let's look at it in practice, Windows allows, Windows implements ACLs per file, very general. So on Windows, you can go to, you know, the properties of a file and specify a long list of which user is allowed to do what, right, so here's an example of a reading system that allows very general ACLs. Something like Unix has nine bits per file, I'm going to see what these nine bits are. So Unix ACLs, so firstly, it divides, so let's say, I'm talking about a file, it divides it into, it divides all principles into three types, owner, group, and others, and read, write, execute, so this becomes, so there are nine bits, there could be zero or one, so that's basically the Unix ACL. Every file is associated with one owner and one group, right, so every file on the Unix file system will say, you know, the owner is user A, and the group is group B, and you know, the creator of the file, or the owner of the file can choose which group this particular file belongs to, or is owned by. And then you can have ACLs of this type, which basically say that this particular user is allowed to, so the owner can do these things to this, so for example, the owner can read and write, but not execute this file, you may want to say that. The group can read the file, but not write to it, and others, everybody else should not be able to either read or write, so let's say here's an example, this is one, this is one, this is zero, this is one, zero, zero, and this is zero, zero, nine bits to ensure, to basically implement ACLs. So clearly this has less, less generality than a complete list that you had on Windows. There's another thing about Unix, there's a special user called root, and root user is allowed to do everything to every file, right, so for the root, this access matrix is not, these nine bits are immaterial, the root user can do anything to any file, for example. Yes? Should the group permissions be a subset of owner permissions? No. No. See, it's a full nine bits, so you can do whatever you like. Alright. Okay, so that's basically, that makes it, the advantage of doing this is that you have a bound on the size of meta information that you have, you can store this information, you can hope to store this information in the inode of the file, as opposed to an unbounded list of user privilege pairs, which will be very difficult to write. Apart from this, so, Unix also provides an interesting thing, which is a setuid bit on the file. So this basically says, so by default it's zero, so it's the default behavior, whatever you expect. So let's say this file is one, then this file, if executed, can run with privileges of its owner. Every file also has one bit, which is called the setuid bit, if this bit is set, then you can run, you know, if some, if let's say I'm running, I have a file in my home, my directory, and I've set the setuid bit to one, then I'm basically allowing anybody else to run this program, and, with my privileges. So for example, this program, if run, so recall that I said that any process that user X invokes will run with the privileges of user X. But if this process is executing a file that had a setuid bit set, or one, then this program can also execute with the privileges of the owner. Why is this required? Let's first understand what's the application, why do you think this kind of a thing is required? If this executable file needs to execute some other executable file, so, I mean, let's say all the other ones are also executable by others, so, you know, then there's no problem. Why do you need this? Are you, I think all of you are using an executable called setuid, you know, through the course of this project, or this course. All the scripts that you're using on Palasi are actually setuid files, right? So if you want to submit your assignment, so what I've done is I have a script which is living in my, I have a file which is living in my home directory, whose owner is, you know, whose owner is me, and, but when you run it, you can actually, you have the privilege, my process has the privileges to write into my home directory. If, for example, it copies files from your home directory into my home directory to make the submission. So how can the process that you are invoking have the privileges to write to my home directory? Right, I said all the processes that you invoke will run with your privileges, and you don't have privilege to write to my home directory, right, so the way to do that is basically to make, to basically allow this file to be executed with my privileges, right, so that's what the setuid bit allows you to do. The setuid bit allows the owner to say that this particular logic, you know, I have tested this particular logic, and this is safe, and I allow other people to run this piece of logic with my permission so that they can access resources that I could access. Isn't it similar to saying that, you know, I have an execute bit set to a file? Now what's the difference between a setuid bit and just saying that this file is executable by others? Right? If I just say that this file is executable by you, you'll be able to execute it, but this process that will execute out of this, you know, out of your invocation will execute with your privileges, not with my privileges, and so it will never be able to touch my files or write to my directories. The setuid allows you to not just execute the file, but also execute it with the privileges of the owner of that file, which also means that if there's a bug in this program, then you can trick this program into, you know, doing things that I wouldn't want you to do, for example. Okay? So also, this, you know, typically when you do these things, for example, the submit script that we have will not just, is not just capable of writing to my directory, it's also capable of reading from your directory, irrespective of what permissions you have for your directory. So if your, if your permissions for your directory are saying that only I can read to this directory, yet this particular process that, you know, that can run as my privileges can actually access your particular directory. So this process can either, can switch between your privileges and my privileges. Right? So how is this done? Well, I said every process has associated with a UID, which says, you know, who owns this. Actually, every process has two identifiers. One is called the UID, and another is called the real UID, right? And so a process can switch between its UID and its real UID at will, right? So using system calls, it can basically say that now I want to run with the privileges of my real UID, and then I can say I want to now run with the privileges of UID. By default, if the UID bit of a process is not set, then you, then real UID and UID are equal to your, your UID, who is invoking it. But if it's, if it's set, then, you know, real UID will be your UID, and the UID would be, let's say, the owner's UID. And so the process has flexibility to switch between the two. So when I want to read from, when this process wants to read from your directory, it should switch to your UID. When he wants to switch to my directory, he wants to, he should switch to my UID, right? That basically allows you to do this, okay, right? The other way to implement access control are capabilities, what's called capabilities. So we looked at access control lists. The other way to do access control is called capabilities, where you organize by rows, right? So where basically you organize by rows, the, the access matrix. So per principle, list of, you know, list of object privilege pairs, let's say. So user X is allowed to access all these files, or user X is allowed to access, so you, you know, you store this information in, per user, as opposed to per file. That's the other way to implement this. So let's see, what are some examples of capabilities that we know about? Here's an example, file descriptors. So every process has a set of file descriptors that basically say that these are the files that I can access. Or I have already opened, so I can, you know, I can access it in X, Y, Z way. And so basically, a process can be thought of as, as a principle, and all these files or these, these pointers to file blocks or structures that, that represent open files can be thought of as objects, and you're basically storing file descriptor tables, that's your capability list. What are the capabilities that this process has? So one, some advantages of capabilities are, let's say I spawn a new process, so it's very easy to delegate. So if I want, I have some capabilities, I want to give you those capabilities, I just give you my table, and, you know, you have the same level of capability. For example, forking a process involves giving my capabilities to my child process, all right? So that's, that's, similarly, you know, let's say memory management, so virtual memory. So you basically say that, you know, what are areas of memory are you allowed to access? This is kept per process. So it's a, you know, it's a capability list per process. In general, the advantage of capabilities is that it's very easy to delegate, so you can, you know, giving, if I have some capability, I can give you the same capability by just giving you access to the same table, basically, right? The other thing is capabilities are also a little more secure in the sense that only if I have a capability can I even name the system, right, name the object, right? So capabilities are also used as a way of naming the object. For example, if I, you know, if I have an, for example, virtual memory, so I can name this particular location because I have a capability of accessing that particular location. Another process who doesn't have the capability of accessing this location will not even have the name on, or the way to access that particular location. So in general, you know, capabilities allow private namespaces, right, basically you have a namespace for this process or a namespace for this user and a namespace for that user, and this user doesn't even know that those files exist, you know, or those resources or those objects exist, which are in your capability list, whereas if you have access control list, the entire namespace is public. So capability systems discourage visibility. Namespaces are private by default, and so they are also thought to be more secure than access control lists in that sense. And there have been experimental systems that have tried to use capabilities for file systems instead of access control lists, but, you know, they tend to be a little clumsy for file systems, but they are used for other things, like, you know, virtual memory systems, et cetera. They're also used in distributed systems a lot, and capabilities are also implemented using cryptographic means, right? For example, a capability could involve a signed key or a signed certificate. So let's say I got a, you know, if I want to authenticate to somebody, I can use, or I can use a certificate from somebody. So if I want to prove my authorization to access a resource, I can show a certificate from somebody else to show, say, that I can access this particular resource, right? That certificate, so capabilities can also be implemented using cryptographic means, basically. All right. Okay, finally, there has to be some way of enforcing access. And for a kernel, so what does access enforcement mean? So we've seen ways of saying that here is how you authenticate. You authenticate using passwords or badges or some, you know, biometrics or whatever. Then you have some way of authorizing, which includes access control lists or capabilities—actually, access control lists or capabilities. And you know, depending on—so, and there's a tradeoff on how much space you want to take to represent this stuff, and how much generality you want. We have seen some—an interesting example of Unix versus Windows. And then you have some way of ensuring that these things actually are obeyed, right? So this basically means that some part of the system should be responsible for enforcing this, and this part of the system should have total power on everything. So there has to be some part of the system which has total power, and it's basically—and this part of the system is checking and saying yes or no to access controls. And for an operating system, this part of the system is the OS kernel, basically, which has total control and is going to do authentication and authorization. So let's look at some attacks. So why do, you know—let's see, what are the most—what are some kinds of attacks that happen? What does a security attack mean? So we keep hearing that, you know, X, Y, Z—there's X, Y, Z vulnerability, there's this attack and that attack. So what do these things really mean? Basically an attack means that a user has—it basically means that a principal has been able to do something that he was not authorized to do. And the most common way of doing an attack is basically what are trojan horses. Trojan horses are basically—so derived from the mythical tale, a trojan horse basically means that a useful program that was supposed to do something legal and meaningful is subverted to do—and had privileges of—or had higher privileges than what you have—is subverted to do something that it was not supposed to do. So that's what a trojan horse means. So let's see where all—what are some ways of implementing trojan horses? Well, let's, you know, let's take the extreme case. If you could potentially subvert the kernel, you know, that's the ultimate trojan horse that you can have, because that has the ultimate power. And if you can subvert that—the access enforcement engine itself, then you have basically done—you can bypass everything else. Similarly, you know, if you could subvert a program that has a set UID bit set, then you can get control over that particular program's resources. Many programs, you know, especially in the older days, so many programs in our systems run with set UID bit set and owner as root, okay, so which basically means that this program is going to execute as the root owner, and the root can—will execute with root privileges, but anybody can invoke it, right? So let's, you know, let me give you some examples. So let's say, you know, there's a program called mail, right, that I can give some file to it, and it will copy it to the destination user's mailbox. So let's say there's a program that I provide in my system that's called mail that says, basically, I—you know, that takes an argument which is some text or some file which contains some data, and I say I want to mail this program to this particular principle, and what this program is going to do is copy that data to that person's mailbox, let's say this is the program. So this particular program, in the older days, would run using root privileges, because this program—so this program will be a program which will be owned by the root user, and will have the set UID bit set, because this program requires the capability—because I can name anybody in my—in the—in my destination—in my recipient field, and so this new program should have the power to write to anybody's mailbox. And so this program, for that reason, needs to run with the root privileges. At least for some time. And so—and with the set UID bit set. So if I could subvert such a program, then I can basically get—do anything that the root user could do. And there are many types of attacks which are not the subject of this course that can allow—so there are many kinds of common bugs in programs that—they were very common 10 years back, not so common today, so it's harder and harder to find bugs in programs that can be subverted. It was very common to do that 10 years back. And if you could—if you could identify the bug, you could exploit it to actually be—ask the program to behave in a certain way, which the programmer didn't expect it to behave. In general, you know, when you have programs of this type, there's—you should follow what's called principles of least privilege, which basically means that if there's a program that's running—so if you have a large program, let's say—let's take the example of the mail program, then it should try to run with the—so it has—this mail program has a set UID bit set, so it can either run with root privileges or run with my privileges. So the program should run with the least privilege at any time. Least privilege is required at any time. For all the operations that don't require root privileges, at that time, the program should be running with my privileges. So basically what that means is all the code that gets executed during that time, if there's a bug in that code, then there's no problem, you know. Or, you know, actually, there are fewer problems, as opposed to if you run all the time with the root privileges. Okay. All right. So with that, let's finish. And we're going to discuss another topic next time, which is called scheduling."}
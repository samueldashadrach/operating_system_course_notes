{"text":"Okay, so welcome to Operating Systems Lecture 25, right. So last time, we were discussing producer-consumer examples, and we were, you know, the example that we had was there is a network thread, and there is a server thread, and there's an incoming queue of network packets, and there could be multiple server threads, for example. And similarly, there's an outgoing queue, and there could be multiple server threads, and there's a network that's picking packets from the outgoing network queue and putting them on the wire. In any case, there's kind of a pattern where there's a producer and there's a consumer. So there are some producer threads, and there's some consumer threads, and there's a shared queue in the middle, and the packets are being processed in the queue in a FIFO order, first in, first out, and the producer is supposed to produce elements, and the consumer is supposed to consume elements from, right? And we said that there are synchronization problems with that, of course, because, number one, the queue itself is a shared structure, so all accesses to the queue and to the pointers in the queue have to be protected using locks, because, you know, shared accesses to shared, I mean, concurrent accesses to shared data is dangerous, so you should protect it with a lock. Not just that, you have to make sure that a producer doesn't produce to a full queue, and a consumer doesn't consume from an empty queue, right? So those are the two conditions that you have to satisfy, and so not just, not only do you have to maintain mutual exclusion, you have to also maintain these two invariants that, you know, that a producer shouldn't produce to a full queue, and a consumer shouldn't consume from an empty queue. So let me take, go through this example in a little more detail, so let's say this is my, this is my circular array that I'm using to represent a queue, it has max elements, I have two pointers, head and tail, initially I set head and tail to zero, and then, you know, we looked at it last time, and we said to ensure that a producer doesn't write to a full queue, the producer should check for the condition, and if the condition is not true, then it should wait on this condition variable called not full, right? And somebody will basically signal or notify this condition variable, and so then the producer can, you know, then proceed. And similarly the consumer should check if the queue is empty, and if it is empty then it should wait on this condition variable called not empty, right? And then there should be a lock which basically does mutual exclusion, and today I'm going to, I'm calling this lock, I mean the name of this lock variable is mutex, you could name it anything, but it's very common to name it mutex to make it clear what the meaning of this lock is, this lock is basically for mutual exclusion, and it's common, it's common practice to use the word mutex to represent a lock which is basically being used for mutual exclusion. All right. Okay, so let's see how a producer works. The producer needs to first acquire the lock because it's going to operate on the read and write shared data, so it acquires the mutex, and then it checks whether the queue is full, and in our case, you know, because it's a circular buffer, checking if the queue is full involves checking if head plus one mod max is equal to tail, and notice because I have the lock, you know, I can do this, you know, without having to worry about concurrent accesses, concurrent changes or reads or writes to head at all, right? And if not, then I should wait on this condition variable called not full, and the second argument to this wait is basically the mutex, and the semantics of the wait are basically that it will release the lock or release the mutex just before going to sleep in an atomic fashion, and after it gets woken up, the first thing it will do is try to reacquire the lock, right? So basically the idea is that it will release the lock before sleeping, and it will reacquire the lock after it wakes up, right? And the condition that's waiting on or the condition variable it's waiting on really is called not full, right? Now if it gets woken up by somebody, so, you know, somebody calls notify on not full, what will happen? It will eventually, it will, the next thing it will try to do is try to reacquire the mutex, and if it is able to reacquire the mutex, it will come out of the wait. In this code, the first thing you will do is you will check the condition again. Why do I need to check the condition again? Let's hold that discussion for a moment, so let's say, you know, you check the condition again, and, you know, assuming there was just one producer and one consumer, and the consumer has just notified me, basically means that there must be some empty space in the queue, right? Somebody has just consumed something, and he has notified me, so there must be some empty space, and so this condition should be false, right? And so you should get out of the loop, and at this point, you can be sure that there's empty space in the queue, and head is pointing to that first empty slot, and you produce in that empty slot, right? After you have produced in the empty slot, you may want to notify the consumer. In this case, I'm actually notifying every time, but, you know, you may want to be more efficient. You may want to say, if, you know, if queue has one element, only then notify. Don't keep notifying unnecessarily. Only if you have just transitioned from 0 to 1, you know, or you have transitioned from an empty queue to a non-empty queue, do you need to notify the consumer, and consumer will have a very symmetric code, right? So if I just look at the consumer code, you know, same thing, you acquire the mutex, you check if the queue is empty. This time, I'm not, I'm writing it in English instead of the actual condition, right? I'll wait on not empty, and mutex, just like before. At this, if I come out of wait, I'll recheck the condition, and if I had just one producer and one consumer, this condition will always be false, and so I'll come out of the loop, and then I'll consume one character, notify not full, release the mutex, okay? Alright. Okay, so, so now, why do I need this loop, right? Can I be sure that if the producer comes out of the wait, the queue is definitely not full? Somebody, so you say no, why? Okay, so yes, I mean, if there are multiple producers, it's possible that even if you come out of the wait, the queue is still full, right? Why can it, how can it happen? Let's say, you know, there were two producers, both of them found the queue to be full, and both of them start waiting. Now one consumer comes along, and he consumes an element, and then he calls notify. Notify will have the effect of waking up both the producers, let's say, right? And so both the producers will wake up. One of the producers will be able to get the mutex. The other producer will wait on the mutex. The producer who gets the mutex will, you know, check the condition, he'll find it false, he can produce one element, but at this point, he has made the queue full. When he releases the mutex, the second producer will be able to get the mutex, he will come out of wait, and it's not okay for him to just go and start producing, he should again check the condition. So the invariant is not that when you come out of wait, the condition has definitely become false, right? You went to wait because the condition was true, but it's not necessary that when you come out of wait, the condition is necessarily false. So hence you need to recheck the condition after you come out of wait, right? And so you need a while loop instead of an if, which we had last time. On the other hand, if you had only one producer and one consumer, if would have sufficed, right? But it's always safer to, you know, use while, I mean, just to make sure, I mean, then you are basically relying on more invariants in your code, etc. So it would have sufficed if you had just one. So if you had just one producer and one consumer, you could have replaced this if while within if. But if you have multiple producers, then you need a while. Similarly, if you have multiple consumers, then you need a while here, right? Okay. All right. So this is a very common pattern. So let's understand how a condition variable is used in general, right? So in general, so I've taken an example of a producer-consumer example to illustrate how condition variables are used. But in general, a condition variable cv corresponds to some condition, let's say cond, right? And you would typically want to check the condition. And you would typically want to check the condition in some kind of a loop. So while not cond, you will wait on cv. And because, you know, you want to make sure that the checking of the condition and the act of actually waiting should be atomic with respect to each other. And also you want to make sure that there is mutual exclusion maintained in your checking of this condition. You would typically want to also use a lock or a mutex, right? And that's the mutex you will pass as the second argument of this, right? This will be the general pattern. And of course, you will do something here and then you will release the mutex. And you may want to notify or not notify depending on whether you expect somebody else to be waiting on a condition or whether you have made some other condition true or not, right? So this is a general pattern in which a condition variable is used. You take a mutex, you check a condition, and if the condition is false, then you wait. But you don't, but you generally put the wait inside a while loop so that when you come out of wait, you recheck the condition, right? Because the condition, I mean, may have become false by the time you actually came out of wait, just like in the producer-consumer example, right? So general pattern. All right. Okay. Now I'm going to talk about another abstraction, which is semaphores. So far, we have seen two abstractions to do synchronization. One are locks, and locks were basically used for mutual exclusion. Another was conditions, condition variables. These were basically associated with conditions, so waiting on conditions, right? Semaphores is yet another abstraction, and they are basically, you know, the abstraction if, you know, most concisely described, it's something that enables you to count, all right? And I'm going to discuss exactly what semaphores mean, right? So we have looked at these two abstractions already, and today I'm discussing semaphores. And let's see what semaphores are. So semaphores, you know, basically a common pattern in programming is basically like the producer-consumer example involves counting of resources, right? So in the producer-consumer example, the resources were the slots in the queue, right? So there were, let's say, max slots in the queue, and you wanted to make sure that, you know, you never go to max plus one. So you never, you know, so those are the number of resources, and you're trying to count the number of resources. So the producer has to count the number of full slots, and similarly the consumer has to count the number of empty slots, and so on. And so this is a very common pattern, and in 1965, Dijkstra, whom you probably also know from his shortest path algorithm, you know, proposed this abstraction called semaphores, right? So semaphores are basically, you know, defined by a type, let's say it's a struct sema, right? Just like there was a struct lock and struct cv, there is a type called struct sema, and this is a stateful type, all right, let's see, and then there are three functions. There is void, semainit, struct sema, and int. So semainit takes the first argument as the semaphore variable, sema, and the second argument as an integer value, which must be, and basically it sets the counter inside sema to be equal to value. So it just initializes the semaphore to that counter called value, right? So basically semaphore has a state called counter, and the init variable will initialize the counter to value, assuming value is greater than equal to zero. So this counter should be greater than equal to zero, that's another invariant of a semaphore. And there is a function called P, and there is a function called V. The alphabets P and V are, you know, are the first alphabets of the meaning of these functions in Dutch, you know, which is basically the tongue, the mother tongue, I guess, but, you know, the other names of this are weight, semaweight, or semasignal, but we want to just call them P and V. So let's see what P and V mean. So P's semantics are that it will decrement the counter of the semaphore by one, right? And V's semantics are that it will increment the counter of the semaphore by one, right? So this is a minus minus in operation, and this is a plus plus operation, basically. So we said that minus minus will only happen if the counter was greater than zero. If it is equal to zero, you will not, you know, so you will never allow the semaphore to become negative. So if it's equal to zero, and you call P on a semaphore that's equal to zero, then you will wait, and you will wait for it to become greater than zero, and only when it becomes greater than zero will you do the decrement operation, all right? Once again, init just initializes the counter to val, P decrements the counter, except that it ensures that the semaphore never becomes negative. If the semaphore is zero, and, you know, somebody has called P, which means it may become negative, it will not actually decrement it. It will start waiting, and it will start waiting for the semaphore to become greater than zero. And when it becomes greater than zero, at that point, it will decrement it and come out of P, right? And V is simply going to increment the semaphore. And of course, you know, when it increments the semaphore, if it's signs that somebody is waiting for it to become greater than zero, then it will wake it up and say, you know, why don't, you know, you can now decrement it. Those are the semantics. Most importantly, these operations, all these three operations are atomic with respect to each other, right? So this operation of decrementing and waiting is atomic with respect to increment and initialization and all, you know. So all these are atomic with respect to each other, right? So that's why this is an interesting abstraction from a concurrency standpoint. So P, V, and init are basically completely atomic with respect to each other, all right? So, you know, to make this clearer, I think it will help if we implement semaphores. Now, the implementation of the semaphore will make it clear exactly what the semantics of the semaphores are in, you know, in concrete terms instead of just plain English. And I'm going to use locks and series to implement condition variables to implement semaphores, right? So, you know, what I showed you in the previous slide was the semantics or the abstraction of a semaphore. Let's look at how a semaphore could be implemented. And I'm going to give you one example implementation of a semaphore, right? So let's say struct semaphore will have one field, which is the count, two fields. And let's say it has a lock, an associated mutex lock, right? And an associated condition variable. So that's, let's say that's how I define my semaphore, I implement my semaphore. It has three fields, a count variable, which is used to maintain this account. And then I have these two other fields that are basically there to ensure atomicity and of my access with respect to each other and also, you know, implementing semantics and allowing weighting, right? On a condition. So let's say I do this, and then I need to implement semainit, has two arguments, sema and int val. And what I'm going to do is say sema.count is equal to val. But before I, and I'm also going to say lock, or yeah, lockinit, let's say, you know, there's a function which initializes the lock. And let's say it initializes it to, you know, unlock state, so just sema.mutex. And let's say there's another function called cvinit, I mean, just initializing the corresponding fields. So that's the, that's the initialization function, just initialize all the, all these three fields. I mean, I just initialize the count and these are just initialization functions of the corresponding components. Let's say p. So I want to say p on sema, let's say, I would say acquire, so I want to make them atomic with respect to each other. So I'll say acquire sema.mutex, that will ensure that nobody else could be operating on the semaphore at this time. So all these operations should do acquire on sema.mutex. And then what should I check? I need to decrement the count, right? But I also want to check that the count is greater than zero. So what should I do? File. File what? File count is equal to zero, right? So I'm using the condition variable to basically wait on the condition that this count becomes greater than zero, right? So while count is not greater than zero or while count is equal to zero, in other words, I would say while sema.count is equal to zero, wait on sema.cv, sema.mutex, okay? And then if I have, if I come out of the loop, I can be sure that sema.count is greater than zero, right? And at this point, I can just say sema.count, minus, minus, right? And then release. Okay? Make sense? Basically, I wanted to do this, but I also wanted to do this only if this condition is false, right? And so till this condition is true, I need to wait. And I'm using a condition variable to wait. And as you can imagine, what I'll do is in the V function, I'll call notify on this condition variable, right? Of course, I use the mutex, I release the mutex before I go to wait. And I do this in an atomic way, just like all the other patterns we have seen so far. Now let's write V. Yes? Sir, when we call wait, the wait function will release the mutex. No, no. So the wait function releases the mutex, but also reacquires it after waking up. It doesn't just release. It also reacquires it. So at this point, or any time you are outside wait, you would hold the mutex in this code. Similarly, there's V on sema. What do I do here? First, I acquire the lock, right? So I acquire sema.mutex. I need to do that to maintain mutual exclusion between P and V, and between multiple Vs and multiple... So mutex is basically ensuring mutual exclusion between a P and a V, or between multiple P's or between multiple Vs, basically, right? So it's just making sure that things are completely mutually exclusive. And what do I write here? I just increment, right? I don't need to wait on any condition. I can just, you know, V, the semantics of V, as I've told you, is just to increment the semaphore count. So I just say sema.count++. Do I need to do anything else? Notify. And one thing is I could always notify, or a more efficient thing would be to check if the count is equal to one, only then notify, right? If I had just become one from zero, only then there's a likelihood that anybody's waiting, right? So let me say if sema.count is equal to one, notify sema.cv. So this implementation obeys the semantics of semaphores. And I'm using loss and condition variables to implement semaphores. But of course, you know, you could... You may not... You may just want to implement semaphores using assembly instructions, like you may want to implement semaphores using the atomic exchange instruction that we have seen, right? That may be a more efficient way of implementing semaphores. And I would like you to think about it at home, right? How will you implement semaphores using just assembly instead of using these high-level abstractions of loss and condition variables, right? Definitely possible. After all, these locks themselves are implemented using assembly instructions, right? And so are condition variables. All right. Okay. So let's look at this abstraction once again. So we have a type called sema. It is a stateful type in the sense that it has a state and the state is the counter, right? And the counter must be greater than or equal to zero, non-negative. And then these are the three functions that you can use on the semaphore. This is a contrast to, so in many ways, semaphores and condition variables look a little similar because condition variables also had a wait function and a notify function. And one may be tempted to say, oh, P looks very similar to wait and V looks very similar to notify, right? After all, P is just saying let's wait on something and V is just saying let's signal something. The difference between a semaphore and a condition variable is that semaphore also has state. A condition variable didn't have any state. If you call notify, if somebody's waiting right now, he will wake up. If nobody's waiting right now, nothing will happen. If somebody goes to wait later, it's his problem. Somebody else should call notify from him. So if a notify occurred before wait, they don't match up. On the other hand, with a semaphore, if a V occurs before P, then it's okay because V would have incremented and so P won't have to wait, right? So in that sense, because of the state, they don't need to happen together. They can happen at different points of time. So this may become more clear when I talk about some example uses of semaphores, right? So let's look at producer-consumer with semaphores. We have seen producer-consumer with the locks and condition variables, but let's see producer-consumer with semaphores and let's say we again have char Q max. And let's say I also have head and tail, but I'm going to just, you know, abstract them. And let's say now I'm basically, I need to, what I'm going to do is I need to count the resources, right? So I need to make sure that a producer doesn't produce to a full Q and a consumer doesn't consume from an empty Q. So what I'll do is I'll maintain two counters, one for the number of elements that are present in the Q and one for the number of elements that are, or number of slots that are available in the Q, right? So I'll have two counters and each counter will be, will be of type semaphore, semaphore. One is, you know, how many elements there are in the Q. So let's see n char, that's the how many elements there are in the Q. So it's just a counter, right? But I'm using it semaphore to represent that counter. And then there's another counter called n holes, which is how many empty slots there are in the Q. And the invariant will be typically that n holes plus n char will be equal to max. So I initialize n char to zero, let's say the Q was initially empty. And I initialize holes to max. Now let's see, how do you write a producer? Let's say this is produce. And let's say this is consume. So recall that in the previous case, what I did was I acquired a mutex, then I checked for a condition inside a while loop. And then I waited. And then when I came out of the loop, then I consumed, et cetera. And when I use semaphore, I don't have to do any of that. All I need to do is if I want to produce, I call P on n holes. Basically means I'm going, I need, I decrement n holes by one in an atomic manner. If I am, and I, because n holes is a non-negative number, if I come out of P, has to be a non-negative number. So if I come out of P, I'm sure that there's an empty slot available in the Q. And then I produce an element, so let's say, produce an element, which may mean Q head is equal to C, head is equal to head plus one, mod max. And then, and let's say that's it. And then in consume, I do P n char. I decrement the number of characters, and I consume them, consume an element. So both of them are just decrementing. Somebody also needs to increment it, right? So where do you increment? Right. So I'll increment here. What will I increment? n chars. Right? So you decrement n holes before, you increment n chars after. Because at this point, you have added a character, and you can basically say, you increment n chars by one. And similarly, you can increment n holes here. That's it. Right? MF holes. Yeah. Go ahead. Yeah. Don't we need mutex? Yeah. Great question. So yes. So that's it for making sure that you don't produce to a full Q. And it's also making sure that you don't produce from an empty Q. But it doesn't make sure that these operations can produce an element and consume an element at atomic with respect to each other. And so you may want to have another. So you will want to have another thing. Let's say you have an acquire mutex here, just for the mutual exclusion part. And then you have a release mutex. All right. Let's see. So the question is, shouldn't acquire be before P and release after V? What do you think? So firstly, you know, we said that P itself is atomic. So it doesn't need to be protected by a mutex. Right? And so, you know, this code is correct, firstly. All right? You need to convince yourself that this code is correct. You have decremented n holes atomically. And at this point, you can be sure that you are free to consume. Or free to produce, here. Right? Similarly, you're decremented in cash. You come out. So you need to be sure that you are free to consume. Right? Mutex is just making sure that they are mutually exclusive with each other. If you put acquire before P, you know, you may actually run into problems, because, you know, here is a situation where you, you know, there are two things, there are two resources. There's a mutex and there's n holes. And you are going to, you want to acquire both of them at once. And now you have to worry about order and all that. And so, you know, you have to worry about deadlocks, et cetera. But if you do code in this way, then, you know, there's absolutely no problem or deadlock. You know, acquire and release are sort of, of mutex are within the inner loop. And so, it can never happen that you wait on a mutex and then you wait on something else. You hold a mutex and you wait on something else. That's not possible. And so you will never have a deadlock in this case. Right? And of course, you also want to make your critical section as small as possible. Right? So that's, you know, that's producer-consumer with semaphores. This code is much simpler than the code that we have seen earlier. Right? What's going on? Well, what's going on is simple. That, you know, we have noticed that there's a pattern. The pattern is that of counting. In both cases, we were counting. We were just counting the number of elements. And we were waiting. And so we have subsumed that logic of counting within the P function itself. Right? That's all we have done. And so, our higher level code looks much simpler. And so semaphores are a very useful abstraction. It allows us to capture this very common paradigm where you're counting resources using P and V. And your code actually looks much simpler and much better to understand. Much easier to understand. And that's it. Right. So this is an example of producer-consumer with semaphores. Let me give you another example. Let's say resource allocation. So let's say, you know, I have ten printers. And there are, you know, many threads, let's say hundreds of threads, that are trying to print on these ten printers. And I say that because there are only ten printers, there should be at most ten concurrent requests in my printer. In my print queue. At any time, let's say. Right? So this is a problem of resource allocation. You have multiple threads. You have hundreds of threads. But you have a few number of resources. And you want to say that, you know, I want to give only, you know, I want to make sure that the concurrency factor is limited to by the number of resources. So let's say the resource is a printer, then at most ten concurrent print requests can be given. Others should have to wait. Right? So very easily handled by semaphores. All you need to do is, let's say, this is your print function. Inside the print function, you will basically say P on, let's say, N printers. You know, call the print command. And then call V on N printers. Of course, you will first initialize the N printers variable semaphore to ten, let's say. If, you know, you have only ten printers or whatever is the number of printers, you initialize the counter to the number of resources. And then whoever wants to consume the resource should include or access the resource should enclose his access logic within a P and a V. And that's it. Right? So if there are a hundred threads, depending on who came first, some of them will get it. And as the threads are done, you know, as threads exit, they will immediately call V, which will cause another thread to enter. Right? So it will, it will, it will allow you to do scheduling across and resource allocation across multiple threads. Right? So semaphores for resource allocation. All right. Let's see. Another sort of interesting example is locks. Can be implemented as semaphores, right, simply. So what's a lock abstraction? You basically have a state. Right? So lock, unlike condition variables, are stateful, is a stateful abstraction. Right? Condition variables are stateless abstractions. Semaphores are stateful abstractions. And lock is also a stateful abstraction because the lock variable has a state called whether it's locked or not. Right? The lock variable has one bit of state. The semaphore has an integer worth of state. All right? Okay. So locks and semaphores, well, what is a lock? It has acquire, L. Well, you can implement acquire L by, you know, putting, using, having a semaphore inside L. And you can just say, you know, you can, you can say in initial, you can initialize the semaphore as, as one. Right? So a lock is nothing but a resource with one instance. And so if there are multiple threads who want to access the source, only one instance can go in it. Right? So a lock can be modeled as a resource and you can just use semaphores to do it. So acquire L is nothing but what? P. That's it. And release L is? P. Simplistic use of a semaphore. You know, semaphore can do much more. But if you wanted to use a semaphore as a lock, very easy, you initialize it to one. Acquire becomes P and release becomes V. Okay. Let's see. Scheduling with semaphores. So let's say, let's say there are, you know, these variables called X, Y, Z. Right? Let's say these are integers and somebody is going to compute X, somebody else is going to compute Y, and then a third thread is going to use X and Y to compute Z. And then once that is computed, you want to print the value of Z. Right? So let's say there are, you know, three threads. One of them computes X. Then another thread computes Y. Then yet another thread computes Z as a function of X and Y. Right? And let's say yet another thread, you know, prints Z. But you want to make sure that this computation happens only after this and this has happened. And you want to make sure that this print happens only after this has happened. Right? So you want some kind of dependency. These are the dependencies you want that, you know, Z should happen after this has happened and this has happened. And this should happen after this has happened. So this kind of, some kind of dependency graph that you have and you're doing computation and different threads are going to compute this thing. And you want to schedule these threads or you want to synchronize these threads in this way. Right? So one way to do this is using semaphores. So you can say struct sema SX, SY, and SZ. You associate each, one semaphore with each variable, denoting whether that variable has been computed or not. Right? So you take SX and you initialize it to zero. So all these semaphores are initialized to zero. So you use, you call the semi init function to initialize them to zero. And then you write code something like this. So when you say X is equal to dot, dot, dot, you say, so initially all of them are zero. So semi init SX zero, SY zero, and SZ zero. Right? And then you say X is equal to dot, dot, dot. And then you say, what? You say V on SX. Right? Say Y is equal to dot, dot, dot. You say V on SY. Basically indicating that X has been computed. So you put up, you push up the flag by one. Y has been computed. So you push up Y's flag by one. And for Z is equal to SXY, what do you do? Before it, you say P of SX and P of SY. The P is going to have the effect of waiting for somebody to have called V. So only if somebody has called V, would I ever be able to come out of P. Right? Because I initialize it to zero. Right? So this is an example of how you will do scheduling. And then after you computed Z, you may say PSZ, VSZ. And of course, before the print Z, you may want to say PSZ. If you initialize the semaphore to zero and use it to represent whether something has been computed or not, or some condition is true or not, you can use that to make sure that things are happening one after another in an ordered way, in a scheduled way. Okay, good. So that's semaphores. Let me talk about another abstraction. So we have seen three abstractions so far, locks, condition variables, and semaphores. Right? And you've seen how locks are absolutely integral to do mutual exclusion. And notice that these abstractions actually can be implemented, they are all actually roughly equally powerful abstractions. So you can implement semaphores using locks and condition variables. You can implement locks using semaphores. So it's not like one is less powerful than the other, et cetera. But of course, you know, there is some difference, of course. You need both locks and condition variables to implement semaphores, for example. All right, okay. Let me talk about something else now. So far, all our abstractions have been of the type where there is some data type that we declare, like a lock or a semaphore or a condition variable, and then we have some functions. And it's the responsibility of the programmer to enclose his code or, you know, instrument his code with these functions appropriately. In general, it's very error-prone, this kind of thing is very error-prone. You know, he puts an acquire in the beginning, and then there are multiple code paths that are going from his function, and then, you know, does he put a release on all those code paths or not? You know, that's a very common bug. You have missed putting a release somewhere, for example. Right? Also, a compiler cannot check anything. Right? These abstractions are not part of the language, per se. The C language has nothing to do with, you know, whether you are using a lock or not using a lock, whether, or anything of that sort, or, you know. So these abstractions are completely independent of the language. And that's not necessarily a good thing, because the compiler will never be able to tell you if you made an error. Right? For example, if you didn't enclose a, you know, if you are not bracketing an acquire with a release always, a compiler could have, should have told you, but it will not be able to tell you, because, you know, it knows nothing about what you are doing. For him, it's just function call, called acquire. Right? You could have called it something else, and, you know, he wouldn't know. So there's a, so to solve this problem, there's yet an, there's an abstraction called a monitor, which is a first-class support inside the language, inside the programming language, to do mutual exclusion. Right? So the idea of a monitor is basically that, you know, you, you basically use object orientation, or, et cetera, and you basically define a class, which will be called this monitor, and then you find, you know, and this, this class will have some shared data. Let's say, in our case, it has this shared data called Q, and these pointers, head and tail, and so on, and it will have some functions, which will operate on the shared data. All right? So there's a function called, let's say, void produce, right? And char consume. So, and it's the responsibility of the programming language to ensure that there's mutual exclusion between all the functions that are defined inside this class. Right? So if you're regular object-oriented programming, there's encapsulation, which means that these variables are private. Only these functions can access these variables. But moreover, these functions will always execute in a mutually exclusive way. So if there's some thread which is executing produce, no other thread will be able to execute either produce or consume, right? So only one thread could be inside the monitor at any time. So this class is also called a monitor. The class of this type, right, is also called a monitor. And the idea is that only one thread will be inside the monitor at any time. Right? So it's the language that provides you a construct to define mutual exclusion. So far we have been defining mutual exclusion using our own data type called lock. Now here's an abstraction that, this is a high-level abstraction provided by the language which allows you to basically say that these functions need to execute in a mutually exclusive way. It also provides you encapsulation because it defines the data which is likely to be shared. And it says that because this data is only visible to these functions, it automatically ensures correctness. Because this data is not global in the true sense, then it cannot, because this data cannot be accessed by anybody else, and because these functions are mutually exclusive, by the definition of the monitor, your code should be correct. So it makes things easy to reason about for a programmer. Moreover, the compiler can now have some idea about what this code is doing. It knows that this is the data that's only being accessed by this, so it can do some optimization in that sense. It also knows that this function and these functions are mutually exclusive. So it doesn't need to worry about, you know, it can do, it can freely do optimizations within produce and within consume because it knows that these accesses are going to be mutually exclusive, et cetera. Okay. So, for example, I could have implemented my queue, my producer-consumer example using a monitor. So languages, some languages support monitor. C does not support a monitor, but let's say Java supports monitor. The synchronized keyword, so there's a keyword called synchronized in Java, which allows you to say that this area needs to be mutually exclusive. It's the compiler which will put, which will ensure that things are mutually exclusive for you, right? So if you don't want to use explicit logs, you can just put code inside, you know, you can, so Java allows you things like, you know, a class is synchronized. So that makes, means a monitor, or it can, or you can also say a synchronized block. So you can just say synchronized on, you know, and, and write some code here. The compiler will ensure that, you know, it basically amounts to saying, acquire a log here and release the log here. And you can also give an argument to this, so this is the log that gets acquired. So that, you know, reduces the chances of you making errors like, you know, and release is not bracketed within acquire. Because you're using static language constructs, you are sure that you're, you know, you don't, you're not running into errors of that type. That's a monitor. Basically what the compiler does is that before and after the calls of these functions, it, it says add call to acquire and release. So there's an implicit log. In all our previous cases, there was an explicit log that we had defined. So if you need a monitor, there's an implicit log that the compiler will insert for you. And also, you know, let's say there are multiple instantiations of this class Q, then each of them will have a separate implicit log, for example. Monitors also need, so the code within the produce, just like, you know, we have seen the producer code, the producer code may need to wait on a condition. So what is the, what is the counterpart of a condition variable inside, in the monitor world? So monitors also have these functions called wait and notify, or, you know, you can call them by different names, wait and signal, or anything else. And, and you can say, can some condition variable, except that when you use wait and signal to notify within a monitor, you don't need to use the mutex as a second argument of wait, right? The mutex of, which is the second argument of wait is also implicit. If the wait is being called inside the code of a monitor, then it knows that this is the, the log is basically the implicit log that needs to be released, right? So the monitors wait and signal notify don't, don't need to care, you know, already know which is the mutex that needs to be released. It's the implicit log of the monitor. Okay, let's stop here and continue our discussion tomorrow."}
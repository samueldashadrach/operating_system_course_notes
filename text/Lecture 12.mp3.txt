{"text":"All right, so welcome to Operating Systems Lecture 12. So, so far we have been discussing paging and we said that the hardware provides the capability of setting up a structure called a page table. So, the operating system can set up the structure called a page table, which we said that if we are using pages of size 4 kilobytes and an address space of size 2 to the power 32, then you would probably want to have a two-level page table so that it has a nice trade-off between the time it takes to translate a virtual address to a physical address and the space that such a structure requires, right? So, we said the two-level page table seems like a nice trade-off between these two things. If we have just one continuous page table, then translation time is very small, but at the same time the space overheads are very large. If we use a multi-level page table, more than two, then the space overheads can become even less, but then the size of, then the translation times become unnecessarily large, right? So, a two-level page table seemed like a reasonable trade-off. And so the way it works is there's a register on the chip, on the CPU processor chip, called CR3, which points to a page, a page-sized structure. This entire thing is one page, but it contains, it's a special page because it contains page directory entries. So, this page is called the page directory. The first 10 bits of the virtual address, so this is the virtual address, the first 10 bits of the virtual address are used to, are called the page directory entry number. And based on the PDE number, you would see which entry you're going to dereference. From that, you're going to get a 20-bit address, which is going to point to another physical, which will be another physical address that will point to the page table, right? And then there'll be the other 12 bits, which are flags. The page table is going to get dereferenced again in physical memory, so this is a physical address that goes, and you dereference the page table. You get the next 10 bits, and that basically forms a page table entry number. You use the page table entry number to look up the page table to get that entry, similarly. And you look at the first 20 bits to get the page number. Once again, this is a physical address, right? And then once again, you have the last 12 bits, which are being used as flags. And finally, you use the last 12 bits of the virtual address to index into this page to actually get the data that you were looking for, okay? I said that the PDE number is just a number between 0 and 2 to the power 10, right? So there are 2 to the power 10 entries in one page directory, because you're using a 10-bit number to do that. And each entry is 4 bytes, so you know, 4 kilobytes, so the whole page directory fits in one page. Similarly, the one-page table fits in one page, and the page itself is one page, right, 4 kilobytes. Also, we said that this 20-bit number here is a physical address. Why does it need to be a physical address? Can it be a linear address? It cannot be a linear address, because a linear address will need to dereference the page table to get converted to a physical address. So if this were a linear address, then I'm basically in an infinite loop, right? So I'll never be able to translate, so this has to be a physical address. This has to be a physical address, and so on. What about CR3? Should it be a physical address, or can it be a linear address? It should be a physical address also, right? It cannot be a virtual address. So all these structures should be physical addresses. Okay, so what this allows you to do is a much more flexible mapping from virtual address space to physical address space, right? Unlike segmentation where we had a very simple base plus VA computation, paging allows you to have a relatively much more arbitrary mapping, except that the mapping is done at page generality. It's not done at byte generality, it's done at page generality, right? So you can say that this page is here, and that page is there, but within a page, two consecutive bytes should be consecutive in the physical memory also. So within a page, bytes should be contiguous. Contiguous bytes within a page on virtual memory, or in virtual address space, are also contiguous in the physical address space, within a page. Okay, so just to get a comparison, here is how segmentation works. If this was the virtual address space, and it starts from zero to let's say some value M, then segmentation would only be able to map it to some base plus zero and base plus M, right? Base plus limit. And so, you know, this is how the process works, basically, that this is the only possible translation, and we saw that this has some problems of fragmentation, process growth, and things like that. So, you know, it's not a very flexible way of doing it. The advantage, however, of doing things in this way is that the time it takes to actually translate a virtual address to a physical address is very small. It's extremely fast. You just have to do an on-chip addition, right? You don't have to look up into any structure, nothing, right? And we also said that the structure, the GDT itself, although it lives in memory, it gets cached on the CPU, right? And when does it get cached on the CPU? When you load the segment selector, or register. And so at that time, it gets cached, and later on, you know, it's just used from within the chip. So, the translation logic is really fast. In the case of paging, it's CR3 cached. We're going to talk about what gets cached or not. But by the way, the base directory of the CR3, I mean, the CR3 register is already on the chip, right? No, no, no. Like the address with CR3? Yeah, that's on chip. CR3 is a register which stores the base address of the page directory, right? So it's already on chip, so it's no problem. So, on paging, on the other hand, you can have much more flexible mapping. So here's an example of a VA space to PA space mapping in paging. Here I can say that, oh, these pages are mapped, and these pages are mapping to this area, and these pages are mapping to this area, and these pages are mapping to this area. And all the other empty spaces are not mapped, so all this is possible, right? I don't necessarily have to map from zero to something. I can just say, oh, these pages are mapped, and these pages are not mapped. You can think about how you're going to architect your page directory and page table to be able to do this mapping, right? For example, if you were to do this mapping from here, you're going to say, okay, what is this address? Let's say this address is M. So you would say, what is M divided by, you know, M, what are the top 10 bits of M, right? And based on that, you're going to set up the page directory entry of that to point to a page table, right? And so now you're going to look at what are the next 10 bits of M, and that particular entry in the page table should have a pointer to that page in this space. All other entries in the page directory and page table can be invalid, right? And how do you say whether a page table entry is invalid or a page directory entry is invalid? Using these flags. So if a present bit is not set in an entry, it basically means that this entry does not exist. It's invalid. Okay? Similarly, there are other flags, like user, basically says that this page should be, is accessible in user mode or not, right? So only if the bit is set to, this user bit is set in the flag, is this page accessible while the processor is executing in user mode, ring level three, right? Other pages which don't have this bit set will not be accessible in user mode. They will only be accessible in ring level zero, kernel mode. Similarly, you can have a bit which says whether this particular page is, the page that's getting dereferenced from this PDE and PTE, page directory entry and page table entry, is it writable or not? Okay? So if it's not writable, then if some instruction tries to write to that address, then you should get a page fault. Okay? So there's, there's something called a page fault, which is, which is just an exception in the hardware. So an exception gets triggered and the exception handler gets called, right? And we have discussed how an exception handler gets called through the interrupt descriptor table. Okay. So, okay, so that's, that's what we discussed. And then we said, okay, let's look at how an operating system uses this page table hardware, page, and page directory hardware to actually implement processes, right? So what does an operating system really need? It needs a few things. It needs to say that my address space should be protected from everybody else's address space, number one. Number two, one processor's address space should be protected from another processor's address space. Right? Those are the basic two things that an operating system wants, and we have already seen how it's done in segmentation. So in, in paging, one way to organize things, and that's how we're going to focus on this way for the, in the beginning, is that, let's say this is the Vs space, okay? And let's say this is the Ps space. So one way to organize this is that you have per process Vs space. So this is Vs space for process P1. And let's say this is, let me use a different color. So let's say this is Vs space for process P2, okay? In the Ps space, you could say, okay, here is, let's say, this is a process P1 page, and let's say here is another process P1 page. You can, and you could have multiple of such regions, non-contiguous regions. And here is, let's say, P2 page, here is another P2 page, okay? And so what will happen is addresses in the P1 page region will map to areas in the Ps space like this. And similarly, you know, and in fact, this P2, they're mapping here, right? Also, we discussed last time that the kernel always stays mapped in the virtual address space. And why it's so, let's discuss it in a minute. But let's say, how does it work? So how big is the Vs space? It starts from zero, and it goes all the way to 2 to the power 32 minus 1, right, on a 32-bit machine. But the Vs space that's given to a process on something like Linux or, let's say, Windows or x86 is basically that you say, oh, a process will not get the entire 2 to power 32 space. Let's cut it somewhere, right? And let's say that a process is allowed this size of the space. So this 2 to power 32 is actually 4 GB, right? So one way to do it, and let's say, let's look at one particular operating system, x86, right? So what does x86 do? It says, you know, a process can use 0 to 2 GB, and that's it, right? All the addresses above 2 GB in the virtual address space belong to the kernel, okay? So the kernel maps itself in the address space of the process, except that this particular mapping has the user bit set to 0, which means these pages will only be accessible if the processor is executing at ring level 0, right, in privileged mode. These pages will not be accessible by the user if the processor is executing in unprivileged mode. And it does so for every process. So even in this process, the 2 GB, so exactly at the same place, the kernel is mapped, okay? So a process has a virtual address space. Here it can have whatever it likes, and those are getting mapped to different regions, potentially different regions in the physical address space. But the kernel is mapped at the exact same place in every process. So we're basically saying no process is allowed to use more than, let's say, 2 GB on x86. And of course, this is also bad. So let's say, let me use a different color for the kernel. And let's say, let's say these are the kernel pages. So let's say these. Here is the mapping from the kernel, and this stays constant, irrespective of the process that's running. You'll always have this mapping. And so what that means is, so how do you implement a different virtual address space for different processes? You have separate page tables for every process, right? So every process has a separate page table. And let's say if you're running process P1, you will load process P1's page table into CR3. If you're executing process P2, you will load process P2's page table into CR3. But what will be common in these page tables is that there will be some entries which are for the kernel, and which will always be there in all these page tables. So that's how you do it. You don't make copies of the kernel. The kernel in the physical memory is just one copy. But there are multiple processes which have this copy mapped in their address space. All right. So why do you do this? And let's see how it works, basically. So let's say I was executing in the process P1, and some exception occurs, like a page fault occurs. Or let's say some external interrupt occurs, like a timer interrupt occurs, or a disk interrupt occurs, or a network card interrupt occurs. And what happens is the processor goes through the IDT and replaces the current value of code segment and EIP with the value of the CS and EIP in the IDT, right? And so typically, these values will be the kernel values. OK? So let's say I was executing in P1, and an interrupt occurs. Then CS colon EIP that will be loaded from the interrupt descriptor table will have CS's base as 0, right? So we are assuming that the segmentation model is completely flat. So all segments are 0 to 2 to the power 32 minus 1. But EIT will be an address which is above 2 GB, right? So EIP will be some 2G plus X, whatever, right? So it's going to point somewhere here. And so if an interrupt occurs, or if an exception occurs, the processor straightaway jumps to the kernel address space. But it also reloads the CS so that the last two bits of the CS register are set to 0. So that, you know, the processor is now executing in privileged mode, right? That's the only way EIP can actually point to something in the kernel space, right? A user, if it just calls jump to this EIP, it will trigger a page fault, right? Because if the user is executing in ring level 3, which is the last two bits of CS, then it says jump to some address which is above 2G, immediately, you know, there will be a page fault because the hardware will try to walk the page table and it will say, oh, you know, you are running in user mode, but this particular page that you're trying to access is actually not a user page. But if you get an interrupt like this, then you also reload the CS, so now you're running in privileged mode, so now you can actually dereference a page above 2G. So the handler is now going to live in the kernel space. Also the stack is now going to, the kernel stack of the process is now going to live in the kernel space. So even in the SS and ESP, the SS's base is still 0 because we're using a flat segmentation model, but ESP value is some 2G plus, you know, let's say Y, so ESP is also pointing somewhere here, right? So that's the kernel stack of the process that was currently running. Where do you get the ESP from? The task state segment, right? So the hardware just reads the task state segment, so it's the responsibility of the operating system to set up the task state segment with the right ESP for that particular process. If the kernel was a process mode kernel, right, it was a process model, then you will have a separate ESP per process, in which case, you know, before you context switch to the new process, you should load a new ESP in the TSS, task state segment. If it's an interrupt model kernel, then the ESP remains constant, this is the same stack that always gets executed, right? So in segmentation, what was happening was the segment itself, the base itself was getting changed. In paging, the base remains the same, the privilege level changes, yes, but what's actually changing is the offset, which is EIP and ESP, right, and these offsets should be set up by the kernel so that they point to the kernel address space, which is 2G and above, 2GB and above, okay? Okay, so let's look at this again, so let's say this is the virtual address space, and let's say this is the, this is 2GB, all right, and this is the kernel, okay? So the entire address space is 4GB here, so what typically happens is that, you know, the kernel will have some code, and so, you know, let's say this is kernel code, A code, let's say this is the memory region which contains all the instructions that the kernel contains, right? And then you have certain region which contains K data, which let's say contains all the global variables that your, that your kernel defined, contains the K data, and everything else above this is actually free space, right? So let's say this is your physical memory, this is PA space, and it's going from zero to, let's say, some value M, capital M, right? And we said, you know, the last time we discussed, we said, you know, the addresses from zero to 1MB are actually, this address space in the PA space is actually cluttered because you have some address range which is meant for the console, right, for the VGA console, so if you write there, it's actually not memory, it's actually going to the VGA output. And there are other things like BIOS ROM and all these things, so zero to 1MB on x86 is a little cluttered, so let's just leave it as it is, right? But from 1MB to M is space that's actually real memory that you can, you can use with memory semantics. And so, so what happens is, you know, let's say in, in this you would first load K code and K data, and so this is physical memory, and so all the other space is basically what's available for other things, right? So K code is mapping here, and K data is getting mapped here, but all the other space in the physical memory is basically just, just extra space that you are going to use for other things. What are the other things? You're going to use it as a heap for, let's say, maintaining your PID, process PCBs, process control blocks. You're going to use it as a space from where you're going to allocate the kernel stacks of the process, Cs, right? The kernel stacks of the processes are also going to get allocated in this space. Moreover, the address space of the process itself is going to get allocated from this space, right? So clearly, this is the entire space which is going to get used for allocating address spaces for the process. It's going to be used for allocating the kernel stack for the process, and it's going to be used for allocating the other kernel data structures, like process control blocks or whatever else it needs, okay? So all that has to get allocated from this space, okay? So let's look at how x36 does this. It basically says, so it says 2 GB is basically what the process will get in the VS space. Above 2 GB is the kernel. Till 2 GB plus 1 MB, it's not going to touch anything. So it just maps this region from 2 GB to 2 GB plus M, where M is the size of the physical memory, to 0 to M in physical address space, right? So 2 GB plus, let's say this is 2 GB plus M, gets mapped to 0 to M. So the entire physical address space is also mapped in the kernel's virtual address space, okay, on x36. And so the kernel can now access the physical memory directly by just saying, if it wants to access physical memory byte number 10, or let's say any x, then all it needs to do is 2 GB plus x in the virtual address space is basically physical byte number x. So let's say the kernel wanted to allocate an address space for the process, so what it'll do is it'll say, let's allocate an address space for the process from here, right? Which will mean it will allocate an address space for the process from here, so let's say, let's use a different color. So let's say it allocated an address space for a process from here, which means it allocated an address space for the process from here, right? And then it sets up a mapping in this area to this area. So what's happened? See, so this is the process's address space, right? Let's say this is P1. So P1 wants to map some area of the physical memory in its virtual address space. So it's going to have a mapping in the physical address space like this, but this area is also mapped in the kernel address space like this. So here's an example where the same page in the physical memory is actually getting mapped both in the user side of things so that the user can access it, but it's also mapped in the kernel side of things so that when the kernel actually allocates it or deallocates it, it has access to all this area. So basically, just to recap, the kernel maps the entire physical memory in its address space. It allocates area from this address space and maps it into the user's part of the address space to implement the process's address space, your user side address space. Mapping the entire physical memory into the kernel's address space has advantages that you can just, you know, if you want to access a byte number X, all you need to do is look at your base plus X, and you get the particular address. Yes? Okay, so the question is, how big is M? So in this organization that I've discussed so far, how big can M be? Actually it's going to be 2 GB minus 1 MB, right, because, actually yes, 2 GB, because you know, 1 MB is also getting mapped here, so it can at most be 2 GB. So basically, xv6 has this limitation that you cannot have more than, let's say, 2 GB of memory in your system, okay? Actually, I should also mention that the top few address spaces are also reserved for devices, so it's actually even less than 2 GB in xv6. So what does it, so the question is, is this, so for something like xv6, it's good enough, number one, okay, because it's just an academic operating system. But for something like a real operating system, like Linux, this may not be good enough. It may have been good enough in the early days of this operating system, like 90s, when you know, memories weren't, they were nowhere near 2 GB mark, so this was, you know, this kind of organization actually worked for hardware of that time. But how Linux deals with memories which are greater than, you know, let's say, 2 GB, if you started at 2 GB, is basically to recycle these addresses. So depending on which address you want to access, it just changes its address space on the fly, right? Here, I'm talking about a static mapping. I'm saying the entire memory is mapped in the kernel address space all the time. So it's completely static for the entire duration of the system that's running. But if you're actually running out of the address space, because the address space of the kernel is only, let's say, 2 GB, but your memory is, let's say, 3 GB, then you will say, okay, the first few MBs, which contain all my handlers and everything, those remain always mapped. But other things, like the area from where I allocate memory for processes, that I sort of keep recycling, right? So some part of this 2 GB slice will get recycled, so sometimes it's mapping to this area of the physical memory, sometimes it's mapping to that area of the physical memory, and the kernel is basically ensuring that it's always, it's doing what it wants to do. But some area of the kernel will always stay mapped, because things like handlers, right, or kernel stacks, they will always stay mapped. The area from where memory for the handlers is taken, which is K code, should always remain. You cannot just remove it at any time. Similarly, the memory from which the kernel stack is living for the current process, that should always remain. And some other things, which are basic functionality of the operating system, they always remain in the kernel. If our physical address space is growing, why can't we grow our virtual address space? How? Okay. Alright, so the question is, if my physical hardware memory is growing, then why can't I just switch to a 64-bit system? Yeah, that's what has happened, right? So one of the big motivations of actually moving to a 64-bit system is so you get rid of these kind of limitations. But let's just focus our attention on a 32-bit system, because, you know, that's simpler and will help us in understanding many concepts. So yes, if you had a 64-bit address space, then you can imagine that these are absolutely non-problems, right? Because there's no way a physical address space, today at least, or actually any time in foreseeable future, that you can have actually a memory which is 2 to the power 64 bits long. I think, you know, I don't know how many atoms there are in the universe, so probably it's comparable. Okay. So, okay, so this is the organization which, let's say, XP6 uses, and in fact, other operating systems also use. So let's understand what are the advantages of doing this kind of organization. So the entire kernel space is mapped in every process, and we said that the entire physical memory is mapped in the kernel space. So essentially, the entire physical memory is mapped in every process in the kernel side of things. And then there is the user side of things, which is controlled by the kernel. And so any time, what this gives the kernel is that if there is an interrupt while the user is executing, you don't have to change any page tables or anything. You just switch the privilege level, and you are executing in kernel mode. If you want to do some operation on behalf of the user, for example, let's say the user said, I want more memory. So all it needs to do is allocate something from its own address space, convert it into its corresponding physical address, and create that particular page table mapping. So it can only use, it can use its own malloc function inside the kernel to manage that space that it has, which is actually the entire physical memory. So it can just use malloc to create a page. Let's say it wants to allocate a page for the physical process, for the process. Then it just mallocs the page, converts, gets its address, converts that address to the physical counterpart, creates the corresponding mapping in the page table at the right position, and that's it. Returns back to the user. So any interrupt or exception or system call does not need any change in the page table. So it's very fast in that sense. Because the kernel is mapped entirely in the address space of the process, although in privileged mode, it sort of improves things in that sense. The other thing is, let's say you have a system call, and the system call will have some arguments. So things like exec, and exec is a system call which takes the first argument as a string. The question is, how does a process give an argument to a system call? How does the argument of a function work? If exec was a function call, the pointer to the string which holds the name of the executable will be pushed on the stack. And the stack address will be visible to the function. So the function can just look at the stack address, and it can dereference that address, and the dereference will also be visible to the function, because that address to which it points will also be mapped in the user address space. So it can dereference the argument, and it will still get a value which is in the user address space which it can access. Similarly, in the case of a system call, the user can use a similar organization. It can store the string in its own address space, for example, slash bin slash ls, and then make a system call called exec. The control moves to the kernel, but if the kernel wants to read the arguments, you're still executing in the address space of the process. So it can just dereference the argument, and because the page which contains that string slash bin slash ls is still mapped, dereferencing should still work. The kernel will be executing in privileged mode, but privileged mode execution can access unprivileged pages. So accessing the arguments of the user is very easy. You just have to dereference the pointer, and you can just get the arguments. Once again, there's an advantage of mapping the kernel into the user address space, because if the kernel is doing something on behalf of the user, and the user wants to pass some information to the kernel, it's very easy to pass information from the user space to the kernel space, because they're both living in the same address space. The user can just set up something in its own address space, and give a pointer to the kernel. The kernel can just dereference the pointer, and it will be able to read the value, because you are in the same address space. Compare this with segmentation. In segmentation, when there was a system call, then you were actually changing the base. So now if the user wanted to give an argument to the kernel, the kernel can't just dereference that pointer, because you are in a new address space. The base is different. So the pointer that the user gives you, if you just dereference it now, you're actually going to be looking at something else, maybe something wrong. In the case of segmentation, what's actually needed is that the user needs to package all these arguments, and copy it into the kernel space, somehow. Because the kernel's address space and the user's address space are separate. And so you need to copy it into the kernel, using some kind of mechanism. In this case, you can just simply dereference the argument. So that makes things faster. Okay, that's an interesting question. So in segmentation, couldn't the kernel have changed so that the kernel already knows what are the user's segments, right? So the question is, in segmentation, can't the kernel just switch to the user's segment before dereferencing the pointer? Right? That's your question. But that requires switching back and forth. And basically, that's how it will typically be done. But that requires switching segments, and then copying. So typically what you'll do is you'll switch to that segment, copy it to your own segment, and then switch back, and then start operating on it. So there is more overhead in that sense. Okay, let's review this once again. Here's another way of drawing this. So this is process P1, this is process P2, and this is process P3. Each of them has a separate address space in the lower 2 GB, but they have the same address space in the upper 2 GB. And what that means is if process P1 makes any change in the kernel side, then process P2 will see it immediately, because they're sharing the address space on the kernel side. So another way to say this is that user processes, each user process is also a kernel thread. Recall what's a thread? We said a thread is basically, you know, threads are basically control flows which share an address space. Right? So these are control flows that are sharing an address space, in this case the address space of the kernel. Right? So even though they are processes at the user level, because they have different address spaces, at the kernel level in this organization, they are threads. Right? Each process has a kernel half and a user half. And it switches between the kernel half, so how does it switch from the user half to the kernel half? Through interrupts or exceptions, or let's call them traps. That includes system calls. And how does it switch from kernel half to user half? Let's say using the IRET instruction. Right? And so, but whatever change one has made, the other one will see immediately. Okay? So in that sense, it's a thread. They don't have separate address space. Okay. Just some facts. Linux on 32-bit, x86, starts the kernel address space at this address, which is 3 GB. Right? Windows on 32-bit, I think by default, starts at this address, that's 2 GB. But you can configure it to say that, you know, please start at 3 GB. Okay? x86, on 32-bit x86, starts at 2 GB. So all these operating systems are actually mapping the entire kernel into the address space of the process. And basically, because it improves, it allows very fast switching between user and kernel, number one. You don't have to change any address spaces. Number two, it allows very fast communication from user to kernel. For example, arguments. And maybe even return values. Right? So very fast communication back and forth between user and kernel, because it's the same address space. All you need to do is dereference the pointer, and you're there. Let's, for completeness, also understand what could have been the other organization. Right? Let's say if the entire kernel was not mapped into the process address space, what's the other possibility? Right? The other possibility is, let's say, this is the virtual address space of P1. It just maps a small area for the kernel. Right? And let's say there's another virtual address space, which is just the kernel's address space, not associated with any process. And so what will happen is, if you're executing in process P1, the handlers and all that are still in this space. So if there's an interrupt, you will jump here. But the first thing the handler will do is switch page table, and you're here. Right? And if you want to go back to the user, you want to switch it back, and then you're going to go back to the user using IRET. But notice that this involves, number one, switching page tables on a kernel execution, number one. Number two, if I want to communicate from here to here, it's not easy, because what I need to do is copy my string from here. Let's say I want to communicate a string. So I need to copy the string from here to here. Then he needs to copy it from here to here. Right? So the way he'll copy it from here to here is, let's say, this same area is also mapped here. And so if he copies it from here to here, it's immediately visible here. And so when it switches it, it now can see it. Right? It involves extra copying, basically, from user to kernel. So it's relatively slow. Can we say it's same as segmentation? Yes. Roughly same. Except that in segmentation, you didn't even, I mean, segmentation is giving you a mechanism where you don't even need to map this area into the user address space. Because it's a completely different segment. Right? Yeah. Question? Yes. Okay. So the question is, you know, if the kernel is just going to have a one-to-one mapping from virtual address space to physical address space, why do I need another via space? Well, just that, you know, once you enable paging on hardware, you cannot just access physical address directly. You have to go through a page table. So once you enable the hardware, you know, every address will go through the page table. So if you want to access a physical address, you just set a one-to-one mapping from virtual address space to physical address space. Okay? All right. So, okay, so that's, you know, that's my, that's the introduction to paging. And from now onwards, we are actually going to look at xv6 code. We're going to look at xv6 code to understand exactly how it's doing all these things that we have so far discussed. Right? So let us understand. So we're going to start with how a computer boots. Right? So how does a computer boot? Well, across power recycles, you know, if you switch on, switch off the power and you switch it on, everything in your memory registers, everything gets wiped out. No processes, no kernel space, no user space, nothing persists. The only thing that persists is a disk. And so when you boot on the computer, there are certain conventions on how the disk should be laid out for the computer to actually start. Right? So let's just, so a disk is actually a cylindrical device, but let's just consider it as a linear address space of blocks. Right? So this is block number zero. So this blocks. So block number zero and block number one, two. Right? And let's say it's very large. Okay. So that's how the disk is. It's a collection of blocks where each block, once again, this is a property of the hardware, is 512 bytes. Right? Or sector. So each block, each sector or block is 512 bytes. And what happens, so the, so once again, the architecture defines exactly how it's going to interpret the contents of the disk. So the first block of the disk, which is block number zero, is called the boot sector. So. And so. When you start up your computer. The first thing, let's say this is physical address space. Right? So the first thing the computer will do before even the first instruction of your operating system executes is that it's going to load this sector number zero into some predefined address. It's going to load it here, and it's going to transfer control to the first instruction in that sector. Right? On x86, this address is hexadecimal 7c00. So you load this particular sector of 512 bytes, add this address, add this physical address, 7c00, and you transfer control to the first instruction. Recall from a previous discussion that when a computer boots on x86, it boots in 16-bit mode. Right? In 16-bit mode, there is no paging. Segmentation is, you know, of a very primitive form where you just multiply the base with a segment value with 16 and add it to the physical address. There's no GDD or anything like that. So at this point, the processor will be executing in 16-bit mode. The boot sector should be, what should the boot sector do? So the hardware will only load the boot sector from here to here. The boot sector should know where the rest of the kernel is, and now it should load it into the right memory and transfer control to it. So in those 512 bytes, the kernel developer needs to write code which loads the kernel into some other space and then jumps to it. Right? Fortunately, 512 bytes are enough to do this small operation. Right? So what we're going to look at next time is basically the code to do this, and then what does the kernel do next and next and next. Right? And then how does it start the first process. Okay. So let's stop here. "}
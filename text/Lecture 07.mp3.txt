{"text":"In the last lecture, we were discussing segmentation. Segmentation is a way to implement process private address spaces and to divide physical memory into virtual address spaces for the processes, right. So we said there are, you know, in some way segmentation provides a mapping from virtual address to a physical address. A virtual address is what the process sees and the physical address is what actually goes on to the wire to the memory, right. And so, you know, we said that the, there is some logic on the hardware of the processor which we call the memory management unit or MMU which does the translation and the particular mechanism that we are looking at right now is segmentation, all right. So this is how segmentation works. There are multiple segment registers. Every memory address or every virtual address that an application specifies which could be specified using direct, indirect, or displaced modes which we have already seen in the instruction encodings, whatever address there is, it has to be prefixed with a segment ID. So that address that is computed by instruction is actually the offset inside the segment that is specified by the segment ID and the segment ID could be CS, DS, CS, whatever, the segment gives you a pointer into a structure called the global descriptor table which also lives in memory, right. The address of the global descriptor table is stored in yet another register called the global descriptor table register, right. What the hardware does on each instruction is that it will dereference GDTR to get the address of GDT. It will add the value of the segment selector, these are all segment selectors, it will add the value of the segment selector to the base of the GDTR or to GDTR into whatever the size of the entry is. So this is one entry of the GDT, right, to get the appropriate segment descriptor. Each entry inside the global descriptor table is called a descriptor, a segment descriptor. What the segment descriptor holds are values like base and limit, right. And what the hardware is going to do is it is going to compute PA as VA plus base and it is also going to check that VA should have been less than limit. The hardware is doing this at runtime on each and every instruction, all right. If we just look at it, if we just look at what it is actually implementing, if this is the address space of process P1, so let us call it P1's virtual address space, P1's VA space and this is P2's VA space and let us say this is the OS's VA space, right. And let us say this is the physical memory, all right. Now let me call it the physical address space, PA space. And we looked, we saw last time how the PA space is organized, there is BIOS, there are devices and then there is actual physical memory inside the PA space, right. And now what the OS does is basically sets up the segment descriptors in such a way that you know each of these map to different regions of physical memory. So let us say, you know, P1's VA space here, so you know, let us say P1's VA space starts at zero and goes up to some maximum value max and let us say all the processes just for simplicity have a maximum value of max, that is the maximum address space a process can have. And let us say, you know, the OS also has zero to some, you know, O max, OS's max, right. So then, you know, I can, the OS can decide to place P1 anywhere he likes, for example he starts at B and so, and what does he set his base and limit to, he sets the base to B and limit to max, right. Similarly P2 can live here and this case becomes, you know, B plus 2 max, let us say. He can put the OS somewhere, so let us say OS is put somewhere. So this is how the physical address space looks like when I am using segmentation and this is what the physical address, the virtual address space of each process looks like. Notice that the virtual address space is completely independent or the naming of the virtual address space is completely independent of where it lives in physical memory, right. So it gives you independence, so it gives independence between the linker and the loader. The linker at link time does not need to worry about at what address I am going to get loaded, right. The OS can make that decision at run time, okay. So one way for an OS to implement virtual memory is that it can say, so let us say here is a CPU, right. So an OS could say at this point process P1 is scheduled on the CPU. So I am going to switch my GDT R, so like, you know, let us look at some ways in which an OS could actually allow multiple processes to live, to coexist in the system. So one way is, you know, let us say I have one GDT per process. GDT is 2 to the power 13 entries. Each entry is, let us say, 8 bytes, so roughly 2 to the power 15 bytes, that is 32 kilobytes roughly, okay. You have 32 kilobytes of space per process just for doing, implementing virtual memory, okay. All right, so I could have, you know, another GDT, so I could have P1's GDT, I could have, no, no, no, P2's GDT, P3's GDT and so on, right. So that is one way of doing it and each time I decide which process is going to get to run on the CPU, I just switch the GDT, all right. So I switch the GDT R to that process's GDT, okay. No question, all right. So why do we need different GDTs for each process? Yeah, it seems wasteful. Another way to do it is, let us have just one GDT and each time I switch a process, I just change the entries in the GDT, now that is another way of doing it, right. So these are all ways. The second way is obviously superior to the first way, all right, because I am not wasting space. I just have one GDT and I can just manipulate the entries on each context switch, very large, yes. I was just trying to, you know, give you a perspective on what all can be done, right. So basically if I want to schedule this process, I load his address space, if I want to schedule that process, I load that process's address space and so on, all right, okay, all right. So let us review protection. How does protection work? The GDT itself lives in the address space of the OS. So an application is not allowed to manipulate the entries of the OS and so it is not allowed to manipulate the entries of the GDT, all right. And secondly, I am not able to load another GDT, a process is not allowed to load another GDT because the instruction to load the GDT can only be executed at privilege level. And so the processor has the concept of unprivileged and privileged modes. And so the process, if it is running in unprivileged mode, cannot execute this instruction. So I cannot change the GDT. I cannot reload the GDT. I cannot change the GDT because GDT is not mapped in my space and that is enough, right. Now what the OS needs to do is it needs to do some kind of bookkeeping that which area, how much memory is allocated for which process and where I have allocated it. And so that kind of bookkeeping the OS will have to do, all right. For example, the OS will keep information like what the base and limit of all the processes that live in my system, right. And so when I switch to that process, I am going to pick up that base and limit and put it in my GDT, all right, and I am going to start that process, right. Where are these data structures being stored which contain the base and limit of each process? In the OS address space, right. A process should not be able to manipulate these things either, right. So these things also need to be living in a protected address space of the OS, all right, okay. The other thing is that sometimes, so now I am going to talk about how things like system calls are implemented. So, so far we have talked about a process having its own address space and a process being confined to its address space so it cannot do anything else, right. But we have also said that, you know, a process cannot live in isolation. It also needs to talk to the OS sometimes, for example, to make system calls. And so, and also the OS needs to take control from the CPU at periodic intervals to be able to do scheduling and preemption. So for that, even though there are times when you would want that both the OS and the application can, should be mapped in the address space. So both, so when the transition happens from application to OS, the OS is, address space should also be mapped so that, you know, the OS can execute, right. So GDT is actually each entry in the GDT, so let us say this is GDT, this is a GDT entry. So we have so far looked at base and limit. And it also has certain permissions, all right, let us call it perms. And which basically say, you know, whether this segment can be dereferenced in, at what privilege level, right. So we also saw that a processor, the x86 processor has this concept of rings, or ring levels. And you know, there are four ring levels, but for most practical purposes, let us assume there are two ring levels, 0 and 3, right. And so this permission is going to tell you at which ring, at which privilege level am I allowed to dereference through this descriptor, right. So for example, if the permission says 0, then this descriptor cannot be dereferenced if I am running in unprivileged mode. On the other hand, if this one says 3, then it can be accessed either in unprivileged mode or unprivileged mode. So apart from this base and limit, descriptor also has permissions, right. So what that means is that an OS can map some of its address space always in the GDT. And so, by the way, how does the processor know which privilege level I am running in? Last two bits of the CS register, right. So this last two bits of the CS register store what, which privilege level I am running in. Also, we said that a process cannot just lower its privilege level, right. I cannot just say, you know, if I am running at ring level 3, I cannot just say make it ring level 0, because otherwise then all protection is lost, right, okay. So if I am running at ring level 3, I can only set my segment values, register values to one of the descriptors which have perms equals greater than equal to 3, right, or just 3. So I cannot set CS to this descriptor. So let's say this is descriptor 10 and this is descriptor 11. You know, setting it to 10 is illegal, which means it will cause a processor exception and the OS will take over, right. But setting it to 11 is okay. That allows the OS to keep itself mapped in the GTT, right, which means that if a processor needs to ever transition from unprivileged to privileged mode, it already has some of its address space mapped and so it can start using it immediately, right. It doesn't have to set up its own address space as soon as it enters the privileged mode, okay. So before we understand that, let's also understand how does the processor actually change the privileged mode, change to privileged mode, right. So I am actually executing the process and I am executing in unprivileged mode and let's say an interrupt occurs, right. Interrupt occurs and the OS needs to now run, right. And the OS needs to run in privileged mode because the OS will need to access its own data structures to be able to do scheduling, for example, access all the base and limit values of different processors and then decide which one to pick and put it in there, right. So to be able to do this, there is another table called the interrupt descriptor table, IDT. Interrupt descriptor which has, which is a table of, you know, 255 entries. Each of these entries basically says, has a CS colon EIP pair, right, so let's say CS 2 colon EIP 2 and so on and this is 0, this is 1, this is 2 or let's say this is 10, 11, 12, just to arbitrarily choosing these values, right. What this means is that if an interrupt occurs, if interrupt number 10 occurs, then switch the instruction pointer and the code segment to these values stored in this descriptor, right. So for example, if I say that a timer interrupt is going to occur at interrupt number 12, then whenever a timer interrupt occurs, the execution is going to switch the code segment and the program counter, EIP to these values, okay. So once again, let me just, let me just say what I am, what this means. So let's just draw the hardware diagram. So let's say this is the CPU and this is memory, devices. The CPU has a pin which is called the interrupt pin, right, and that interrupt pin is connected to some logic, right, and then that logic, and that logic just multiplexes lots of devices and allows them to set interrupt to the CPU, right. So let's say there's a disk device, there's keyboard, there's mouse, there's network, there is, and there are other devices on the motherboard and they are all going through some logic and ultimately they are connected, they also have a connection to the interrupt port of the CPU, right. So when this line gets set, the CPU gets interrupted, right. So whatever it was doing as a regular execution, it gets interrupted. What does it mean for a CPU to get interrupted? It basically means that it switches execution to some, based on this interrupt descriptor table, in this way, right. So if, so apart from the interrupt pin, there is also, you know, there are also pins which specify the interrupt vector number. So let's say, you know, a device wants attention, it says I want to assert the interrupt pin, the interrupt gets raised to the CPU, but before it raises the interrupt pin, the interrupt vector number has been set appropriately, all right. The interrupt vector number determines which of these entries gets activated, right. Let's say entry number 12 gets activated, which basically means that the execution should get interrupted, which means whatever it was doing should get interrupted, and the next instruction that should execute should be at this address, CS3 colon EIP3, all right. That's the semantics of the CPU. Who sends the interrupt vector number? The hardware device, right. So you have programs, so there's logic, that's, you know, sometimes programmable, often programmable. You can say that, you know, this device has been connected to this interrupt number. This device has been connected to this interrupt number, and so on, and so the OS can also program the device, and now when the device actually asserts an interrupt, that particular vector number gets sent to the CPU, right. Depending on the interrupt number, the corresponding program counter gets set, right. This program counter is also called the handler of that interrupt, right. In other words, when an interrupt occurs, the handler gets called, okay. So now what happens is, what the OS will typically do is that it will install these handlers a priori. So for example, it will say that on a timer interrupt, execute this code. That code will probably live there in the address space of the OS, right, which means that the CS3 will be a segment selector of the OS. I mean, the descriptor that is 0.2 will be a descriptor of the OS, right, and this descriptor is allowed to have the last two bits as zero, which means ring level zero, right. So that's one way the OS can actually rest control of the CPU from the running application, okay. So the OS will typically install a timer handler, a timer interrupt handler. The timer interrupt handler's code will actually live in the OS address space. It will set up the interrupt descriptor table in such a way that the pointer, the handler of the timer interrupt points to the handler in the OS address space appropriately, and irrespective of what I'm executing, as soon as the timer interrupt occurs, the process is going to switch to this code segment, which is most likely a privileged code segment, and it will start executing in OS mode, right. Here's an example where CPU switches from unprivileged mode to privileged mode, or ring level three to ring level zero. I said that a processor, a process cannot just lower its ring level, but ring level can be lowered by other events, like an external event, like an interrupt got set, right. So in this hardware figure, one of the devices is, let's say, a timer clock, right, and the CPU can program the timer clock to say I want an interrupt every 100 milliseconds, right. So the CPU has told the timer clock, I want an interrupt every 100 milliseconds, because I want to, you know, execute after every 100 milliseconds to take stock of the situation, who all are running, who all are waiting, who should run next, et cetera, et cetera, right. This is called scheduling, right. So the OS will program the timer clock. How can it program the timer clock? Using the IO address space that we've already talked about, right, either in out instructions or memory mapped IO, where you can just write to physical address space and you can get to. So you can program the timer clock to generate an interrupt every time quantum, let's say the time quantum is 100 milliseconds, that interrupt gets generated after that every time quantum, and the OS gets to run at every time quantum. The OS gets to run in privileged mode, obviously, right. The OS, when it's running, wants to be in privileged mode so that it can do whatever it likes. Irrespective of whether the processor was running in unprivileged mode or privileged mode, as soon as the timer interrupt will occur, you will start running in privileged mode, and you will get to do whatever you like to do, right. Similarly, so we have looked at the interrupt descriptor table. Notice that the code segment in the CS value, the selector value of the code segment in the interrupt descriptor table has to point to one of the valid entries in the global descriptor table, right. And because of this perm field in the global descriptor, I'm able to do this, right. So for this to be a valid value, I mean, the selector is going to point somewhere in the table, right. And so there has to be an entry for the OS address space in this table. But I also have to make sure that the process itself is not able to change its entry to that descriptor, right. And so the perm field in the descriptor allows you to do this differentiation, right. So a perm zero field can only be accessed if, you know, if you are executing in ring level zero, and you can only execute in ring level zero if you, for example, get a, get an interrupt. Now the interrupt descriptor table. The interrupt descriptor table is, so we have seen it, we have seen that it is used for external interrupts. Particularly we saw how it could be used for the timer device, right, but it could be used for any other device as well, for example, disk, network, printer, whatever, right. So let's say, you know, your program is executing, the printer has finished some job, and once you just interrupt the CPU, it will send an interrupt. The OS, if it's the same OS, would most likely set up the handler to live in the OS address space, because it's only the OS which is allowed to talk to the printer, right. The processes are only allowed to make system calls to the OS. So the OS, the printer handler is going to get called, and the OS can do appropriate handling for the printer. The handling may mean, okay, just say, you know, just update some internal data structures, and then return control back to the process, right. Or the handling could mean, you know, notify the process that something has happened. What are some ways of notifying the process? Signals, right, so that's one way of, let's say, notifying the process, all right. So other devices. It can also be, it's also used for exceptions, for example, divide by zero. So what happens if a process is running in unprivileged mode, but it makes, it calls an instruction which actually amounts to a division by zero. It executes an instruction which amounts to a division by zero. The processor doesn't know what to do, because the division by zero is undefined. So it's going to raise what's called an exception. Raising an exception is internal to the CPU, as opposed to the previous example where we saw that an external device is actually asserting the interrupt pin. Raising of an exception is internal to the CPU, right. But the effect it has is roughly similar, which means, you know, every exception is allocated a particular number. So let's say, you know, the divide by zero is allocated number nine. Just making it up. It's not the real number. But let's say it's allocated number nine. So the ninth entry in the interrupt descriptor table should point to the handler of a division by zero exception, right. So typically what will happen is if a process executes divide by zero, an exception is going to get generated. The exception handler must have been set up by the OS in such a way that the handler actually points to OS address space. And the OS's divide by zero handler gets called in privileged mode. The OS's divide by handler can do multiple things. It can either just straight away kill the process, saying that, you know, he was not allowed to do that. Or alternatively, he can send a signal to the process saying you did a floating point exception, right. So we also saw sigfpe in Unix, which was just doing a signal to the process, right. Similarly if there's a segmentation fault. What's a segmentation fault? There's a memory instruction where the address is not legal, right. So in this example, all addresses between zero and max are legal. So if the address that he's trying to dereference is between zero and max, it's legal. But if he tries to dereference a negative address, or he tries, you know, anything, if it's an unsigned, then the only possibility is if it tries to dereference an address which is greater than max, then the processor is going to raise an exception, right. How does the process know that it's an exceptional condition? The segmentation logic has this assert, right. So that assert is going to fire, saying that, look, you are actually trying to be greater than limit, right. So the processor is going to say there's something wrong. It's going to throw an exception. Once again, that exception will have a certain number, depending on the type of that exception. So let's say the segmentation exception number is, let's say, 14. So the 14th entry should be set up by the OS such that it points to the segmentation handler, fault handler. And the segmentation fault handler may choose to either kill the process, or he may want to do something else, or he may actually send a signal to the process itself, like the 6xv that we have seen on Unix, okay. So that's, those are two uses of interrupt descriptor table. The third use is actually the same thing, is actually also used often for implementing system calls. So we saw that system calls are basically functions that are implemented by the operating system and called by the process. But clearly, the system call function, the system call itself, has to execute in privileged mode, right. It cannot execute in unprivileged mode, right. If I, for example, make a read system call, and the read, and the file descriptor is actually pointing to a device, then I need to talk to the device, right. And that talking to the device may need privilege. And so the system call itself needs to be implemented at privileged level, whereas the caller is in unprivileged level. So the caller is unprivileged, the callee is privileged. And so I cannot just implement it as a regular function call, as you have seen last time. So one way to implement system calls are what's called software interrupts. So software interrupts are nothing but instructions of the form int, dollar, some vector number. This int is the opcode of the instructions, says interrupt. So apart from this, which is, you know, somebody from outside is asserting the interrupt pin, this, which is, I made an exception, like a divide by zero segmentation for, or others. Here's an example where the software deliberately and explicitly says, raise this exception, right. So here's an instruction that just emulates the raising of the exception number, of the vector number, specified as its operand, right. So I can say, raise the, raise exception number 70, 80, right. And so the 80th entry in the interrupt descriptor table will get activated. And that particular handler is going to get called, right. So how will system calls get implemented in this way? Let's say this is the interrupt descriptor table. And you know, here are all these entries. Let's say, you know, some of these entries are pointing to, let's say this is for the segmentation fault, and let's say this is for the floating point exception, and they are pointing to appropriate handlers in the OS space. And then, you know, there is this special number, which the, which the operating system can define as a system call number. So let's say this is the sys call number, which will also point into the OS address space. And basically, one way to implement system calls is that the process sets up, sets up the arguments somewhere. Let's say it sets up the arguments on, in the registers. And then, executes this instruction. This instruction is going to execute a routine inside the OS, and that, that routine should assume that the system, the application is trying to make a system call, right. And so what this, that routine is going to do is it's going to look in the value, in the registers for the operands, and exactly what you want to do. So for example, one of the operands could just be what system call you want to call, whether it's fork, or exec, or read, or write, or open. That could also be specified in a register, right. You set up a register saying, this is a system call I want to call, and then I just execute this instruction, int, that number. The OS handler gets to run, it checks the value of the register, and based on that, it executes the corresponding functionality. Yes. Why do we need software interrupts? Why do we, or I think the question is also, why do we need system calls? Why do we need system calls? Well, because the process cannot do everything itself. It needs some things that only the OS can do for it, right. That's the OS abstraction. For example, I want to fork a process. I need to tell the OS that please fork a process for me. The OS is an intermediate agent that's working on your behalf. You only make requests to the OS, that look, please do this for me. And the OS checks whether you are allowed to do this or not, and then depending on what he finds, he's either going to do it for you, or he's going to say no, I'm not going to do it. There's a separation of privilege, and the system calls are a way of actually bridging that gap between two privilege levels. And the question really is, how do you implement the system calls? So we have already seen why system calls are needed. We're really talking about why, how do you implement the system calls? Because the system call also needs, so there is some hardware support in this, in the mechanisms that I've described so far. The hardware support is that there's an interrupt descriptor table, which has these pointers, which have these long jump pointers, which has a code segment and a program counter. And then there's a global descriptor table, which uses those selectors to basically say exactly which address you should go to. And then the application just simulates an interrupt, and tells the OS that this is what I want to do. So it's basically overloading the same interrupt mechanism to also do system calls, and also do exceptions. So this is one mechanism that can do all these common things for you. So what about all the system calls? Are all the other system calls also in the interrupt descriptor table? Actually there's just, you only need one vector number for the entire system call space that you have. You can specify what system call you want in the register. You set a certain register value, and that's going to tell you whether you want it to fork or exec or whatever. Because if there are 300 system calls, then I'm going to exhaust my IDD space. We just have one entry for this system call. And then you specify it as an argument, what system call you want. All interrupt handlers are asynchronous. What does that mean? No. So, okay. Good. So now the question is, how does the interrupt handler execute? And in what environment does it execute? Firstly, the interrupt handler execution, so I was executing a certain instruction in a certain address space. An interrupt occurred, or you know, a software interrupt occurred, or an exception occurred. All these three are the same. I'm just going to call it the interrupt occurred, right? So I'm executing a certain instruction in a certain environment, and an interrupt occurred. I just switched my CS and EIP. Nothing else changes. So I'm still executing in the context of the original process, in the same address space. That's not completely true. It also changes two more things sometimes, which are, so it changes CS, EIP, and EIP and it also changes SS and ESP in a conditional manner. So, on an interrupt, four things get changed, potentially. One is the code segment and EIP will definitely get changed, because you want to point to the new handler. And what's also needed, as we're going to discuss next, is basically change the stack pointer. You also want to change the stack. So you're going to operate on a new stack. Why that's needed, et cetera, we're going to discuss very soon. And SS colon ESP basically determines the position of the stack. So an interrupt can potentially also change these values. Apart from that, it changes nothing. So the same address space, same everything. Of course, the handler, the first thing it may want to do is, you know, reload its segment registers. So the first instruction, for example, in the handler would be move some value to the DS register. So that the next memory accesses, which go through DS, actually are OS values. So the new stack that comes in is called kernel stack, but, you know, let's just hold on to that thought for a moment. Okay. So let's see. So a CS and EIP handler is, so let's say this is a handler. And let's look at a typical code for a handler. Firstly, we have established that the handler lives in the OS address space. And the descriptor to which CS points should already be mapped in the GDT. The first thing the handler may want to do is, let's say, set up DS. Something, some value to AX, and then move that value to DS. That may be the first thing the OS may want to do, because, you know, very soon I'm going to start executing code, which is going to do memory accesses, and I want that those memory accesses should actually be for the OS address space. And so for them to be, for the OS address space, all my segments should actually be pointing to the OS's segment descriptor. So I may want to do it for other segment descriptors also, for example. I could also do it for, let's say, the stack segment. But there's a chicken and egg problem here. So let's say I'm a process. And here's the OS. And I executed a, and some interrupt occurred. Let's say it was software interrupt, hardware interrupt, doesn't matter. And the OS gets to run. The OS, before it starts running the first instruction, needs to save some context of where it was when it was interrupted. Because, you know, when it's going to return, it needs to restore that context. In particular, what context does it need to save? Tag pointer, okay. The instruction pointer, the old instruction. Anything that it's overwriting, it needs to save the old value, right? Because it will need to restore the old value. So so far we have only seen that it overwrites these two registers. So those are the two registers that it needs to save. It's overwriting CS and EIP. After it's done executing, it will want to restore CS and EIP to its original value so that it can continue from where it's left, right? So it needs to save that somewhere. The question is, where does it save it? If the handler is making a change in the register, it's happening in software. So if the software writer is actually making a change to the register, he should be making he should save that in software. But the hardware doesn't need to save it, okay? For example, the handler is overwriting DS. Before he does that, he may want to move, he may want to save DS somewhere. But that's completely a software mechanism. Whereas the saving of CS is a hardware mechanism. Because CS gets overwritten by the hardware. There are some things that the hardware is doing. For example, it's overwriting CS and EIP. And everything else, the software is free to do whatever it likes. Now, this is a typical thing what a software will do. But it may or may not do it, depending on whether it's actually going to make a memory access or not. Okay, so I mean, you can do all that. So you have to save all the registers of the process, that's true. But all that can be done in software, right? So the handler itself will have logic to actually do this saving and restoring. But we are just talking about, you know, the process by which the handler gets called. Even that process is actually clobbering some registers. And those registers have to be saved by hardware. Because by the time the software gets run, it will have no idea what the old values were. So some values need to be saved by the hardware. And in this case, we can clearly see the old CS and EIP need to be saved by the hardware. The question is, where does it save it? So one typical place where you usually store these things is a stack. So, you know, the process may have some value of ESP. And one response to this question could be, let's just push CS and EIP to the user stack. So just decrement ESP and stuff CS and EIP on the stack, on the top of the stack. But the process is untrusted. You know, a process could actually set up ESP to zero and then call this instruction called int something. And the OS is going to now try to, or the hardware actually, is going to try to stuff CS and EIP at zero. Where nothing lives, or some other invalid address. And so what's going to happen is the processor is going to go into recursive false exceptions. Because the hardware tried to push something to an invalid address. And that's going to cause another exception. And now the exception handler is going to try to execute. And again, you know, you're going to try to, for that to execute, you're going to try to push the exception handler CS and EIP into the stack. So if the stack is invalid, you know, you have basically halted the system completely. The way we wanted to design a system is that these processes should not be trusted. A process should not be able to bring down the system. Definitely not. So I cannot trust any pointer that the process provides me. ESP is just a pointer that the process is providing me. And it's supposed to hold the process in stack. But if the process is malicious, it can just set it to something wrong. Or if it's just, you know, if it's also possible that the process is actually running out of stack. And in which case also, I don't want to be held responsible for that. So what the OS needs is it probably needs a stack of its own. It needs some space, which is going to say, this is my space. And this is where I'm going to save these things before I execute. And that's where I'm going to store things from when I execute. So the processor provides another data structure or hardware structure to do that, which is called the task state segment. The task state segment, you know, is actually also a selector, which points to the GDT. But eventually it points to a data structure which contains two values, SS0 and ESP0. And what this means is that any time you switch from privilege level higher than 0 to privilege level 0, load SS and ESP with these values before pushing the old values on the stack. So let me repeat. Anytime I want to switch from process to OS, before I attempt to push anything to stack, I'm going to overwrite my SS and ESP with these values. So the X86 structure allows you to, you know, there's some memory structure that allows you to specify that this is SS0 and this is ESP0. And each time you transition privilege level from unprivileged to privileged, SS will get loaded with SS0. ESP will get loaded with ESP0. And then the old values of SS and ESP and CS and EIP will get pushed on this new stack. In other words, let's simplify it. There are two stacks. There's a kernel stack and there's a user stack. The user stack is untrusted. When I make a system call, I'm basically executing the stack pointer pointing to the user stack. Or it may point to something else also. I don't care. Before I execute even the first instruction or before I even try to push anything on the stack, I should switch stacks to the kernel stack. We are clear on that. The question is, this operation of actually pushing has to be done by the hardware. So the hardware needs to know where the kernel stack lives. The hardware provides the data structure where the OS can set up values to specify that this is where the kernel stack is. And so if you ever transition, load this kernel stack before trying to push values on it. So the OS tells hardware where the kernel stack is using SS0 and ESP0 pointers or values. Which segment? What offset? Once again, the value of SS0 should be de-referencable inside the GTT. Using this, the kernel tells the hardware that this is my kernel stack. Right now I am executing in user stack. But if there is for any reason a switch to privileged mode, the first thing you should do is load the stack. The second thing you should do is push CS and EIP of the user into this stack and not the user stack. And also push the old user's SS and ESP onto this stack. Because you are also overwriting the stack. So that needs to get pushed now. I mean the hardware has some temporary buffer to basically make sure that it's not lost. That's all hardware implementation. We just have to look at the semantics of the hardware. The semantics of the hardware is on an interrupt or on a switch, it's going to switch the stack. It's going to save the old CS and EIP and it's going to save the old SS and ESP. Save the old instruction pointer and save the old stack pointer. And now it can run. Because this value of SS0 and ESP0 was set by the OS itself, it's a trusted value. I can trust it. No process is allowed to modify it. Let's stop here."}
{"text":"All right, so let's start welcome to operating systems lecture 9 Right so so far we have seen Operating system abstractions typical operating system abstractions a process has its own private address space all of the processes code data stack and heap live in that address space right and Depending on what are the values of certain registers like EIP, ESP etc. You know where the code is where the stack is What to execute next The OS transfers control of the CPU to a process And then the process is free to run Right, so the OS is completely out of the picture when the process is running in some sense The OS can regain control if The process makes a system call for example right it causes an exception like a divide by zero or a segmentation fault or Or some external interrupt occurs like some device needs attention In which case you know the OS comes into play right so we are we all understand it so far Then you also said you know to implement address spaces. There is a mechanism called segmentation which involves On-chip structures like segment selectors Etc There are segment so there is a global there's a descriptor table so there are segment descriptors Yes, and segment selectors point to segment descriptors, and they live in a in structures like the global descriptor table Right and global descriptor table is also pointed to by an on-chip register like it's called GDTR all right and and so this allows you to implement address spaces and each process can have a separate base and limit and Completely non overlapping base and limits will ensure that every process has a private address space Also the operating system can have a private address space for itself And so you know and you should make sure that the operating systems base and limit is not overlapping with any of the process Okay, then we said okay, but we also need to make implement system calls etc So you know I need to transition between address spaces and all that so firstly the GDT and descriptors also have a field which says Whether it can be executed in privileged mode or not so certain segments are allowed to be executed Accessed in only privileged mode and others are allowed to be accessed in unprivileged and privileged mode both And then we said how do you transfer control an application a process shouldn't be just allowed to Say that now I want to execute in privileged mode right so but you sometimes want to execute in privileged mode for example if you Want to make a system call or there's an interrupt or there's an exception etc so for that to facilitate that We have what are called you know interrupt Descriptors and They are they live in the structure called the interrupt descriptor table right so if an interrupt occurs And I'm using the word interrupt to mean any any of the following conditions exception System call or external interrupt or let's let the other term for this is trap So if a trap occurs the interrupt descriptor Dictates how it should be handled right so the interrupt descriptor contains things like the CS colon IIP pointer And that's what you transfer to right so what the OS the now the so this is the mechanism provided by the hardware It's the responsibility of the OS to set up these interrupt descriptors properly so that if if an interrupt occurs Then you know the appropriate handler gets called number one number two the process itself should not be able to override the handler Right and number three the handler itself should be very trusted piece of code It should not have any bugs or anything otherwise. You know I know it's a Malicious process could make allow it to could actually Trick it to do something which he wants with the OS shouldn't be really doing All right Because if the code segment is a privileged code segment the handler will win is going to be executing in a privileged mode All right, and so the handler has to be very very carefully written so that You know the process cannot ask the OS to execute his code in privileged mode for example All right Okay, and then we said look if if So on each of these traps. There is a user the trap causes trap Can happen trap can transition trap can happen in a kernel mode in which case? You know the old CS and IIP is stored on the current stack whatever the stack pointer is Because it's already executing in the kernel mode the current stack must be something that's trusted the kernel must have set it up Itself so when if a trap occurs in the kernel mode the old CS and old IIP and Old II flags are stored on that stack right on the other hand if a trap occurs in user mode It's not safe to store these values on the user stack So what happens is if a trap occurs in the user mode or the unprivileged mode? The processor also switches the stacks right and where does how does it know where to pick up the stack from? Yeah, there's a data structure There's a there's a hardware structure called a task page segment which points to the task page segment And so you can basically pick up that so the hardware knows here's where to pick up the stack pointer from and it loads that Stack pointer and then pushes these things on to it right so because it's also loading the stack pointer It also needs to save the old stack pointer Right so if you take a trap in the user mode you are saving saving five values to the stack If you are taking a trap in the kernel mode you're saving only three values to the stack Okay All right So so it's the responsibility of the kernel to set up this task page segment appropriately before transferring control to the process Right because if it doesn't do that then if a trap occurs or a system call occurs then things can go back now the other thing is that How does so so each process has? an address space each process Also needs to know you know what is the kernel stack that it's run on right so we said that a kernel could be implemented In two ways one is the process model They are one stack per process one kernel stack per process in this mode Whenever you transfer control to a process you have a special You have a special area, which you call this process is kernel stack right special memory area And that that's basically what you load into the task segment so before you actually transfer control to process p1 You load p1's kstack before you transfer control to p2 you load p2's kstack and so on right in the other model Which is the interrupt model? You basically say let's just have one stack right and so irrespective of whether you transfer to p1 or p2 This the the stack will be the same, which is you know one kernel stack. Let's call that the kstack right and and so Basically that means what that means is that whenever a process actually transitions to kernel mode It will always start start with a completely fresh stack Right completely fresh a fresh stack basically means it has nothing else except The five values that were pushed on the trap itself right five or three whatever the case may be So you know in the interrupt model whenever you transition from the user to kernel typically you will start with a fresh stack all right actually Even in the process model typically you always start with a fresh stack But the kernel actually has a flexibility to actually you know say that look these are some values already pushed in the stack and So in the process model for example I could say here is my you know Here's my ESP 0 and I could have already pushed something here And though when the trap occurs actually the free the five values get pushed here And so the stack is not completely empty it also has other stuff which the handler may need Right, but typically this is not used you also start with a fresh stack in the process mode You don't really have Things that are saved previously and similarly in the interrupt model Of course it is possible that while I was while the process was actually Executing in the kernel mode, so you know So now I'm going to use this terminology a process could be executing in user mode Which means the process is executing in its own address space with its own EIP and all that or the process could be executing in kernel mode What I mean by a process executing in kernel mode is let's say a process executes a system call I transition to the kernel It's not the process which is executing, but it's the kernel which is executing on behalf of the process Right or you know there's a there's an interrupt that happened So the the kernel it is an external interrupt that happened So the kernel actually takes over and the kernel is executing on the stack that was you know for example The stack of the process that was originally running right so even in this case I'm going to say that the process is running in the kernel mode It's really the kernel running on behalf of the process or in other words is the kernel running on the stack of the process in The process model right okay, right, so so yeah, I'm explaining how it works in the interrupt model So let's say a process was executing in the kernel mode and now the process wants to switch the stack Right or switch the start another process running So let's say a process made a system call like read Right and the file descriptor of the read was actually pointing to a file which lives on disk And you as you know a disk actually a very slow device is going to take a lot of time Right so process said read the kernel figured out that it's going it wants to read from the disk now one option Is that the kernel could just you know? The you know keep spinning waiting for the disk to complete. No, that's the polling model And the other way to do it is you say okay? You know I know the disk is going to take a lot of time, so I basically say I want to switch the The CPU right so I'm going to get the CPU from p1 to p2 While p1 read system call is actually executing on the disk so p2 can execute on the CPU while p1 is executing on the disk So to say Right now when I'm doing this when I go when the disk actually completes And I want to get back to p1 then I should know exactly where to start from in this case I should start from within the kernel execution right because I was interrupted within the kernel execution And I switched to p2 and now I want to cut back to p1 in the kernel mode and so the kernel stack should be Exactly has as it was left before the context switch right so the switching from p1 to p2 is also called a context switch All right, and and What you need to do in the interrupt model is that when you do a context switch you also store the contents of the stack Somewhere where they from where they can be restored when the p1 gets context switch back Right when it gets restored right in the process model You don't need to save the contents of the stack you could just save the stack pointer, and that's enough So that's the that's the real difference There's no fundamental difference in one case is storing the state contents of the stack If there's a context switch that occurs within the kernel execution in the other case you're just switching the stack itself All right, okay All right, so so that's our review of last time's discussion So I see some questions over email and there was also a question last time that can't a kernel just Jump to the user mode Directly using let's say the L jump instruction instead of the you know instead of the irate mechanism that we saw last time So recall that we saw this mechanism where an external interrupt or an exception or a software interrupt enters the kernel after pushing some data on stack and then there's this irate instruction that pops this data of the stack and then Returns back to the user typically right and so I said even the first process I mean this stack could either be created by an entry to the kernel by the real entry to the kernel by hardware or It can be manufactured by the OS kernel itself and simulated And an irate is simulated as though an interrupt return has happened Although it has not happened to transfer controls back to the user and so I think the question was why do I need to do The do this sort of complicated mechanism where first I first set up the stack and then I call irate Why can't I just do L jump to to that particular? Code segment of the user. Well, it turns out that L jump doesn't allow, you know Transition across privilege levels. I'll jump only say selector. Okay. All right, so nothing nothing fundamental But just a matter of fact The other question I thought I got was our email was that When you context switch to processes I said you change the address space, right? So I said that let's the first the first sort of Dumb way of switching the address spaces you change the GDT every time you change the process So you switch from P 1 to P 2 you also reload the GDT are each time you do that, right? Before you can transfer control to but he said, you know, that's too wasteful You know GDT GDT is actually 2 to the power 13, which is which is pretty big and you know If I want to have one GDT per process, that's too wasteful The other way to do that was let's you know, overwrite the values of the GDT itself each time I context switch Each time I context which I overwrite the values of GDT and then I can go back and so the question was why do I? Need to even overwrite the values of GDT Why can't I just have you know that 2 to the power 13 entries in the GDT and I'm so far I've just said, you know, that's you know, six segments and so, you know, what are the other entries is really therefore Why can't I just say, you know process P 1 these entries process P 2 these entries process P 3 these entries? And so when I context switch, I don't even overwrite the GDT. I just reload the segment selectors and I'm done So what's the problem? So my GDT contains the segment selectors of all the different processes When I want to context switch from one process to another I just change the segment selector, what's the problem a Process is free to change its segment selector, right? So if the GDT has segment descriptors of other processes Then a process can easily just change overwrite its segment selector to point to somebody else else's address space And so that's a security risk. P1 can now access P2's memory, which was not supposed to happen So you actually need to overwrite the GDT to do with that. Sure Sorry That's in the descriptor, right? So, okay So, let's see how it works, right let's say this is my GDT Right and let's say this was P 1 P 1 base colon P 1 limit Right and let's say this is P 2 base Colon P 2 limit Right and let's say this is OS base Base colon OS limit. This is the kernels address space, right? All right. Now when I context switch if I just switch the segment selectors You know and a process is allowed to overwrite its own segment selectors So what did all the process needs to do is point to this segment select, right? So P 1 can now point to P 2 and so that's a problem Right P 2 cannot P 1 cannot still point to OS because you know, the OS will have a bit which says privileged Right, so you cannot in an unprivileged mode point to the OS is at the descriptor But you can point to another process is descriptive because that's also unprivileged Right and so you don't want to allow that. So each time you switch between between two processes you actually You know ensure that the peak the descriptor table GDT has only entries which This process should be allowed to access Okay Yes, so there should not be any entry of P 2 when P 1 is running in the GDT Okay, so so this is you know, this is the this is the way that that was a suggestion in my in the question in The email but this is not how it's done, right? So you won't have separate descriptors of P 1 and P 2 what you will have is you will have a GDT Right and you will have something called user base and user limit and You will have kernel base or OS base and kernel limit, right? So you'll have just one descriptor for the process and each time you context which you're going to override this descriptor Right That may you know that may bring you to the question, you know Why do I need to do by 13 entries if you know, that's all I'm using the GDT for well, you know There are other ways to use segmentation hardware But this is the typical way and OS will use it For example, you know, this is how Linux would use it or Windows would use it or or you know The your programming assignment OS Pios is going to use it or what we're going to study later It's easy. So most operating systems use this hardware in this way You know, the hardware designers imagine a certain way of way of usage the operating system Designers figure out that you know, this is the best way to use it and so, you know There's some extra things that go into the hardware because the hardware was designed before though It's written and you know, even the ring levels are an example of that the hardware designers actually designed four ring levels 0 1 2 3 and the The intention there was that you know, you will typically need multiple privilege levels You know, you will need 0 for the kernel 1 for the device drivers You know This is this is typically what you hear then 2 is for let's say the libraries the system libraries and then 3 is for the real Application, right? So that was the that was the imagination of the hardware designer the OS designer said no No, I don't need all this. It's too complex. I just need to And so I'm just going to use 0 and 3 Okay Alright Yeah, so the other question I got was, you know You know, I refer to the Wikipedia page of GDT and the GDT has also other things like task settings and LDT local descriptor Colgate what are these for? I would say ignore it. We don't need it for this course Once again, there are features that are present in the hardware. We don't I mean that's so many features that we don't we are not talking about All right There was another question. Sometimes an exception is customized according to a process so Question is, you know, can a process actually customize the exception handler according to itself So saying that you know handle my page fault in this way Or handle my segmentation fault in this way handle my divide by zero error in this way Right or handle the interrupt from this device in this way and so on can a process do that? Well in the abstractions we have studied so far that's not allowed Right what executes in the kernel? On an exception is not controllable by the process. What is controllable by the process is signal handlers So, you know, for example units provides you this mechanism of converting Hardware interrupts or exceptions to software signals Right. So if for example you actually did a divide by zero the hardware is going to generate a floating-point exception The OS is handler for that floating-point exception is going to get called the OS may convert it into a floating-point signal and Give it to the the process which actually executed that offending instruction And so and so basically what will happen is that the process which was executing will now straightaway jump to the signal handler of the FBE the floating-point exception, right and so the signal handler of the floating-point exception can be customized according the process So the process can customize the handling of at the user level Handling we cannot customize the process the kernel level handling of a certain condition Right. Yes How will you tell so, you know Unix basically has Standard so hot, you know certain semantics, for example a floating-point exception will always generate the floating-point exception signal Okay, or a segmentation fault will always generate the sig seg V the segment So it's a segmentation exception on the hardware will always generate a segmentation exception in the signal in the software to the process Right and there are other ways by which a segmentation signal can be generated and and so on so there are certain semantics that always an exception at the hardware will generate a signal in the process level and now the process and Also, typically the process will have default handler solving for these signals and the default handler will just say, you know We'll just kill it kill you. There are certain signals that can have That can be overridden the handlers of which can be overridden and there are certain signals to handlers to which cannot be overridden for security Okay Okay, the question is there's an interrupt handler and there's a signal handler the interrupt handler lives in the OS the signal handler lives in the process an Interrupt that occurs actually first in so, you know, what happens both execute does one execute etc The answer is that they both execute, right? So when the interrupt occurs the kernel interrupt handler gets called the kernel interrupt handler is the one which is actually going to generate What does generation of a signal mean it just means that it's going to override the instruction pointer of the process with the value of the handler That's all Right, and now it's going to transfer control to the process just like you know It was doing earlier But the only thing is the process is going to feel that suddenly jump from where it was to something somewhere else So that's what generating a signal means Okay Not always right the question is why do we need two abstractions interrupt and signal if all that an interrupt does is generate a signal So an interrupt firstly an interrupt does not always generate a signal all right and Interrupt could be coming from a hardware device like a disk and in which case your device driver just needs to just copy the value That's served by the disk to some buffer in which case you don't didn't need to generate the signal So you know OS is in it is operating in a different environment Right the process in operating in a different environment The question you are asking is why do I need signals when I have interrupts the reason is because interrupts cannot be passed directly to The process because interrupt handling needs to be privileged mode handling because you're dealing with real devices real resources Right on the other hand You know you need signals because the process also needs similar kind of event driven behavior Something has happened You know I want to know about it, and I want to know it in an interrupt driven fashion as opposed to keep checking So you know you could you know unit signals is not a necessary abstraction I could just say you know I don't need you know my operating system does not support signals You know if you have made if you if some Error condition occurs if you make an exception. I'll always kill you right and if you for example make some kind of interprocess communication or some kind of You know device communication, then it's a responsibility of the process to keep checking rather than a signal based mechanism So you know this is also possible abstraction in which case an interrupt will not be converted to a signal right so just want to When you're designing an abstraction you basically want to look at you know what are the common things and what happens? So and basically what it turns out is that the fashion that the hardware design is implemented Those are the and the fashion that the operating system design is implemented There's some similarity between them signals are an abstraction that the operating system design is implemented Interrupts are an abstraction that the hardware design is implemented All right So there was another question let's say I have a USB port and there are multiple devices connected on the USB port You know you can connect a mouse and a keyboard to the same USB port using a hub or whatever and so now you know There's an interrupt then how does the OS know whether it's a keyboard handler that I should call or the mouse handler that I should Well an interrupt does not just just say that this put all the devices connected to this particular port Or you know all the devices for which the interrupt vector is this One of those devices has required my attention So that's what an interrupt means now the interrupt handler will typically now look at all the devices I trade over them and check ask all of them Do you need my attention you need my attention and so on and if whoever says I need your attention He's going to give the attention and don't say what attention you need right so it's interpret just a way of Say telling the processor or in that I need attention It's like you know a phone call versus an email right a phone call just immediately gives you some attention You know when you get a phone call, then you ask you know who you are etc What do you need etc an email is basically it's in the in the email box at the polling mode in which case you're going To just check on your own in both case the operation is the same It is a way of notification. That's different All right Okay Finally I want to I said that there are two pointers on the chip There is the global descriptor table register Which is the which is points to the GDT, and then there is the interrupt descriptor table register my question to you is Is the GDTR the value in the GDTR is that a physical address or a virtual address So what is the virtual address virtual address in segmentation is all the form of you know Percentage some selector like you know CS colon percentage yet. This is a virtual address or percentage SS colon percentage ESC or You know DS EBX and so on these are all virtual addresses right or I could say CS colon 100 basically means offset 100 in the segment called CS Right so GDTR what what does it need to be is a can it be a virtual address or does it need to be a physical address Physical address because I mean the translation from virtual to physical needs to go through this This GDTR and so if that is a virtual address, then you are in an infinite loop so that doesn't make sense in fact The IDT are also is not a virtual address It's a physical address and if you in the terms of in what we are saying you know when we're only using segmentation All right, okay Okay, so so we saw that the process the curve so basically so far we have seen that the kernel executes transverse control to the process So if I if I'm a CPU You know and this is my timeline Yeah, give me a second Okay question How does the Sorry, how does the what fit in The physical address separate in the GDT are Using the LGDT instruction, right The LGDT instruction allows you to set up this value So whatever is the argument to this gets fed into GDTR operand to the LGDT instruction similarly LIDT instruction Fills in IDTR low GDT loads IDT. That's what it means All Right more questions In the GDT descriptor the u-base is it a physical address or a virtual address Physical right? I mean it doesn't make sense. It's a physical address limit. It's just so it's It's just a value. It doesn't matter. What about the IDT descriptor? IDT what does it have it has a physical address or a virtual address? Virtual it's basically CS colon EIP, right? So it's basically specifying both the segment and offset. So it's a virtual address Okay Right. So if I look at the CPU and I look at its timeline basically what happens is let's say this is boot So the kernel executes For some time where it boots boots up and then it creates some process internally So it creates some address space For example, it creates a segment for the address space and now it will set up the stack and call either it and here is The first process that gets run so it starts executing in user mode Now this process is going to make some system calls or you know Something still interrupt occurs and so some other kernel Activity is going to happen and then it's going to go return back to user then it happens kernel and so on, right? So that's a timeline of CPU. Sometimes it's executing in kernel mode. Sometimes things in user mode and etc Now in the event when it's executing the user mode, it could be executing let's say P1 earlier now, it's executing P2 and now it's executing P1 again and so on right and Each time the code it switches back to kernel mode the kernel has a choice whom to get to run next and they sets it sets things up accordingly and Transfers control to that particular process. For example, it sets up that sets up the kernel stack It sets up the address space and then transfers control to that particular process So to be able to do this and need certain data structures, for example, it needs You know, it needs let's say So typically it will have so a kernel Will store a list of Process Control blocks Or PCBs So this is basically all the active processes in the system at any time Let's say this is boot time At boot time. There is no active process in the system. In fact during all the duration There is no active process in the system at this point The kernel what it does is it adds it sort of creates manufacture the process There was no process earlier. That's fine So it manufactures the process it means it manufactures it creates a new address space allocates a new address space creates corresponding base and limit entries creates a kernel stack and Adds this process P1 to this list of PCBs. So add the PCB to this list, right? What are the PCB typical typically contain it will contain the idea of the process PID All right It will contain things like state What is it state whether it is currently running? Whether it's ready to run but it's not currently running. So things like you know, well, it's running a Process could be actually running right now, right or whether it's ready to run but not running Let's call it ready or let it blog. You know blog is basically things like I made a Request to the disk and you know, I'm blocked So I'm not ready. I'm not eligible to run on the CPU till the disk device comes, right? So what will happen is the the process that made the read system call that's put in the block state The device driver the device is active as you know Informed that please give me the value of these these disk blocks The device won't take some time and after that the device actually invokes an interrupt The colonel's interrupt handler come gets executed the colonel interrupt handler figures out You know Which request has actually finished and it figures out that the request that was finished is actually the request that was made by this particular Process and so now at this point it can transition it from block to ready Okay, so that state now there are other things like address space You know, for example, what are my base and limits In segmentation, that's the address space. That's all you need to store You know, let's say the kernel stack if I'm using the process model Then I store only the pointer or if I'm using the interrupt model, then I also and then I store the contents if any Okay, and let's add the information, you know, this is just example We want to look at what kind of information may be stored. But this is what a PCB is stored, right? Where are where is this list stored in the kernel data space, of course, right? You don't want a process to be able to ever Read or write to this list It's completely private to the kernel and you are implementing this using the kernels segmentation the segmentation at the base and limit of the kernel All right Now the question is how Does this time in what conditions does this transfer happen? We have already seen it can happen to system calls exception or interrupt. Now one of the system calls happens to be yield So, you know, for example Unix will have a system called for yield and the semantics of the yield system call is that You know The process figures out that I'm actually waiting for something And he wants to say that, you know, I'm waiting for something and I don't want to take up the CPU So it's like being a good citizen and he just says I want to yield the CPU So he just says I want to yield the CPU the kernel you transition to the kernel So the way it says he wants to yield the CPU is there's a system call called yield. That's the only way you Process could communicate with the kernel So the kernel the process says yield the kernel gets to run the kernel figures out whether there are other processes who are also waiting for the CPU and if so It you know should use another process through that CPU If there are no other processes, then it just says okay, you know, you are trying to be good But you know, there's nobody else. So why don't you just take it? All right. Okay, so that's That's a yield system call So that's one way that you could transition from user to kernel in which case you basically Transition the state of the process from running to ready Right. So if actually you you know, if somebody called yield you basically just Transition his state from running to ready and you transition another processes state from ready to running All right But you know not all processes are good citizens, so there could be a process which just you know, never called yield So what do you do? So you've discussed this before The kernel has you know has heavy-handed mechanisms in which case it basically sets up the hardware device called timer. So every you know, every computer system will have a device for the timer device on its motherboard, let's say and So that device is what the kernel has configured before transferring control to the first process So the kernel has configured the timer device to say periodically generate an interrupt every hundred milliseconds So even if the process is not calling yield every hundred milliseconds, the kernel timer interrupt handler Will get called And the timer interrupt handler may do this operation even if the process is not doing it Right. So a process can be can do call yield or the kernel can do it on his way In either case you are sure that a process cannot run away with the CPU, okay, right, okay So this mechanism of shifting from one process to another which is Converting my state from running to ready and convert converting somebody else's state from ready to running It's called a context switch, right? And of course, it's not just fitting states It also means saving my data which means my registers my stack in the PCB Right. So one of the things that a PCB also contains is let's say registers Save registers So all these things are saved in the PCB The state is modified from running to ready another process is state is modifying from ready to running Its registers are loaded from a PCB into the hardware state stack is set up properly and You give control right and eventually it will go on call irate which is going to go back to the process okay, so so this is the timeline of how a Other kernel executes. All right so so far we have seen that, you know, let's say this is my Physical address space and The OS Segments it into you know kernels Area p1's area p2's area and so on Right now and the kernel internally is Storing things like the global descriptor table the interrupt descriptor table The list of PCBs and other data structures that it needs and also the handlers all the code that's going inside the handlers It's all living in this region, right? Now let's let's look at something which is more fine fine. The end question is how does the kernel manage the space? So this is just a chunk of space that the kernel has reserved for itself now, how does the curl manage the space? So typically typically the how a software manages space are using these functions called malloc Which is memory alloc and free which is memory free, right? And so what malloc takes is a size and And returns a pointer and what free does is it frees that pointer? I'm sure all of you have used malloc and free. Yes Okay All right. So and of course malloc and fail, right? So malloc may return the null pointer in which case the malloc couldn't happen and this could happen If you know you've been malloc in too much and you actually run out of the space that the kernel allocated for itself So, let's see how malloc could be implemented typically the way it's implemented is let's say this is the kernel So I'm just you know magnifying this area. Let's say this is the kernel so The kernel itself will have some code It'll have some data And it will initialize its own stack somewhere here, right? So these are all the stacks So that's it's an interrupt driven model. Let's say it's initialize the stack here. So there's only one stack in the size of tail All right, and now everything else which remains in the space is what called the heap Which is managed by these functions called malloc and free Initially you just add the entire space To a list called a free list We add this entire space to the free list You reserve certain space for the stack and all the other space you basically say let's call it in the free list each time a function calls malloc each time the kernel some part of the kernel calls malloc you are going to Look at the free list get that amount of chunk of memory and return it Right and and so on each time somebody calls free you are going to add it back to the free list, right? So you can maintain a list of free memory locations So, let's see how this works. Let's say this is address space. That's the heap 0 and 2, you know some value M and Let's say you malloc 1 then you malloc 2 then you malloc 1 again Then you malloc 3 and then you said free 2, right? So let's say I said malloc 1 malloc 2 Malloc 1 again, let's say Malloc 3 and let's say my memory allocator is just doing contiguous allocation Just increments the pointer and just gives you the next available memory location and then I say free to Right. What's going to happen is this area is going to get freed and it's going to get added in the free list and then I say malloc 3 again and So what happens is this is a region of length 2 you are asked for 3 bytes and I cannot just give you these Right. So what because there is no contiguous right here. And so what I have to do is I have to go here And so what can happen eventually is that there can be lots of small holes In your address space, right? So you have areas that have been malloc and then there are holes in the middle that we freed But the holes are actually not big enough to satisfy many of your requests. So eventually your Your address space will get what's called fragmented This is called fragmentation So there are many algorithms on choosing where to you know, when somebody calls malloc The the function malloc has freedom in choosing exactly which area to give Right and exactly how to manage this space in such a way that you minimize fragmentation Is something that we're going to look at later, but we should at least know what the problem is Okay, same thing exists in the process level so, you know, I Motivated fragmentation in the context of the kernel, but similarly the process has a very similar structure. There's code. There's data You know, so there's somewhere there's a stack and now you have the heap everywhere Right, and now the function the process internally is going to you manage its own address space using malloc and free Which is the map managers keep using malloc and free. All right But when I look at the physical address space again So let's it is a physical address space The kernel This is p1 this is p2 and so on and so in a typical execution of the kernel You are going to see lots of process creations and process Exits the process is going to get created. You're going to allocate space for it. And you know, you're going to So let's say, you know p1 got 4 4 p1 Then 4 p2 Then 4 p3 Then you said exit p1 exit p2 Let's say you said 4 p4 Once again, you have the similar problem. So You know p1 p2 p3 got created like this then p2 got p2 exited and now I want to allocate space for p4 Let's say p4 was bigger than p2. You know, I have a hole that I cannot use and I have to basically use extra memory so there's a fragmentation in the Physical address space. What are some possible solutions? Okay, so let's say I wanted to look for p4 and let's say I know search entire address space and I couldn't find a block That's big enough for p4. One thing is I can just say, you know folks succeed didn't succeed I return a negative value to the four system calls. That's one way but you know, what is you know, the sum of all the holes is bigger than p4 and Can I do something smarter? I can just shift p3 down. What does it mean to shift p3 down? I just change the base and limit appropriately and the process will never know Right. So this indirection which is the segmentation hardware is actually allowing you to move the address space at will inside And without the process of annoying will you just change the base and limit you move the p3 down The process code has nothing to do with it Right because it sees still the same addresses zero to whatever maximum it's allocated All right Okay, but you know It's not a very convincing solution because a process may be large and copying between memory is an expensive operation because you know There's lots of bytes that are going to go over the system bus You're going to and and so because processes are big copying the entire process is a expensive proposition Also, you know, let's say I did p1 p2 So let's say I do 4 p1 4 p2 4 p3 and then I just wanted to say grow p1 grow p2 by 1 byte Not possible because there is p1 You know There's there's p3 right above p2 and so if I want to grow p1 by 1 byte Actually, I have to copy I have to find you know that Space and then I have to copy the entire p2 there and then I grow it by 1 byte once again Very inefficient way of doing things Before you call you change the base value, but you also copy the physical memory contents, right? You cannot just change the base value Right. Okay Okay, so Okay So these are problems which are again, you know come what are called fragmentation problems and The reason they are they exist is basically because the segmentation hardware allows us to only allocate contiguous regions of physical address space and and and give them to the Process so I cannot say, you know, no p2 has p2 lives here here here and here So I cannot have lots of different. I cannot just say these are p2's areas and I cannot just have a list of p2's areas I just need to say that p2 had lived in this contiguous address space if I were able to say that p2 live You know scattered around in the memory. Then it will be much easier. I could just do You know do things in a better way there is some respite though because as we said, you know segment there are six segments So I could potentially have six different Contiguous regions, but not now the programmer needs to be very careful about you know, which segment it's you know It doesn't see a uniform address space. It actually sees segmented address spaces. Oh, there's the code segment is a stack segment There's the data segment. It's possible but you know Typically you don't use it complicates the program the compiler it program complicates the job of the programmer Or the compiler the job of the compiler writer and so it's not typically done you like it's much easier to actually write programs For a uniform address space as opposed to a segmented address space All right. Okay, so but that's it. Yeah question. So I think there was a question there Okay Right, so question is, you know No, it does not know a priory how much memory and a process needs, right? And so question is shouldn't I allocate equal memory to each process? Yes. I mean that's one way of doing it I mean see what are our abstractions are abstractions of folk and exact and things like that, right? And then we have malloc and all that. So So when I do folk, I have no idea what this process is going to actually execute, right? You know, I just create an address space and you know in segmentation what I'll do is I'll probably create the address space equal to the parent address space But now let's say execs an executable that requires much bigger at the mega memory Parents address space will not increase but the child's address space may increase right because you called exec and the executable that you're going To load now is much bigger than the parent's address space So, I mean basically the point is that you need dynamic growth of processes and this way of doing Address translation is not supporting very fast way of doing dynamic growth of processes question Okay Okay, so so we're going to look at next lecture Another mechanism called paging. All right, so right now so so basically we are we are really talking about a mechanism of in the operating system called virtual memory and So what is virtual memory virtual memory translates an address which is called the virtual address and and to a physical address and There is some function F which does a translation so far in segmentation This F was a very simple function where we just said, you know VA is equal to base plus PA is equal to VA base plus BA and you also check it against the limit But what you really need is that this function should be more sort of detailed So you could be able to say oh this byte goes here and this byte goes here and this byte goes there And so what is what is the most general function? Well, the most general function is for each byte I basically have something which says, you know, this is where you should this is where this byte left This is a despite list but but the data structure is for to store this mapping will be bigger than the address space itself Right. So what you what you basically do is you basically divide the virtual address space into what are called pages And Then you have a table in the function Which maps one page in the virtual address space to another page? Space in the physical address space and we're going to discuss more details in our next lecture. All right. Okay, let's talk"}
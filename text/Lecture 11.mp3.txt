{"text":"Okay so welcome to operating systems lecture 11. So we've been looking at the memory management unit in a typical hardware system and we've been looking at the x86 MMU in particular and we said the x86 MMU implements both segmentation and paging right. So a virtual address is always of the form segment colon offset, cs colon offset, ds colon offset etc. The segment will point to a segment descriptor we have seen this in detail and then the offset is going to be added to the base which is stored in that segment descriptor to get a linear address right. So far we had been calling this a physical address but it really is a linear address if paging hardware is also enabled. So further this linear address goes through another level of translation which we call paging to get you a physical address okay. Most operating systems or most systems in general actually today don't use segmentation hardware for this kind of translation I mean in the way that it in the sense that they all they typically said base is equal to zero and limit is equal to you know whatever the maximum value is in a 32-bit machine for all the segments. You get a flat address space irrespective of what segment you're going through whether you're going to cs, ss, ds doesn't matter it's the offset that counts right. So basically effectively that means that your linear address becomes your offset okay. You could imagine an operating system which is actually using only segmentation and not paging. We have discussed this previously right. In the discussion that I have been having so far when we didn't discuss paging we said you know it's possible to implement virtual address spaces using segmentation and in which case you know linear address becomes equal to physical address and it's possible to do this you just keep swapping the user's descriptor and keep changing its base and limit depending on which process is getting loaded right. So it's possible to implement a complete MMU using only segmentation. Well the only problem is it has some drawbacks and the drawbacks are for example fragmentation becomes a problem, growth of a process is very tricky, and plus you know if you are using multiple segments then the programming model has to worry about which segment I am currently accessing and all that. On the other hand if you have a flat segmented model in which all the segments are have exactly equal base and limit in that case you know the fragmentation problem becomes more severe. Yet another operating system can just use paging hardware in which case he just sets you know all these things to the thing. It still uses the segmentation hardware for things like you know for understanding what privilege level I am executing on. Recall that the last two bits of the CS register basically indicate whether I am executing in privilege level 3 or privilege level 0 and so that still holds. But apart from that the offset pretty much has a one-to-one mapping to the linear address right. So base is equal to zero so in which case it is only using the paging hardware and yet another operating system could try to use both. That's also a possibility. Okay all right so now let's look at paging in more detail. So we said look paging gets rid of some of the problems of segmentation. The main problem with segmentation was that it required the entire process to be in one contiguous chunk in the physical memory. The entire process memory should be in one contiguous chunk in the physical memory and so it was creating problems with fragmentation and growth. So as opposed to that if it was possible to have a mapping between virtual addresses to physical addresses such that the flexibility is more in which case you know a process could be sprinkled across that physical address space but in the virtual address space it may be contiguous and you could basically have mappings arrows going from the virtual address space to the physical address space right and we said you know it's possible to do that you know one has to design it carefully if so basically at what granularity are you going to do this mapping so we said let's call the granularity at which you're going to do this mapping a page right so for every page so within a page contiguous bytes in the virtual address space will be also contiguous in the physical address space but across pages that need not be true okay now question is how big should a page be you said you know page page cannot be so small that the the data structure to store this translation is so big that it's actually bigger than the actual address space itself that's you know that's ridiculous on the other hand it shouldn't be so big that you know you're wasting a lot of space so we said you know let's say that 4 kilobytes is a reasonable value for a page and and then we said okay then if 4 kilobytes is a reasonable value for a page what's the maximum size of virtual address space can be it can be 2 to the power 32 right so 2 to the power 32 divided by 4 KB comes to 2 to the power 20 so you can have at most 2 to the power 20 pages in your virtual address space similarly your physical address space let's assume can be at most 32 bits wide let's assume that the bus can only take a 32 bit address on the physical bus which goes to memory so your physical memory can also be up to 2 to the power 32 bytes let's assume although you know it may be smaller depending on actually how much RAM you have in your system in any case the hardware needs to be needs to provision for the maximum possible so let's say 2 to the power 32 on both sides so what's the number of maximum number of pages on both sides 2 to the power 20 and so you need a mapping from a set of 2 to the power 20 numbers here to another set of 2 to the power 20 numbers here right and so this mapping we said if you know if I was to do it in one contiguous table it will require 2 to the power 20 entries so I can just have an array which has 2 to the power 20 entries and each entry basically stores where this page is mapped and this this this array will actually be pretty big it will be 4 megabytes if I was to do this and so assuming that each process has a separate address space each process will need a separate mapping and so for each process I'll need to have a separate data structure of this size but this sounds very large you know 4 megabytes for every process is a very large because typically processes are smaller so we said okay let's divide the map let's divide this mapping into a two-level hierarchy right and the first level we're going to call a page directory which is going to create a mapping from the first 10 bits to a page table and then the second page and the page table that you obtain you're going to use the next 10 bits to get the actual physical address you have divided the 2 to the power 20 entries into sets of 2 to the power 10 you know into this by the 20 bits into 2 into 10 bits 10 bit look up right so the advantage of this is let's say a process has only is only mapping you know 64 kilobytes of space right so 64 kilobytes of space can be captured in you know 64 divided by 4 that's 16 pages right so 16 pages can probably just you know one page table can have up to 1 0 2 4 entries so one page table can actually have 1 0 2 4 pages so in just you just need to allocate one page table and fill in those 16 entries here and just have one entry in the page directory that's pointing to that table at the corresponding offset right so let's say let's say my process was having an address space from 0 to 64 KB right so what will happen is the the 0th entry in the page directory will point to a page table and the 0th to 16th entries in the page table will point to pages all the other entries will be invalid okay so that way a process which was only 64 kilobytes large needed a page table structure of 8 kilobytes right two pages each of these is a 4 kilobyte structure so you needed one page directory and one page table so you know you needed 8 kilobytes to store the mapping for a 64 kilobyte process which has a contiguous mapping from 0 to 64 kilobytes okay so significant improvement over the 4 megabytes that we had earlier right it's a simple thing you just divide one linear array into it into a two level tree and you basically only have pointers where there exists the mapping and for others you just say it's invalid okay so of course the downside of dividing a one single cable into two is what number of lookups right the number of lookup that you need to do in memory or number of D references that you need to do in memory has doubled earlier you just had to do 1d reference to get the physical address now you have to do two different answers first you do a difference here then you have to do a D reference here before you actually get a get to the data right so let's so so here's how it works on x86 there's a special register called the control register 3 we said there are some special control registers in x86 so there's a special register called control register 3 which points to the base of the page directory okay and then you know any linear address that's computed through the segmentation hardware the first 10 bits are used to index into this page directory to get a page table the next day 10 entries bits are used to index into the page table to get the page and the last 12 bits are indexed into the page to get the real data right the physical address is actually this value plus whatever this offset is right that that will be the physical address and that's where the data is going to live in physical okay why does the pointer to the page table need to be 20 bits great question because in each page table is also a page you have basically divided your entire physical address page into pages right and you have mandated that page directories and pages page tables will also are also constrained to start only at page boundaries right a page table cannot be across two pages right so basically just statically created a partition of you know you basically said every four kilobytes you have drawn a line and you said that a page table has to live in one of those slots it cannot actually you know straddle two slots so because and so then the number of bits you need to actually understand what which slot you have is only two is only 20 bits okay so similarly you know the page directory needs to be really only 20 bits the page table can be addressed using 20 bits and the page itself can be added using 20 minutes okay we also said you know even although these pointers are 20 bits it makes sense to actually allocate 32 bits for the entire entry so this this entry is also called the page this is called the page directory entry and this is called the page table entry so let's use the words PDE and PTE right so both PTE and PDE are 32 bits long so the last 12 bits are can be used for other purposes and in particular these last 12 bits are used to store flags right for example just like in segmentation you can where you could store you know whether this segment is allowed to be accessed in unprivileged mode or not you can say whether this this page is allowed to be accessed in unprivileged mode or not right so that's the user flag firstly there's the present flag whether it says whether the page is actually present right so so in this example let's say a process has only 64 kilobytes of map space where from 0 to 64 kilobytes and it's a linear address then the only the first entry will have the present bit set all the other four zero you know one zero two three entries in the page directory will have the present bit zeroed out right that's what it means that the entry is actually invalid similarly in the page table the first 16 entries will have the present bit set all the other entries will have the present bit set to zero so that's a bit which says whether the sense whether this page table entry actually has means anything or not whether the hardware should actually consider both dereference it at all or not all right then there is another flag which is user which basically says whether I am able to whether I should dereference this page table entry only in supervisor mode or am I allowed to dereference this page table entry either in supervisor or in user mode right so you can do it either in user or privileged mode and the third thing which it has is whether this page is writable or not right so it gives you a other sort of added capability you can actually the operating system can actually map certain pages as read-only and you see you know why this is a very useful thing to have so if a page has a writable with zero doubt then if a program tries to write to an address that dereferences through that entry it should generate a an exception right and this kind of an exception is called a page fault so instead of a segmentation fault now we are talking about paging so the new name is called a page fault the meanings are similar basically you're trying to access an invalid address or you are trying to address access a valid address in an invalid way right so a page fault can occur if you are trying to access a non-user page in user mode or if you're trying to access a non-present page or if you're trying to write to a non-writable page you know either of these basically mean that you know you generate up the hardware will generate a page fault and you know the page fault handler will do the similar thing for example it may kill the process or it may you know convert the page fault into a signal that it gives to the process all these just like before right okay okay so yeah great question are these page tables managed by hardware or does the OS have a role to play in it the OS sets up these page tables so the OS sets up the cr3 pointer for example right the OS sets up the contents of the page directory the OS sets up the contents of page tables before it transfers control to the process but for each memory access the OS is not coming into picture it's the hardware that walks these page tables or the hardware that reads these page tables right so this process of actually converting a linear address to a physical address is called page table walking or walking the page table so the walking of the page table is actually done by the hardware the operating system sets up the page table okay so the hardware walks the page table and if there was an error for example you know you're trying to read an an entry which is not present then it will generate a page fault okay all right so okay right so right so yeah so basically each of these flags so when I say there's a flag in the page directory entry let's say the present flag in the page directory entry is not set what does that mean it means there's actually no page in this map there's no mapping here right so if if the program actually try to access a linear address that has the first 10 bits map pointing to this entry which has a present bit not set then it will generate a page fault right there it doesn't need to do a second level page lookup at all right similarly user and writable so I mean it's possible that you know so it's possible that this entry was present but it says this entry is not writable on the other hand the page table entry corresponding page entry table says writable you know one of the entries says not writable the second entry says writable so the net effect is basically the and of these two which means not writable okay once you know conversely this could be writable and this could not be this could be non-writable in which case overall it's non-writable so you know the OS can do it do this at a very fine grained level at page granularity you can do all these writable you can mark all these writable and then you know only pages which are not writable in this particular entry that those are non-writable otherwise others are same thing for user and supervisor right so you could have you know the page directory entry itself could say I am I'm a user mode entry which means anybody can access me but some of these entries are user and some of these entries are supervisor so once again you take the and of these two so if both of them are supervisor only or both of the only both of them of only both the user bits are set can the user access that page right if only if for any of these entries of user bit is not set then the hardware should not be it should generate a page fault if it's executing in uncivilized mode okay all right so let's see how paging can be used so we saw how segmentation can be used to implement processes question what is the difference between a segmentation fault and a page fault actually at the Unix abstraction level a page fault is converted into a segmentation signal 6x V right so both of them actually map to the same thing okay but at the hardware level you know on x86 different exceptions are used to indicate different conditions so there's a separate exception number for page fault and there's a separate exception number for segmentation violation if we are not using segmentation a segmentation violation should never occur well that's not true because you know you are not using segmentation in the sense that you are not using it to segment memory but you are still using the privilege bits or the you know the the permission bits in the segment descriptor so you know if you try to act execute for example the user tries to load into the segment selector a privilege descriptor so that will still cause a segmentation violation okay so it's still possible to have a segmentation violation even in this flat segmentation model where you know you're basically mapping the entire space into all the segments okay all right so let's see how paging can be used well one very simple thing is you create you set up the page table to to basically have an identity mapping right so linear address X always map to physical address X and so that's one way and how will you do that you will just say oh how big is my physical memory let's say 0 through M so you know you will basically say okay 0 through M let's say this is my page directory I'm going to set up you know Z the first M by 2 to the power 20 entries here right and then each of these is going to point somewhere and each of them is going to set up all its entries appropriately right to exactly the same address you could set up a linear completely identity map between your linear address and your physical address that is probably you know that's probably what you will do if you're not implementing multiprocessing and you're not having multiple processes and all that for example if you are you know using your system your processor to implement some kind of an embedded system for example something which does not expect multiple processes to be running is just doing going to run the OS in one way and you have this paging hardware you would probably just set up an identity mapping and or alternatively you could even disable paging and so it's the same effect right so just to get a set just to understand that you know you can how you're going to do this it sort of increases your understanding of how paging works so identity mapping is easy the other thing you can do with paging is you know set it up like segments right so you can say okay okay so so here's my page table and let me let me just assume that you know it's a uniform sort of address space and so what I'm going to do is I'm going to say okay let's say this part of the let's say this is my physical address space this is my PA space all right so let's say this part of the PA is let's say this part of the PA is reserved for the kernel and this part of the PA is reserved for process P1 this part of the space is reserved for P2 P3 and so on and let's say this is free okay just like what we had in segmentation and we were implementing it using base and limit this what I'm going to show you is basically that paging is more general than segmentation because you know you can easily do this in paging also very clear what you're going to do is basically say that in your page table so let's say this is physical address 0 and this is you know something let's say a B C and D right so in your page table in your page directory you're going to say let's say in your in your letter this is via space in your via space so this was a PA space and this is a virtual address space in the virtual address space each process should see here see the same set of addresses so what you're going to do is in the via space you're going if P1 is loaded then you're going to map P1 to this space right you're going to set up the page tables at that 0 to B minus A of P1 maps to A to B in physical address space right easy to set that up you just set up the page directory entries and page table entries then let's say you switch to P2 you will load a new page table right and how will you load the new page table you will change the CR 3 register right you will change the CR 3 register so a new page table gets loaded and the new page table will have a similar thing but it is a 0 to let's say C minus B and that's going to map this to so you can just so in the segmentation model each time there was a context which we were overwriting the segment register descriptor with a new base in this case each time there's a context which I'm overwriting CR 3 so that I have a new page table loaded and I've set up the page tables to basically emulate exactly what the segmentation hardware would have done yes we are changing the page directory and also the page tables we can change the entire two level hierarchy right so assuming that there's no sharing between different page directories right each page directory so you change the page directory and consequently you change all the pointers of the page directory okay so yes when you context switch in the paging world we're going to replace the CR 3 so you're going to have a new page directory and you can you know set up your page directory or page table to do this mapping just like you were doing in segmentation the only difference is that in this case you know the page tables will be different right in one case the page tables mapping that entries which will be present in the page table you know the or the pointers in the page tables will be different they'll be pointing to different regions in the physical memory basically question yes so if you know each process has a page directory and a page and a page table structure and let's say I update one of them with a new pointer as the OS must ensure that this pointer and where is this page is pointing in physical memory that's not it doesn't that that page is not being pointed to by any other page table structure right so that's that's possible for the ways to do no problem the way this keeps that there's some bookkeeping that these pages are belonging to this process these pages are belonging to this process and there they are all you know disjoined sets of physical pages and so and you then create mappings appropriately okay all right so let's assume that all processes are completely disjoined set of pages in physical memory and you're going to just set up your page table in such a way that the page table of process P1 is going to point to its pages and process page table of process P2 is going to point to its pages and each time you context which you're going to override the CR3 register okay yes I don't know could you repeat your question yes so for in the GDT there's a U base and U limit for each process yes okay yes all the let's say all the segment registers will always point to U base and U limit when the process is executing okay that U base and U limit will not point anywhere okay U base and U limit will only be used to compute a linear address right so from the offset you complete compute a linear address and now the hardware will what will point to the page directory is CR3 is a completely you know separate register you're going to use CR3 to actually look into the page directory use the use the linear address computed through your segmentation hardware to index into CR3 the first 10 bits and and so on okay all right so so this is good X except that is one thing so this is this sounds very similar to how it was done for segmentation right the only difference really is in this case I'm changing the page tables themselves in that case I was just changing the segment descriptor right the the difference here is that the kernel is also you know I said that in the in this model let's assume that the segmentation is completely flat so even the kernels segment descriptor also has base is equal to 0 and limit is equal to 2 to the power 32 minus 1 right so the kernel is also you know the kernel is also not using the segmentation hardware at all that's it in which case you know somebody else so the virtual address to physical address translation is just going to take the offset and make this make that the linear address and now the linear address has to be converted to physical address by a paging hardware so the kernels linear address is likely if it's possible that so the kernels linear address needs to be converted to physical address by the paging hardware and so what you do is you inside the page table of every or inside the VS space of every p1 you also map the kernel somewhere so the kernel shares VS space with the process okay let's see you know this so basically let's take some concrete examples how does it work in Linux alright so how does it work in Linux every process has an address space which can go from you know by definition or 32-bit machine you can at most have 0 to 2 power 32 minus 1 except that you say that a process is not allowed to access the entire 0 to 2 power 32 minus 1 if you are compiling a process for Linux or if a process should be able to run inside Linux legally then it should never access an address beyond so you know this let me call it 4 GB just to make it more readable so 2 to power 32 minus 1 is less than 4 GB and so you shouldn't ever access an address above 3 GB right so a process is constrained to access addresses only within 0 and 3 GB the addresses from 3 GB to 4 GB the virtual addresses are reserved for the kernel so that's where the kernel is mapped okay so let's say this is p1 so typically what will happen is p1 is mapped 0 to let's say some address you know 100 KB and all this is not used and then there is p2 which also has 0 to you know let's say 200 KB this time and but also has the kernel mapped from 3 GB to 4 GB so the kernel also ensures basically while setting up the page table that its own pages are always mapped in a certain address range of the VF space so if for example there's a transition from user to the kernel and the kernel wants to access its own data structure it can just use one of these addresses from 3 GB to 4 GB to start to try to start in accessing its own code and data for example because we did in this scenario we are not using segmentation at all what was happening in segmentation each time there was a switch from user to kernel CS was overwritten and CS had a different base right and so that way the kernel you know you are now actually accessing kernels memory and not users memory immediately and you know the first thing the kernel will do is load other segment registers so that you know apart from the code other data other segments are also pointing to the kernel but in this model when everything is flat and the kernel is also using a flat model the user is also using a flat model when you switch from when you switch CS you're still in the same same linear address space right and but you need you need to say that now I want to access kernels data or and now I want to access kernels code so that the way it's done is CS the offset of CS is still 0 but the EIP there are certain EIPs that are reserved for the kernel so in particular the EIP is above 3 GB are reserved for the kernel on Linux in the interrupt descriptor table for example the CS colon EIP the CS base of CS if you're if I'm not using segmentation the base of CS will be 0 but the EIP will be some address above 3 GB typically that's where the handler will live and so so because the offset is about 3 GB the linear address will also be about 3 GB and now it will go through the paging hardware and you will basically go reach the kernels space it's the job of the kernel to ensure that the paging hardware translates the address 3 GB and above to the right place in the physical memory and that it can do by by setting up the page table in such a way so each process is a page table not only maps that processes address space but also map the kernels address space at the top in Linux right on Windows you know this is typically the model followed in many operating systems similarly in Windows Windows seem to seem to you know sometimes need more space so it can actually take 2 GB you know it actually takes the top 2 GB for its own kernel on the 32-bit machine but it actually allows you to actually change it if you if you want so depending on so and this is part of the the specification of the operating system so if you're compiling something for Linux then you should ensure that your application will never access an address above 3 GB okay so it's part of the interface the the compiler should be aware of that or you know the if the programmer is assembly programmer he should be aware of that and and how do you do protection how do you ensure that the user is never able to access kernels data or execute kernels code the flag right the user flag so the user flag is off for these mappings of kernel so for the all the kernel mapping the user flag in the page directory entry and the page table entry is 0 for all the other entries the user flag is 1 so the user can never access this kernel but if there's a there's an trap then CS gets reloaded and the last two bits of CS will become 0 and now it can access the upper upper regions of memory virtualization right so just like we saw that in segmentation the kernel remains constant right the kernel doesn't move the kernel in the physical address space remains sort of there and the mapping for the kernel remains constant similarly the mapping this remains constant so the same entries which get copied in every page table or every page directory and page table of every process it's an except it's a yeah so it's an so that so here here's an example we have we are breaking the rule that every page table should be pointing to a distinct set of pages right here is an example where two different processes page tables can you point in the same page in physical memory point and actually there are more examples which we don't discuss later question does this also have the kernel stack for the process the kernel address space yes so so so let's look at how the kernel stack gets switched so we said that if there was a trap while I'm executing in the user mode both the CS will get overwritten and SS will get overwritten EIP will get overwritten and ESP will get overwritten and so what does the OS need to ensure that the EIP is an address above 3 GB and the ESP is also an address of 3 GB okay and within this kernel space you could be having multiple stacks one per process so actually you know in the kernel space you're actually having all the stacks of all the processes all the kernel stack assuming the process model of of the kernel so in the kernel space you will have all the stacks of all the processes but it's all inaccessible to the user user cannot access it right so it's just as a kernel has mapped its entire data structure and code into the user address space so if there's a trap and a flat segmentation model then you straightaway go to to the to that to the kernel address space in both for EIP the program counter and the ESP the stack pointer okay and then you also change your other sort of segments and all that okay question is why do I need the entire kernel to be mapped inside the process address space couldn't I have just mapped the kernel stack in the process address space just one one you know let's say whatever size I want to have for the stack kind of stack that's what I'm going to put it in the but what about the code you know so the program counter you'll also need to put that so the handler needs to be there and so the handler is going to make more calls so you could potentially say that look I don't you know this this 1gb of space taken away from the process seems too costly and so what I want to do is actually have a very small sort of handler inside which which is not 1gb but let's say you know a few hundred KBs and that handler is actually immediately going to fit the page table and then he's going to execute the kernel logic that's a possibility right there are there are pros and cons to doing that this seems this actually works this this is one of the best performance kind of design designs so you know there have been multiple designs of operating system that have been proposed but this is this is sort of the most popular design and one reason this is the most popular design is it's the most performant design okay and or I should qualify the statement this is in a controversial statement may not be the most performant design but it's the easiest to get performance out of this design right and this is a design that you know your mainstream kernels use Linux Windows xv6 is you know what you're going to be we were going to be studying next starting next time Pintos which is your base going to be your programming assignments all right so so basically this is how so the kernel basically maps itself in every process address space and and you know if there's a trap it can immediately transition without having to do anything and the kernel can now execute happily inside the process basically there's one difference that the kernel needs to be aware that it should only be accessing you know it should be living in a certain address range in segmentation case the kernel could have mapped itself from zero to something right because you know CSB base has been changed so you know you're finding somewhere else but in this case the offset needs to be within a certain range three to four GV okay so let's see what happens on the timeline just like we have seen for for let's say this is boot time just like we've seen for for the process so what happens is you know at boot time it will first set up its segmentation table and now in this case it will just set up the segmentation tables to completely identity mapping 0 and 2 to the power 2 minus 1 then it will set up its own page table which will be let's say an identity mapping and it will enable paging in the hardware right and so it's the kernel page table that's getting loaded here then the kernel will load itself in a certain address space so the kernel has been compiled to assume that it will be living in a certain address range so the kernels EIP and all these the program counters will always be in that address range and so when you it loads the kernel and the core kernel starts executing you know so let's say so initially you start executing in physical address space so kernel is living from zero to whatever maximum value you have then what the kernel does is it loads itself from you know while it's executing it loads itself in the top address space also so it's first set up page table so enable paging it sets up the address space and now it says let's map myself in the new page table at the top so it's going to map itself on the top also so it's going to say 3 GB to let's say 3 G plus M wing so this is this is where it gets loaded and now now it starts running from here and now it's you know context which is to the first process it starts the first process and so the kernel lives here I want to say K and the process let's say lives here P1 right and then it again context which is when it context which is it actually you know it's it executes so when it context which is a trap occurs while it was executing here when the trap occurs it starts executing here here it does the appropriate changes in CR 3 in the page table so when it does the page table change it actually reaches here it changed the address space it's in CR 3 and now it calls return to get to to resume execution of process people right so process P1 is executing in user mode a trap occurs you switch to kernels address space in the same page table the kernel in that page table while it's executing that page table creates a new page table for process P2 if needed maps itself in that new page table switches the page table because it had mapped itself at exactly the same addresses when it switches itself you know it's not like the carpet has been dragged out under its feet because the same addresses are still valid right so the new page table has the kernel mapped in exactly the same place where it was mapped in the old page table so when you switch it doesn't matter right the kernels can still execute it's just the user space address page that has changed and now you can return back using the irate instruction to the process and now the process P2 can start executing so let's say you know the kernel has decided that it wants to context switch from P1 to P2 right so it needs to load the new P2 page table but the nice thing is that P2 page table also has a kernel mapped at exactly the same position so when it does the when it overwrites CR3 its addresses are still valid so the next instruction pointer will exactly go to the same physical location still right and now the next thing it will do is basically go to user mode and this time it will see P2 there all the kernel spaces in each of the processes are at either replica well they actually point into the same place so they are not replicas they're shared they're not copies they are just shared with each other page tables are replicas the kernel space itself is not called replica the page tables are replicas for those particular entries not all the entries just those particular entries which are mapping the kernel okay all right okay right so let's see some nice thing that you can do with paging you can do something called so firstly page table paging solves the problem of fragmentation and growth in a large way right because now if a process needs to grow all it needs to do is let's say this is the VA space and this is the PA space so so let's say the process is mapped in 0 to capital M but you know these are pages which are mapped here let it have two pages one is mapped here and the other is mapped here let it is p1 so these are p1 pages and these even pages and now there are other pages like p2 pages p3 pages so there's two let's say two p2 pages one p3 page and now there's all this empty space now if I want to grow M all I need to do is you know create another mapping for another page allocate another page here p1 and create this mapping here so growth is very easy no problems of fragmentation you just sort of allocate a new page in the in the physical address space and you create a mapping in the page table so that the physical virtual address space growth the growth growth is no problem fragmentation is no problem because you know the the address the mapping don't need to be contiguous if there was enough space in the if there are there are enough pages for the new process to fit in it will get fit in it's not like they need to be contiguous all right okay so it's all fragmentation the other nice thing it can do is what's called demand paging what is demand paging let's say I created a new process and let's say this process is LS right so let's say this is LS and LS maps its code in this is 0 to capital M hypothetically and let's say there's this disk right which has a program file called LS executable right LS executable now when you actually say LS one way to implement the exit system call in the OS is to actually copy the entire contents of the LS executable into physical memory and create this mapping that's you know upfront you you allocate that much memory you copy the entire disk contents to memory create the mapping and start the process running an optimization over that is that you actually don't read the disk into memory upfront you just create an address space from 0 to M by reading the executable and then you basically just store some meta information in this address space saying that look right now these pages are not present but if the user tries to access this page then here's where you should get it from on this so here's the disk log from where you should get this particular page from right so for example if LS was a large program you know let's say the program was at a 1 megabyte long large but typically when you type LS you're only going to be executing let's say 100 kilobytes of code somewhere and you know almost you know let's say 4 kilobytes of data they only needed those 104 kilobytes in memory you didn't need to read the entire 1 megabyte into memory so what you do is you know demand paging helps but the OS doesn't know you know which what may get executed in future so but demand paging helps it creates the address space for the entire 1 megabyte it maps the first page of the page containing the instruction which is the first instruction into memory and transfers control to that instruction if that instruction happens to execute some other address which is not currently mapped what will happen page fault the operating system will come into action it will figure out oh you know actually the process is not doing anything illegal it's my I who is playing tricks under the rug right and so I shouldn't I should actually you know stick to my contract and so that's when you will basically pick up the page paste it into physical memory create the mapping and restart the instruction right this is this is demand paging very useful optimization in fact we discussed this we discussed fork and exec right in Unix and we said you know and then we said Windows has this create process and he said look folks seems very graceful because you're going to actually copy the entire process in from disk to memory and all that but the reason you know Unix designers at that time thought that it's not a big problem you can actually fork is not so inefficient is because of demand paging at that time memories were really small so most of your program code and data used to live on disk right and so forth was basically just forking the process just involved creating a new page table and you know updating and having the same pointers shared pointers to the disk and the fork was really cheap in that sense and if the next thing the process is going to do is exec you know no problem you actually didn't waste much work it's at that time it seemed very natural and so fork and exec was was a was a nice interface because given that demand paging was a very very very possible optimization so I mean optimization also dictate your programming models right nice example of this another thing you can do is copy-on-write so what's copy-on-write let's say here's a process the p1 and it folks another process p2 right and let's say you know we are it's not the old world in the new world then processes act memories are large so the process actually living in memory right so once again focus actually one way to implement focus that you create a page table for the new process and you basically point the page table entries of both p1 and p2 to the same physical pages except that you mark all those pages read only right because if one process right you don't want that to be other process you mark all those pages read only so you so the entire space is shared except that it's now become read-only now if one of those process tries to write one of those pages then immediately there will be a page fault and you will just copy it at that time so that's called copy-on-write so you actually shared the pages and assuming that you the child process was going to call exec immediately it's actually not going to write to any page right and the page table is going to get overwritten so focus again very cheap even in the memory world right okay good so so let's stop here and we're going to discuss more of paging from the next lecture onwards please bring your xv6 code listing to class right so you're going to actually now start looking at the xv6 code to see how the concepts that we discussed so far are actually implemented in practice in a real offering"}